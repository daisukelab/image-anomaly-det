{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *\n",
    "\n",
    "sys.path.append('..')\n",
    "import anotwin\n",
    "from utils import *\n",
    "\n",
    "dataroot = '/data/mvtec_ad/original'\n",
    "project = 'mvtecad_anotwin'\n",
    "\n",
    "params = EasyDict()\n",
    "params.project = project\n",
    "params.work_folder = 'tmp'\n",
    "params.valid_pct = 0.2\n",
    "params.suffix = '.png'\n",
    "params.n_mosts = 4\n",
    "params.load_size = 256\n",
    "params.crop_size = 224\n",
    "params.batch_size = 16\n",
    "params.n_epochs = 50\n",
    "params.workers = 12\n",
    "params.model = 'arc_face'\n",
    "params.backbone = 'resnet34'\n",
    "params.train_album_tfm = None\n",
    "params.train_tfm = None\n",
    "params.dataset_cls = anotwin.DefectOnBlobDataset\n",
    "params.val_ds_cls = anotwin.AsIsDataset\n",
    "params.logger=None\n",
    "params.lr = 0.0001\n",
    "params.lr_step = 10\n",
    "params.weight_decay = 0.95\n",
    "params.scheduler = 'OneCycleLR'\n",
    "#params.scheduler = 'CyclicLR'\n",
    "params.data = {}\n",
    "params.data.width_min = 1\n",
    "params.data.width_max = 10\n",
    "params.data.length_max = 40\n",
    "params.data.color = True\n",
    "params.data.pre_crop_rect = None\n",
    "params.max_fpr = 0.1\n",
    "params.min_tpr = 1.0\n",
    "params.sigma_k = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:22:22,455 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 15:22:22,459 dlcliche.utils add_good_samples [DEBUG]: Adding 209 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n",
      "\n",
      "--- Start evaluating [bottle] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:23:04,405 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:23:04,406 dlcliche.utils create_datasets [DEBUG]: all train files: 209, val files: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.0763 acc: 0.0000  val loss: 14.0068 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.006806\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.8035 acc: 0.0000  val loss: 13.3092 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.309205\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.0567 acc: 0.0000  val loss: 11.8539 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.853923\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.3764 acc: 0.0000  val loss: 11.0674 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.067404\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.8189 acc: 0.0000  val loss: 9.5034 acc: 0.0119\n",
      "Update: Best val acc/loss: 0.011905/9.503386\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 11.3318 acc: 0.0000  val loss: 9.1931 acc: 0.0119\n",
      "Update: Best val acc/loss: 0.011905/9.193131\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.9675 acc: 0.0000  val loss: 8.1491 acc: 0.0952\n",
      "Update: Best val acc/loss: 0.095238/8.149105\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 10.1396 acc: 0.0000  val loss: 7.8669 acc: 0.1071\n",
      "Update: Best val acc/loss: 0.107143/7.866928\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 10.5676 acc: 0.0030  val loss: 7.8038 acc: 0.0833\n",
      "Update: Best val acc/loss: 0.083333/7.803757\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 10.0808 acc: 0.0030  val loss: 7.5953 acc: 0.0595\n",
      "Update: Best val acc/loss: 0.059524/7.595322\n",
      "Training complete in 0m 20s\n",
      "Best val Acc/Loss: 0.059524/7.595322\n",
      "Epoch 0/50 lr:0.0000040  train loss: 10.1313 acc: 0.0090  val loss: 6.3056 acc: 0.2976\n",
      "Update: Best val acc/loss: 0.297619/6.305565\n",
      "Epoch 1/50 lr:0.0000052  train loss: 8.4898 acc: 0.0210  val loss: 5.3117 acc: 0.3333\n",
      "Update: Best val acc/loss: 0.333333/5.311664\n",
      "Epoch 2/50 lr:0.0000088  train loss: 7.1508 acc: 0.0629  val loss: 3.7615 acc: 0.5952\n",
      "Update: Best val acc/loss: 0.595238/3.761489\n",
      "Epoch 3/50 lr:0.0000145  train loss: 5.3831 acc: 0.1976  val loss: 3.1888 acc: 0.7500\n",
      "Update: Best val acc/loss: 0.750000/3.188772\n",
      "Epoch 4/50 lr:0.0000221  train loss: 3.6438 acc: 0.4731  val loss: 2.0011 acc: 0.8690\n",
      "Update: Best val acc/loss: 0.869048/2.001117\n",
      "Epoch 5/50 lr:0.0000312  train loss: 2.4392 acc: 0.6198  val loss: 1.5396 acc: 0.9524\n",
      "Update: Best val acc/loss: 0.952381/1.539551\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.4784 acc: 0.7665  val loss: 1.3669 acc: 0.9524\n",
      "Update: Best val acc/loss: 0.952381/1.366863\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.0767 acc: 0.8323  val loss: 0.5803 acc: 0.9643\n",
      "Update: Best val acc/loss: 0.964286/0.580263\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.8406 acc: 0.9042  val loss: 0.0091 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.009139\n",
      "Epoch 9/50 lr:0.0000728  train loss: 1.0867 acc: 0.8743  val loss: 0.7888 acc: 0.9643\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.7679 acc: 0.8922  val loss: 0.2763 acc: 0.9881\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.8139 acc: 0.9341  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 1.2928 acc: 0.9042  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.9725 acc: 0.8892  val loss: 1.0064 acc: 0.9762\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.4648 acc: 0.9760  val loss: 0.6178 acc: 0.9762\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.3740 acc: 0.9431  val loss: 0.0002 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.1826 acc: 0.9731  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.4215 acc: 0.9491  val loss: 0.4676 acc: 0.9881\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.5251 acc: 0.9581  val loss: 0.0004 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.7125 acc: 0.9341  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.4308 acc: 0.9581  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.6162 acc: 0.9371  val loss: 2.1999 acc: 0.9405\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1272 acc: 0.9880  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.8626 acc: 0.9371  val loss: 0.5274 acc: 0.9881\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.5270 acc: 0.9671  val loss: 1.0103 acc: 0.9762\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.2477 acc: 0.9820  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1858 acc: 0.9731  val loss: 0.5315 acc: 0.9881\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1789 acc: 0.9790  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.2099 acc: 0.9820  val loss: 0.5313 acc: 0.9881\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.3965 acc: 0.9671  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1622 acc: 0.9850  val loss: 1.0752 acc: 0.9762\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.2044 acc: 0.9760  val loss: 0.4407 acc: 0.9881\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1113 acc: 0.9760  val loss: 0.5402 acc: 0.9881\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.3962 acc: 0.9820  val loss: 0.5318 acc: 0.9881\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0172 acc: 0.9970  val loss: 0.9273 acc: 0.9762\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.2711 acc: 0.9790  val loss: 1.0725 acc: 0.9762\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0623 acc: 0.9970  val loss: 0.5394 acc: 0.9881\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.2881 acc: 0.9671  val loss: 0.5348 acc: 0.9881\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1047 acc: 0.9940  val loss: 0.5381 acc: 0.9881\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.5369 acc: 0.9521  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.4411 acc: 0.9551  val loss: 0.3988 acc: 0.9881\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.1243 acc: 0.9940  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0238 acc: 0.9940  val loss: 0.5463 acc: 0.9881\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1052 acc: 0.9970  val loss: 0.5353 acc: 0.9881\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.1662 acc: 0.9731  val loss: 0.5354 acc: 0.9881\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0087 acc: 0.9970  val loss: 0.1609 acc: 0.9881\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0478 acc: 0.9820  val loss: 0.5337 acc: 0.9881\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0992 acc: 0.9850  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0007 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0004 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 20s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:25:44,094 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:25:44,123 dlcliche.utils create_model [INFO]:  using model weight: weights_bottle\n",
      "2020-04-18 15:25:44,124 dlcliche.utils add_good_samples [DEBUG]: Adding 209 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 15:26:25,883 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 15:26:42,567 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 15:26:42,624 dlcliche.utils add_good_samples [DEBUG]: Adding 224 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.8990069034857653 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.026182161636524745 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.026182161636524745 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.2934478223323822\n",
      "Results: {'target': ['bottle'], 'auc': [1.0], 'th_k_sigma': [2.8990069034857653], 'th_fpr': [0.026182161636524745], 'th_tpr': [0.026182161636524745], 'norm_factor': [0.2934478223323822], 'pauc': [1.0]}\n",
      "\n",
      "--- Start evaluating [cable] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:28:37,979 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:28:37,979 dlcliche.utils create_datasets [DEBUG]: all train files: 224, val files: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.4627 acc: 0.0000  val loss: 14.3540 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.353988\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.3598 acc: 0.0000  val loss: 14.0035 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.003525\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 14.1300 acc: 0.0000  val loss: 13.8449 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.844920\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 14.0169 acc: 0.0000  val loss: 13.6343 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.634336\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.9121 acc: 0.0000  val loss: 13.4817 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.481742\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.8600 acc: 0.0000  val loss: 13.2422 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.242165\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 13.7768 acc: 0.0000  val loss: 13.2392 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.239161\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 13.6911 acc: 0.0000  val loss: 13.0501 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.050098\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 13.5821 acc: 0.0000  val loss: 13.1023 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 13.6484 acc: 0.0000  val loss: 13.0594 acc: 0.0000\n",
      "Training complete in 0m 29s\n",
      "Best val Acc/Loss: 0.000000/13.050098\n",
      "Epoch 0/50 lr:0.0000040  train loss: 13.6212 acc: 0.0000  val loss: 13.1215 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.121544\n",
      "Epoch 1/50 lr:0.0000052  train loss: 13.2734 acc: 0.0000  val loss: 12.0747 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.074747\n",
      "Epoch 2/50 lr:0.0000088  train loss: 13.0273 acc: 0.0000  val loss: 11.3241 acc: 0.0111\n",
      "Update: Best val acc/loss: 0.011111/11.324051\n",
      "Epoch 3/50 lr:0.0000145  train loss: 12.4755 acc: 0.0000  val loss: 9.8072 acc: 0.0889\n",
      "Update: Best val acc/loss: 0.088889/9.807220\n",
      "Epoch 4/50 lr:0.0000221  train loss: 10.3632 acc: 0.0000  val loss: 7.2809 acc: 0.2222\n",
      "Update: Best val acc/loss: 0.222222/7.280884\n",
      "Epoch 5/50 lr:0.0000312  train loss: 7.5018 acc: 0.0810  val loss: 2.9389 acc: 0.5556\n",
      "Update: Best val acc/loss: 0.555556/2.938856\n",
      "Epoch 6/50 lr:0.0000413  train loss: 3.5857 acc: 0.3799  val loss: 1.5163 acc: 0.9111\n",
      "Update: Best val acc/loss: 0.911111/1.516263\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.6748 acc: 0.7318  val loss: 2.3803 acc: 0.8889\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.7456 acc: 0.8240  val loss: 1.9295 acc: 0.9222\n",
      "Epoch 9/50 lr:0.0000728  train loss: 1.3429 acc: 0.8771  val loss: 0.9868 acc: 0.9667\n",
      "Update: Best val acc/loss: 0.966667/0.986837\n",
      "Epoch 10/50 lr:0.0000819  train loss: 1.2899 acc: 0.8966  val loss: 1.2155 acc: 0.9667\n",
      "Epoch 11/50 lr:0.0000895  train loss: 1.3164 acc: 0.8939  val loss: 2.9833 acc: 0.9111\n",
      "Epoch 12/50 lr:0.0000952  train loss: 1.8418 acc: 0.8939  val loss: 2.1365 acc: 0.9444\n",
      "Epoch 13/50 lr:0.0000988  train loss: 1.2140 acc: 0.9162  val loss: 2.3870 acc: 0.9111\n",
      "Epoch 14/50 lr:0.0001000  train loss: 1.9064 acc: 0.8408  val loss: 2.1688 acc: 0.9333\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.5742 acc: 0.9441  val loss: 0.3005 acc: 0.9889\n",
      "Update: Best val acc/loss: 0.988889/0.300469\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.9063 acc: 0.9218  val loss: 0.0253 acc: 0.9889\n",
      "Update: Best val acc/loss: 0.988889/0.025253\n",
      "Epoch 17/50 lr:0.0000982  train loss: 1.0364 acc: 0.9497  val loss: 1.9602 acc: 0.9111\n",
      "Epoch 18/50 lr:0.0000968  train loss: 1.3621 acc: 0.9330  val loss: 2.4130 acc: 0.9333\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.7777 acc: 0.9497  val loss: 1.7219 acc: 0.9111\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.7901 acc: 0.9218  val loss: 1.5783 acc: 0.9556\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.5614 acc: 0.9693  val loss: 3.2718 acc: 0.9111\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.9416 acc: 0.9525  val loss: 2.5738 acc: 0.9333\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.7391 acc: 0.9581  val loss: 1.8789 acc: 0.9444\n",
      "Epoch 24/50 lr:0.0000812  train loss: 1.1085 acc: 0.9469  val loss: 0.9670 acc: 0.9778\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.6023 acc: 0.9469  val loss: 1.0731 acc: 0.9556\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.9190 acc: 0.9581  val loss: 1.9534 acc: 0.9444\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.7762 acc: 0.9385  val loss: 1.1305 acc: 0.9667\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.3575 acc: 0.9693  val loss: 1.1134 acc: 0.9667\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.8794 acc: 0.9525  val loss: 0.7985 acc: 0.9778\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.4036 acc: 0.9525  val loss: 2.0880 acc: 0.9333\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.2742 acc: 0.9777  val loss: 2.2065 acc: 0.9444\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.3665 acc: 0.9469  val loss: 1.6365 acc: 0.9556\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.3835 acc: 0.9860  val loss: 1.2558 acc: 0.9667\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.6835 acc: 0.9106  val loss: 1.5723 acc: 0.9556\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.2752 acc: 0.9888  val loss: 2.1040 acc: 0.9444\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.4159 acc: 0.9749  val loss: 1.2855 acc: 0.9556\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.7670 acc: 0.9469  val loss: 1.8266 acc: 0.9444\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.4663 acc: 0.9693  val loss: 1.0792 acc: 0.9444\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.7667 acc: 0.9665  val loss: 1.2356 acc: 0.9556\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.2716 acc: 0.9860  val loss: 0.7481 acc: 0.9778\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.3679 acc: 0.9804  val loss: 1.2640 acc: 0.9556\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.1569 acc: 0.9860  val loss: 1.1519 acc: 0.9667\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1808 acc: 0.9860  val loss: 1.7762 acc: 0.9444\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.5960 acc: 0.9218  val loss: 1.1930 acc: 0.9556\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.3609 acc: 0.9749  val loss: 0.8053 acc: 0.9778\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.4640 acc: 0.9302  val loss: 0.4684 acc: 0.9778\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.6467 acc: 0.9777  val loss: 0.0116 acc: 0.9889\n",
      "Update: Best val acc/loss: 0.988889/0.011571\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.4306 acc: 0.9860  val loss: 0.7723 acc: 0.9667\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2883 acc: 0.9777  val loss: 1.3977 acc: 0.9667\n",
      "Training complete in 2m 53s\n",
      "Best val Acc/Loss: 0.988889/0.011571\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:31:59,478 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:31:59,508 dlcliche.utils create_model [INFO]:  using model weight: weights_cable\n",
      "2020-04-18 15:31:59,508 dlcliche.utils add_good_samples [DEBUG]: Adding 224 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 15:33:58,802 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 15:35:17,923 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 15:35:18,018 dlcliche.utils add_good_samples [DEBUG]: Adding 219 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 5.9172674406781685 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.4263537896855032 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.1880665162774053 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.031875304877758026\n",
      "Results: {'target': ['cable'], 'auc': [0.8588830584707646], 'th_k_sigma': [5.9172674406781685], 'th_fpr': [0.4263537896855032], 'th_tpr': [0.1880665162774053], 'norm_factor': [0.031875304877758026], 'pauc': [0.6275546437307662]}\n",
      "\n",
      "--- Start evaluating [capsule] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:37:09,960 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:37:09,960 dlcliche.utils create_datasets [DEBUG]: all train files: 219, val files: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3490 acc: 0.0000  val loss: 14.0258 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.025845\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.9204 acc: 0.0000  val loss: 13.1339 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.133875\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.2056 acc: 0.0000  val loss: 11.8657 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.865706\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.4393 acc: 0.0000  val loss: 10.2875 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.287463\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.7857 acc: 0.0000  val loss: 8.8351 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.835058\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 11.1511 acc: 0.0000  val loss: 8.5640 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.564032\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.7392 acc: 0.0000  val loss: 7.2050 acc: 0.0455\n",
      "Update: Best val acc/loss: 0.045455/7.205027\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 10.3292 acc: 0.0000  val loss: 7.2907 acc: 0.0455\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 9.7704 acc: 0.0000  val loss: 6.9213 acc: 0.0455\n",
      "Update: Best val acc/loss: 0.045455/6.921265\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.8982 acc: 0.0029  val loss: 6.7425 acc: 0.0455\n",
      "Update: Best val acc/loss: 0.045455/6.742506\n",
      "Training complete in 0m 27s\n",
      "Best val Acc/Loss: 0.045455/6.742506\n",
      "Epoch 0/50 lr:0.0000040  train loss: 9.1079 acc: 0.0029  val loss: 4.8616 acc: 0.3295\n",
      "Update: Best val acc/loss: 0.329545/4.861602\n",
      "Epoch 1/50 lr:0.0000052  train loss: 7.3891 acc: 0.0314  val loss: 3.1519 acc: 0.5682\n",
      "Update: Best val acc/loss: 0.568182/3.151865\n",
      "Epoch 2/50 lr:0.0000088  train loss: 5.6942 acc: 0.1143  val loss: 2.6305 acc: 0.7955\n",
      "Update: Best val acc/loss: 0.795455/2.630548\n",
      "Epoch 3/50 lr:0.0000145  train loss: 3.3370 acc: 0.3343  val loss: 1.2152 acc: 0.9091\n",
      "Update: Best val acc/loss: 0.909091/1.215187\n",
      "Epoch 4/50 lr:0.0000221  train loss: 1.6793 acc: 0.6171  val loss: 2.3036 acc: 0.9091\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.5892 acc: 0.7057  val loss: 0.0241 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.024145\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.6027 acc: 0.8400  val loss: 0.0095 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.009463\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.9666 acc: 0.8514  val loss: 0.0832 acc: 0.9886\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.6879 acc: 0.8771  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.4188 acc: 0.9314  val loss: 0.0663 acc: 0.9886\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.3785 acc: 0.9571  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.4142 acc: 0.9143  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.2938 acc: 0.9371  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4479 acc: 0.9343  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.5006 acc: 0.9457  val loss: 0.3224 acc: 0.9886\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.1882 acc: 0.9600  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.1238 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.3986 acc: 0.9600  val loss: 0.0010 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.1840 acc: 0.9914  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.4282 acc: 0.9771  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.0788 acc: 0.9771  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1846 acc: 0.9857  val loss: 0.1461 acc: 0.9886\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1113 acc: 0.9714  val loss: 0.4907 acc: 0.9886\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3833 acc: 0.9514  val loss: 0.0007 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2099 acc: 0.9857  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.1664 acc: 0.9771  val loss: 0.6671 acc: 0.9773\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.3951 acc: 0.9857  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.2768 acc: 0.9800  val loss: 0.9709 acc: 0.9773\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.4548 acc: 0.9829  val loss: 0.0607 acc: 0.9886\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.2087 acc: 0.9857  val loss: 0.4599 acc: 0.9886\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0612 acc: 0.9943  val loss: 0.0013 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1595 acc: 0.9686  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1114 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0377 acc: 0.9857  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0215 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1014 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0019 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0913 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0084 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.2261 acc: 0.9686  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0113 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0838 acc: 0.9686  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0278 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0024 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0006 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0054 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0369 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0522 acc: 0.9800  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0363 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.1240 acc: 0.9714  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 45s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:40:22,941 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:40:22,971 dlcliche.utils create_model [INFO]:  using model weight: weights_capsule\n",
      "2020-04-18 15:40:22,972 dlcliche.utils add_good_samples [DEBUG]: Adding 219 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 15:42:21,103 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 15:43:35,996 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 15:43:36,081 dlcliche.utils add_good_samples [DEBUG]: Adding 280 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 6.076102197915652 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.05375274544632743 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.026488921822680332 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.07122696191072464\n",
      "Results: {'target': ['capsule'], 'auc': [0.8667730355005984], 'th_k_sigma': [6.076102197915652], 'th_fpr': [0.05375274544632743], 'th_tpr': [0.026488921822680332], 'norm_factor': [0.07122696191072464], 'pauc': [0.7419855982197217]}\n",
      "\n",
      "--- Start evaluating [carpet] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:44:45,943 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:44:45,943 dlcliche.utils create_datasets [DEBUG]: all train files: 280, val files: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.2578 acc: 0.0000  val loss: 14.2456 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.245643\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.0283 acc: 0.0000  val loss: 13.5070 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.506954\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.6297 acc: 0.0000  val loss: 12.5929 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.592921\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.2704 acc: 0.0000  val loss: 11.7695 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.769473\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.6710 acc: 0.0000  val loss: 11.1963 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.196250\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 12.2121 acc: 0.0000  val loss: 10.9866 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.986601\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.1506 acc: 0.0000  val loss: 10.3643 acc: 0.0179\n",
      "Update: Best val acc/loss: 0.017857/10.364340\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.6190 acc: 0.0000  val loss: 9.9363 acc: 0.0268\n",
      "Update: Best val acc/loss: 0.026786/9.936272\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 11.5723 acc: 0.0000  val loss: 10.0174 acc: 0.0089\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 11.5386 acc: 0.0000  val loss: 9.6869 acc: 0.0089\n",
      "Update: Best val acc/loss: 0.008929/9.686900\n",
      "Training complete in 0m 42s\n",
      "Best val Acc/Loss: 0.008929/9.686900\n",
      "Epoch 0/50 lr:0.0000040  train loss: 11.0092 acc: 0.0000  val loss: 8.4661 acc: 0.1250\n",
      "Update: Best val acc/loss: 0.125000/8.466058\n",
      "Epoch 1/50 lr:0.0000052  train loss: 10.0361 acc: 0.0089  val loss: 6.9116 acc: 0.1964\n",
      "Update: Best val acc/loss: 0.196429/6.911594\n",
      "Epoch 2/50 lr:0.0000088  train loss: 8.7725 acc: 0.0446  val loss: 5.0414 acc: 0.3125\n",
      "Update: Best val acc/loss: 0.312500/5.041429\n",
      "Epoch 3/50 lr:0.0000145  train loss: 6.9765 acc: 0.0871  val loss: 3.1771 acc: 0.4821\n",
      "Update: Best val acc/loss: 0.482143/3.177107\n",
      "Epoch 4/50 lr:0.0000221  train loss: 4.3944 acc: 0.2969  val loss: 1.2250 acc: 0.9196\n",
      "Update: Best val acc/loss: 0.919643/1.224982\n",
      "Epoch 5/50 lr:0.0000312  train loss: 2.2471 acc: 0.6116  val loss: 1.4088 acc: 0.9554\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.5523 acc: 0.6897  val loss: 0.3626 acc: 0.9911\n",
      "Update: Best val acc/loss: 0.991071/0.362614\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.9080 acc: 0.8415  val loss: 0.5989 acc: 0.9821\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.6715 acc: 0.9040  val loss: 0.3698 acc: 0.9911\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.7573 acc: 0.8884  val loss: 0.6968 acc: 0.9821\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.7161 acc: 0.9554  val loss: 0.4252 acc: 0.9821\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.7841 acc: 0.9129  val loss: 0.3633 acc: 0.9911\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.7292 acc: 0.9062  val loss: 0.4840 acc: 0.9732\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.5051 acc: 0.9487  val loss: 0.3993 acc: 0.9911\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.5167 acc: 0.9487  val loss: 0.3922 acc: 0.9911\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4880 acc: 0.9509  val loss: 1.0084 acc: 0.9732\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.3049 acc: 0.9866  val loss: 0.5397 acc: 0.9821\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.3343 acc: 0.9866  val loss: 0.7923 acc: 0.9821\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.4902 acc: 0.9554  val loss: 0.3768 acc: 0.9911\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.2464 acc: 0.9911  val loss: 0.3954 acc: 0.9911\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.1793 acc: 0.9866  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1843 acc: 0.9621  val loss: 0.7683 acc: 0.9821\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.2381 acc: 0.9799  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.2373 acc: 0.9799  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.0942 acc: 0.9955  val loss: 0.3902 acc: 0.9911\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.0923 acc: 0.9933  val loss: 0.8035 acc: 0.9821\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.2312 acc: 0.9911  val loss: 0.3967 acc: 0.9911\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1686 acc: 0.9888  val loss: 0.4048 acc: 0.9911\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0877 acc: 0.9933  val loss: 0.8036 acc: 0.9821\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1688 acc: 0.9933  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0029 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0811 acc: 0.9978  val loss: 0.4037 acc: 0.9911\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0091 acc: 0.9978  val loss: 0.4046 acc: 0.9911\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0020 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0023 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0082 acc: 0.9978  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.2340 acc: 0.9665  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0814 acc: 0.9978  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1454 acc: 0.9955  val loss: 0.3805 acc: 0.9911\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0752 acc: 0.9978  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0626 acc: 0.9978  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0067 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0110 acc: 0.9978  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0855 acc: 0.9933  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.1189 acc: 0.9821  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1574 acc: 0.9955  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0901 acc: 0.9933  val loss: 0.3952 acc: 0.9911\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0046 acc: 0.9978  val loss: 0.3795 acc: 0.9911\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0181 acc: 0.9978  val loss: 0.4024 acc: 0.9911\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.1292 acc: 0.9866  val loss: 0.3732 acc: 0.9911\n",
      "Training complete in 3m 32s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:49:00,899 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:49:00,931 dlcliche.utils create_model [INFO]:  using model weight: weights_carpet\n",
      "2020-04-18 15:49:00,931 dlcliche.utils add_good_samples [DEBUG]: Adding 280 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 15:50:04,760 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 15:50:31,381 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 15:50:31,513 dlcliche.utils add_good_samples [DEBUG]: Adding 264 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.934571186447983 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.18156856006728714 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.07202839096633033 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.1832418292760849\n",
      "Results: {'target': ['carpet'], 'auc': [0.9137239165329053], 'th_k_sigma': [2.934571186447983], 'th_fpr': [0.18156856006728714], 'th_tpr': [0.07202839096633033], 'norm_factor': [0.1832418292760849], 'pauc': [0.9053814311058546]}\n",
      "\n",
      "--- Start evaluating [grid] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:51:24,266 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:51:24,266 dlcliche.utils create_datasets [DEBUG]: all train files: 264, val files: 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.1545 acc: 0.0000  val loss: 14.4291 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.429123\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.9588 acc: 0.0000  val loss: 13.5500 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.550039\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.6388 acc: 0.0000  val loss: 12.2845 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.284477\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.8736 acc: 0.0000  val loss: 11.6861 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.686133\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.3870 acc: 0.0000  val loss: 10.9818 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.981756\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 11.8461 acc: 0.0000  val loss: 9.7847 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.784714\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 11.3388 acc: 0.0000  val loss: 9.2987 acc: 0.0283\n",
      "Update: Best val acc/loss: 0.028302/9.298661\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.2605 acc: 0.0000  val loss: 8.8391 acc: 0.0849\n",
      "Update: Best val acc/loss: 0.084906/8.839094\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 10.9040 acc: 0.0000  val loss: 8.7154 acc: 0.0660\n",
      "Update: Best val acc/loss: 0.066038/8.715431\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 10.8313 acc: 0.0000  val loss: 8.7117 acc: 0.0377\n",
      "Update: Best val acc/loss: 0.037736/8.711674\n",
      "Training complete in 0m 28s\n",
      "Best val Acc/Loss: 0.037736/8.711674\n",
      "Epoch 0/50 lr:0.0000040  train loss: 10.5499 acc: 0.0000  val loss: 6.9093 acc: 0.1698\n",
      "Update: Best val acc/loss: 0.169811/6.909256\n",
      "Epoch 1/50 lr:0.0000052  train loss: 9.1080 acc: 0.0071  val loss: 5.9321 acc: 0.2075\n",
      "Update: Best val acc/loss: 0.207547/5.932115\n",
      "Epoch 2/50 lr:0.0000088  train loss: 7.3987 acc: 0.0450  val loss: 3.7666 acc: 0.3679\n",
      "Update: Best val acc/loss: 0.367925/3.766635\n",
      "Epoch 3/50 lr:0.0000145  train loss: 5.4496 acc: 0.1043  val loss: 1.4130 acc: 0.6887\n",
      "Update: Best val acc/loss: 0.688679/1.413002\n",
      "Epoch 4/50 lr:0.0000221  train loss: 2.8123 acc: 0.3294  val loss: 0.3323 acc: 0.9717\n",
      "Update: Best val acc/loss: 0.971698/0.332256\n",
      "Epoch 5/50 lr:0.0000312  train loss: 2.3346 acc: 0.5284  val loss: 0.3583 acc: 0.9906\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.9204 acc: 0.8009  val loss: 0.0366 acc: 0.9906\n",
      "Update: Best val acc/loss: 0.990566/0.036568\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.2861 acc: 0.9171  val loss: 0.1543 acc: 0.9811\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.3571 acc: 0.9171  val loss: 0.0047 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.004729\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.5176 acc: 0.8957  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000005\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.3123 acc: 0.9289  val loss: 0.0105 acc: 0.9906\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.6533 acc: 0.8957  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000002\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.6266 acc: 0.9123  val loss: 0.4269 acc: 0.9906\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4075 acc: 0.9194  val loss: 0.0091 acc: 0.9906\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.1484 acc: 0.9692  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.0352 acc: 0.9882  val loss: 0.4337 acc: 0.9906\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.0631 acc: 0.9810  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.1038 acc: 0.9929  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.0670 acc: 0.9810  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.1476 acc: 0.9645  val loss: 0.4185 acc: 0.9906\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.1763 acc: 0.9692  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2425 acc: 0.9550  val loss: 0.4314 acc: 0.9906\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1308 acc: 0.9834  val loss: 0.4277 acc: 0.9906\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3782 acc: 0.9810  val loss: 0.4356 acc: 0.9906\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2271 acc: 0.9905  val loss: 0.4321 acc: 0.9906\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.2889 acc: 0.9787  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.3985 acc: 0.9431  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1267 acc: 0.9834  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.1731 acc: 0.9929  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1044 acc: 0.9716  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0578 acc: 0.9834  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0774 acc: 0.9763  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1535 acc: 0.9810  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0956 acc: 0.9716  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.2063 acc: 0.9834  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1569 acc: 0.9858  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0323 acc: 0.9905  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0011 acc: 1.0000  val loss: 0.4359 acc: 0.9906\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0517 acc: 0.9858  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0755 acc: 0.9763  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0111 acc: 0.9976  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0790 acc: 0.9976  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0292 acc: 0.9929  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1616 acc: 0.9763  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0026 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0662 acc: 0.9858  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0225 acc: 0.9905  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.2697 acc: 0.9645  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0355 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0658 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 51s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:54:43,120 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:54:43,150 dlcliche.utils create_model [INFO]:  using model weight: weights_grid\n",
      "2020-04-18 15:54:43,151 dlcliche.utils add_good_samples [DEBUG]: Adding 264 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 15:55:40,144 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 15:55:56,536 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 15:55:56,620 dlcliche.utils add_good_samples [DEBUG]: Adding 391 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 6.167544686650942 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.11172415385659591 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.029333395775425576 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.06904641538858414\n",
      "Results: {'target': ['grid'], 'auc': [0.6817042606516291], 'th_k_sigma': [6.167544686650942], 'th_fpr': [0.11172415385659591], 'th_tpr': [0.029333395775425576], 'norm_factor': [0.06904641538858414], 'pauc': [0.6240601503759399]}\n",
      "\n",
      "--- Start evaluating [hazelnut] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 15:59:24,447 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 15:59:24,447 dlcliche.utils create_datasets [DEBUG]: all train files: 391, val files: 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.1513 acc: 0.0000  val loss: 14.1543 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.154301\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.8999 acc: 0.0000  val loss: 13.2180 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.217984\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.1194 acc: 0.0000  val loss: 11.5990 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.599037\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.4463 acc: 0.0000  val loss: 10.3263 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.326329\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.6990 acc: 0.0000  val loss: 9.2709 acc: 0.0190\n",
      "Update: Best val acc/loss: 0.018987/9.270936\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 10.9712 acc: 0.0016  val loss: 8.1091 acc: 0.0696\n",
      "Update: Best val acc/loss: 0.069620/8.109128\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.4919 acc: 0.0032  val loss: 6.8096 acc: 0.1013\n",
      "Update: Best val acc/loss: 0.101266/6.809629\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 9.8413 acc: 0.0144  val loss: 7.0716 acc: 0.1013\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 10.0150 acc: 0.0112  val loss: 6.7149 acc: 0.1392\n",
      "Update: Best val acc/loss: 0.139241/6.714924\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.5633 acc: 0.0160  val loss: 7.0663 acc: 0.1519\n",
      "Training complete in 0m 44s\n",
      "Best val Acc/Loss: 0.139241/6.714924\n",
      "Epoch 0/50 lr:0.0000040  train loss: 9.0014 acc: 0.0337  val loss: 4.9290 acc: 0.3481\n",
      "Update: Best val acc/loss: 0.348101/4.928988\n",
      "Epoch 1/50 lr:0.0000052  train loss: 7.1351 acc: 0.0881  val loss: 3.8735 acc: 0.5949\n",
      "Update: Best val acc/loss: 0.594937/3.873508\n",
      "Epoch 2/50 lr:0.0000088  train loss: 5.3099 acc: 0.2404  val loss: 1.9186 acc: 0.7785\n",
      "Update: Best val acc/loss: 0.778481/1.918630\n",
      "Epoch 3/50 lr:0.0000145  train loss: 3.4577 acc: 0.4599  val loss: 0.9809 acc: 0.9114\n",
      "Update: Best val acc/loss: 0.911392/0.980919\n",
      "Epoch 4/50 lr:0.0000221  train loss: 2.1956 acc: 0.6843  val loss: 0.9125 acc: 0.9557\n",
      "Update: Best val acc/loss: 0.955696/0.912456\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.3426 acc: 0.8301  val loss: 0.5122 acc: 0.9684\n",
      "Update: Best val acc/loss: 0.968354/0.512188\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.8897 acc: 0.8814  val loss: 0.0523 acc: 0.9937\n",
      "Update: Best val acc/loss: 0.993671/0.052334\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.8540 acc: 0.9295  val loss: 0.2716 acc: 0.9873\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.9955 acc: 0.8798  val loss: 0.7952 acc: 0.9747\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.5295 acc: 0.9423  val loss: 0.5600 acc: 0.9873\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.3902 acc: 0.9583  val loss: 0.7133 acc: 0.9747\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.3957 acc: 0.9631  val loss: 0.5716 acc: 0.9873\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.6614 acc: 0.9551  val loss: 0.1375 acc: 0.9873\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.7628 acc: 0.9647  val loss: 0.2817 acc: 0.9937\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.3605 acc: 0.9776  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.8765 acc: 0.9647  val loss: 0.6401 acc: 0.9810\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2446 acc: 0.9824  val loss: 0.0216 acc: 0.9937\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.4602 acc: 0.9599  val loss: 1.3656 acc: 0.9620\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.8499 acc: 0.9535  val loss: 0.5899 acc: 0.9810\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.7110 acc: 0.9567  val loss: 0.4917 acc: 0.9873\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.3239 acc: 0.9696  val loss: 0.2533 acc: 0.9937\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.6224 acc: 0.9551  val loss: 0.0094 acc: 0.9937\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.5573 acc: 0.9599  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3652 acc: 0.9728  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.3287 acc: 0.9856  val loss: 0.8993 acc: 0.9747\n",
      "Epoch 25/50 lr:0.0000776  train loss: 1.0463 acc: 0.9375  val loss: 0.5232 acc: 0.9873\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.5353 acc: 0.9776  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.5316 acc: 0.9696  val loss: 0.0806 acc: 0.9937\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.2327 acc: 0.9776  val loss: 0.5372 acc: 0.9873\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.2548 acc: 0.9728  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0752 acc: 0.9936  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1517 acc: 0.9888  val loss: 0.2751 acc: 0.9937\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1991 acc: 0.9888  val loss: 0.4230 acc: 0.9873\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.2833 acc: 0.9856  val loss: 0.1937 acc: 0.9937\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0783 acc: 0.9968  val loss: 0.8274 acc: 0.9810\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.2362 acc: 0.9888  val loss: 0.2525 acc: 0.9937\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0970 acc: 0.9968  val loss: 0.2913 acc: 0.9873\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1346 acc: 0.9904  val loss: 0.2377 acc: 0.9937\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0581 acc: 0.9984  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1339 acc: 0.9888  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1109 acc: 0.9936  val loss: 0.2391 acc: 0.9937\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.2139 acc: 0.9760  val loss: 0.2416 acc: 0.9937\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.1540 acc: 0.9808  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1547 acc: 0.9952  val loss: 0.2530 acc: 0.9937\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.2426 acc: 0.9792  val loss: 0.2634 acc: 0.9937\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1403 acc: 0.9904  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0991 acc: 0.9888  val loss: 0.4402 acc: 0.9873\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0944 acc: 0.9968  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0590 acc: 0.9984  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2778 acc: 0.9904  val loss: 0.2764 acc: 0.9937\n",
      "Training complete in 4m 4s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:04:13,576 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:04:13,606 dlcliche.utils create_model [INFO]:  using model weight: weights_hazelnut\n",
      "2020-04-18 16:04:13,606 dlcliche.utils add_good_samples [DEBUG]: Adding 391 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:07:45,995 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:08:45,558 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:08:45,676 dlcliche.utils add_good_samples [DEBUG]: Adding 245 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.6335652814791217 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.04198270392174005 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.02369660978046619 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.1719777137041092\n",
      "Results: {'target': ['hazelnut'], 'auc': [0.9807142857142856], 'th_k_sigma': [3.6335652814791217], 'th_fpr': [0.04198270392174005], 'th_tpr': [0.02369660978046619], 'norm_factor': [0.1719777137041092], 'pauc': [0.9642857142857144]}\n",
      "\n",
      "--- Start evaluating [leather] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:10:43,167 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:10:43,168 dlcliche.utils create_datasets [DEBUG]: all train files: 245, val files: 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.0054 acc: 0.0000  val loss: 14.1037 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.103747\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.9332 acc: 0.0000  val loss: 13.3581 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.358073\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.2262 acc: 0.0000  val loss: 11.7647 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.764732\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.8161 acc: 0.0000  val loss: 10.6490 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.649031\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.2779 acc: 0.0000  val loss: 9.4569 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.456864\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 11.4989 acc: 0.0000  val loss: 9.7486 acc: 0.0204\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 11.2380 acc: 0.0000  val loss: 8.6083 acc: 0.0918\n",
      "Update: Best val acc/loss: 0.091837/8.608341\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 10.7383 acc: 0.0000  val loss: 7.5069 acc: 0.1122\n",
      "Update: Best val acc/loss: 0.112245/7.506928\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 10.7650 acc: 0.0000  val loss: 8.2334 acc: 0.1020\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 10.4598 acc: 0.0026  val loss: 7.9930 acc: 0.1020\n",
      "Training complete in 0m 31s\n",
      "Best val Acc/Loss: 0.112245/7.506928\n",
      "Epoch 0/50 lr:0.0000040  train loss: 10.2079 acc: 0.0051  val loss: 6.3914 acc: 0.2245\n",
      "Update: Best val acc/loss: 0.224490/6.391400\n",
      "Epoch 1/50 lr:0.0000052  train loss: 8.6049 acc: 0.0332  val loss: 5.7018 acc: 0.2551\n",
      "Update: Best val acc/loss: 0.255102/5.701808\n",
      "Epoch 2/50 lr:0.0000088  train loss: 7.0071 acc: 0.0587  val loss: 2.8526 acc: 0.5102\n",
      "Update: Best val acc/loss: 0.510204/2.852560\n",
      "Epoch 3/50 lr:0.0000145  train loss: 5.2854 acc: 0.2041  val loss: 2.0937 acc: 0.7347\n",
      "Update: Best val acc/loss: 0.734694/2.093689\n",
      "Epoch 4/50 lr:0.0000221  train loss: 3.0479 acc: 0.3827  val loss: 0.7613 acc: 0.9694\n",
      "Update: Best val acc/loss: 0.969388/0.761257\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.4294 acc: 0.6735  val loss: 0.5733 acc: 0.9694\n",
      "Update: Best val acc/loss: 0.969388/0.573263\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.3156 acc: 0.7628  val loss: 0.0078 acc: 0.9898\n",
      "Update: Best val acc/loss: 0.989796/0.007753\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.0731 acc: 0.8444  val loss: 0.1821 acc: 0.9898\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.6613 acc: 0.9031  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.7394 acc: 0.9005  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.5192 acc: 0.9388  val loss: 0.2498 acc: 0.9898\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.2257 acc: 0.9592  val loss: 0.0570 acc: 0.9898\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.3570 acc: 0.9541  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.1236 acc: 0.9566  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.3045 acc: 0.9413  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.1436 acc: 0.9719  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2445 acc: 0.9566  val loss: 0.4642 acc: 0.9898\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2867 acc: 0.9617  val loss: 0.0021 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2321 acc: 0.9617  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.2288 acc: 0.9821  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.0370 acc: 0.9898  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.0454 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.0079 acc: 0.9974  val loss: 0.4636 acc: 0.9898\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.0023 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.0166 acc: 0.9923  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.0013 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.0226 acc: 0.9923  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.0291 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.4944 acc: 0.9821  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.0045 acc: 1.0000  val loss: 0.3046 acc: 0.9898\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0033 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0284 acc: 0.9847  val loss: 0.8878 acc: 0.9796\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1382 acc: 0.9694  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0267 acc: 0.9923  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0381 acc: 0.9872  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0038 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1017 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0974 acc: 0.9847  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1046 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1201 acc: 0.9923  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0013 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.3126 acc: 0.9388  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0008 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.2730 acc: 0.9643  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0604 acc: 0.9872  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0932 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1055 acc: 0.9923  val loss: 0.4353 acc: 0.9898\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1279 acc: 0.9745  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1498 acc: 0.9949  val loss: 0.0076 acc: 0.9898\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0914 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 3m 4s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:14:18,372 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:14:18,403 dlcliche.utils create_model [INFO]:  using model weight: weights_leather\n",
      "2020-04-18 16:14:18,404 dlcliche.utils add_good_samples [DEBUG]: Adding 245 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:16:20,075 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:17:14,902 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:17:15,007 dlcliche.utils add_good_samples [DEBUG]: Adding 220 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.3096546087997 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.06462402997056463 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.037974342488143575 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.4535038471221924\n",
      "Results: {'target': ['leather'], 'auc': [0.9976222826086957], 'th_k_sigma': [2.3096546087997], 'th_fpr': [0.06462402997056463], 'th_tpr': [0.037974342488143575], 'norm_factor': [0.4535038471221924], 'pauc': [0.994279176201373]}\n",
      "\n",
      "--- Start evaluating [metal_nut] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:17:53,850 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:17:53,850 dlcliche.utils create_datasets [DEBUG]: all train files: 220, val files: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.1473 acc: 0.0000  val loss: 14.0294 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.029447\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.1735 acc: 0.0000  val loss: 13.6259 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.625906\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.9702 acc: 0.0000  val loss: 13.1420 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.141962\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.4439 acc: 0.0000  val loss: 12.3958 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.395804\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.1093 acc: 0.0000  val loss: 12.3840 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.383969\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.0058 acc: 0.0000  val loss: 11.5947 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.594729\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.8393 acc: 0.0000  val loss: 11.4064 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.406396\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 12.4295 acc: 0.0000  val loss: 10.9989 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.998902\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 12.4882 acc: 0.0000  val loss: 11.6733 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 12.4516 acc: 0.0000  val loss: 11.1143 acc: 0.0000\n",
      "Training complete in 0m 17s\n",
      "Best val Acc/Loss: 0.000000/10.998902\n",
      "Epoch 0/50 lr:0.0000040  train loss: 12.4506 acc: 0.0000  val loss: 10.4174 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.417362\n",
      "Epoch 1/50 lr:0.0000052  train loss: 11.9772 acc: 0.0000  val loss: 9.6752 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.675177\n",
      "Epoch 2/50 lr:0.0000088  train loss: 10.9534 acc: 0.0000  val loss: 7.2708 acc: 0.0227\n",
      "Update: Best val acc/loss: 0.022727/7.270814\n",
      "Epoch 3/50 lr:0.0000145  train loss: 8.9202 acc: 0.0000  val loss: 3.4569 acc: 0.4659\n",
      "Update: Best val acc/loss: 0.465909/3.456857\n",
      "Epoch 4/50 lr:0.0000221  train loss: 6.3733 acc: 0.0966  val loss: 1.9651 acc: 0.7841\n",
      "Update: Best val acc/loss: 0.784091/1.965110\n",
      "Epoch 5/50 lr:0.0000312  train loss: 3.2789 acc: 0.4233  val loss: 1.8325 acc: 0.9205\n",
      "Update: Best val acc/loss: 0.920455/1.832481\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.3441 acc: 0.7301  val loss: 1.1262 acc: 0.9432\n",
      "Update: Best val acc/loss: 0.943182/1.126226\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.9216 acc: 0.8778  val loss: 0.4805 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.480510\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.3080 acc: 0.7869  val loss: 0.4582 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.458190\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.6074 acc: 0.9034  val loss: 0.4434 acc: 0.9773\n",
      "Update: Best val acc/loss: 0.977273/0.443421\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.7120 acc: 0.9460  val loss: 1.3776 acc: 0.9545\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.6650 acc: 0.9517  val loss: 0.4962 acc: 0.9886\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.6613 acc: 0.9489  val loss: 0.4612 acc: 0.9886\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.6207 acc: 0.9119  val loss: 0.4789 acc: 0.9886\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.6463 acc: 0.9489  val loss: 0.4779 acc: 0.9886\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.9807 acc: 0.9517  val loss: 0.9917 acc: 0.9773\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.6203 acc: 0.9602  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2182 acc: 0.9716  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.5445 acc: 0.9688  val loss: 0.3585 acc: 0.9886\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.6905 acc: 0.9716  val loss: 0.4769 acc: 0.9886\n",
      "Epoch 20/50 lr:0.0000929  train loss: 1.0039 acc: 0.9602  val loss: 0.4781 acc: 0.9886\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.4368 acc: 0.9574  val loss: 0.5174 acc: 0.9886\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.2973 acc: 0.9716  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.5095 acc: 0.9773  val loss: 0.4912 acc: 0.9886\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.3846 acc: 0.9858  val loss: 0.5128 acc: 0.9886\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.1131 acc: 0.9801  val loss: 0.5145 acc: 0.9886\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.2746 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.4449 acc: 0.9801  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.2668 acc: 0.9915  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1481 acc: 0.9830  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.3290 acc: 0.9716  val loss: 0.4777 acc: 0.9886\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.4242 acc: 0.9744  val loss: 0.5125 acc: 0.9886\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.2974 acc: 0.9801  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.2988 acc: 0.9915  val loss: 0.5093 acc: 0.9886\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.2956 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.4402 acc: 0.9659  val loss: 0.5017 acc: 0.9886\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0349 acc: 0.9972  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1415 acc: 0.9915  val loss: 0.6038 acc: 0.9773\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.2056 acc: 0.9915  val loss: 0.5078 acc: 0.9886\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1990 acc: 0.9943  val loss: 0.1721 acc: 0.9886\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.2168 acc: 0.9773  val loss: 0.5066 acc: 0.9886\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.1235 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.5530 acc: 0.9460  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0713 acc: 0.9972  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.3002 acc: 0.9915  val loss: 0.5110 acc: 0.9886\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.2107 acc: 0.9915  val loss: 0.7153 acc: 0.9773\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0953 acc: 0.9972  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1878 acc: 0.9688  val loss: 0.9726 acc: 0.9773\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.3073 acc: 0.9886  val loss: 0.4709 acc: 0.9886\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2267 acc: 0.9773  val loss: 0.5005 acc: 0.9886\n",
      "Training complete in 2m 10s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:20:21,044 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:20:21,075 dlcliche.utils create_model [INFO]:  using model weight: weights_metal_nut\n",
      "2020-04-18 16:20:21,075 dlcliche.utils add_good_samples [DEBUG]: Adding 220 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:21:00,108 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:21:20,252 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:21:20,312 dlcliche.utils add_good_samples [DEBUG]: Adding 267 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 5.5543905622011485 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.09561496297921054 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.06408626523404602 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.07160414755344391\n",
      "Results: {'target': ['metal_nut'], 'auc': [0.8831867057673509], 'th_k_sigma': [5.5543905622011485], 'th_fpr': [0.09561496297921054], 'th_tpr': [0.06408626523404602], 'norm_factor': [0.07160414755344391], 'pauc': [0.8127283016926481]}\n",
      "\n",
      "--- Start evaluating [pill] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:22:37,152 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:22:37,153 dlcliche.utils create_datasets [DEBUG]: all train files: 267, val files: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.1177 acc: 0.0000  val loss: 14.3811 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.381118\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.7593 acc: 0.0000  val loss: 12.9753 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.975331\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 12.9464 acc: 0.0000  val loss: 11.1543 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.154254\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 11.8625 acc: 0.0000  val loss: 9.8193 acc: 0.0093\n",
      "Update: Best val acc/loss: 0.009259/9.819254\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.4046 acc: 0.0000  val loss: 8.5730 acc: 0.0278\n",
      "Update: Best val acc/loss: 0.027778/8.572998\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 10.3314 acc: 0.0000  val loss: 7.4218 acc: 0.0833\n",
      "Update: Best val acc/loss: 0.083333/7.421818\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 9.7551 acc: 0.0000  val loss: 6.6925 acc: 0.1481\n",
      "Update: Best val acc/loss: 0.148148/6.692475\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 9.4493 acc: 0.0047  val loss: 6.2042 acc: 0.1944\n",
      "Update: Best val acc/loss: 0.194444/6.204230\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 9.2054 acc: 0.0023  val loss: 6.6103 acc: 0.1296\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.2212 acc: 0.0094  val loss: 6.4378 acc: 0.1667\n",
      "Training complete in 0m 22s\n",
      "Best val Acc/Loss: 0.194444/6.204230\n",
      "Epoch 0/50 lr:0.0000040  train loss: 8.6543 acc: 0.0211  val loss: 4.5175 acc: 0.3796\n",
      "Update: Best val acc/loss: 0.379630/4.517466\n",
      "Epoch 1/50 lr:0.0000052  train loss: 6.5689 acc: 0.0962  val loss: 3.0828 acc: 0.6574\n",
      "Update: Best val acc/loss: 0.657407/3.082831\n",
      "Epoch 2/50 lr:0.0000088  train loss: 4.8389 acc: 0.2582  val loss: 1.1516 acc: 0.8241\n",
      "Update: Best val acc/loss: 0.824074/1.151631\n",
      "Epoch 3/50 lr:0.0000145  train loss: 2.9661 acc: 0.4883  val loss: 0.9321 acc: 0.9537\n",
      "Update: Best val acc/loss: 0.953704/0.932091\n",
      "Epoch 4/50 lr:0.0000221  train loss: 1.6492 acc: 0.7277  val loss: 0.3686 acc: 0.9815\n",
      "Update: Best val acc/loss: 0.981481/0.368550\n",
      "Epoch 5/50 lr:0.0000312  train loss: 0.9986 acc: 0.8192  val loss: 0.3861 acc: 0.9630\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.9620 acc: 0.8521  val loss: 0.0222 acc: 0.9907\n",
      "Update: Best val acc/loss: 0.990741/0.022230\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.7034 acc: 0.8685  val loss: 0.3971 acc: 0.9907\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.3633 acc: 0.9296  val loss: 0.0966 acc: 0.9907\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.4043 acc: 0.9366  val loss: 0.0231 acc: 0.9907\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.2472 acc: 0.9507  val loss: 0.4214 acc: 0.9907\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.1971 acc: 0.9836  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000028\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.0888 acc: 0.9883  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.3050 acc: 0.9554  val loss: 0.3011 acc: 0.9907\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.8475 acc: 0.9178  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4708 acc: 0.9155  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.0839 acc: 0.9883  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2711 acc: 0.9695  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.0065 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.5699 acc: 0.9671  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.7227 acc: 0.9765  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2336 acc: 0.9695  val loss: 0.4157 acc: 0.9907\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.3967 acc: 0.9695  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3639 acc: 0.9836  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2538 acc: 0.9836  val loss: 0.4126 acc: 0.9907\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.1429 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1213 acc: 0.9765  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.0122 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0080 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.0786 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0018 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0353 acc: 0.9859  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0451 acc: 0.9883  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1345 acc: 0.9789  val loss: 0.4264 acc: 0.9907\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0005 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0017 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0008 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0015 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0004 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0881 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0011 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0018 acc: 1.0000  val loss: 0.3881 acc: 0.9907\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0017 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1355 acc: 0.9765  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0028 acc: 0.9977  val loss: 0.0986 acc: 0.9907\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0064 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0004 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0034 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0502 acc: 0.9906  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0834 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 40s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:25:39,943 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:25:39,973 dlcliche.utils create_model [INFO]:  using model weight: weights_pill\n",
      "2020-04-18 16:25:39,974 dlcliche.utils add_good_samples [DEBUG]: Adding 267 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:26:58,176 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:27:47,666 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:27:47,740 dlcliche.utils add_good_samples [DEBUG]: Adding 320 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 5.225254296951892 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.04548631592214175 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.0292454623286801 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.10995451360940933\n",
      "Results: {'target': ['pill'], 'auc': [0.8025095471903982], 'th_k_sigma': [5.225254296951892], 'th_fpr': [0.04548631592214175], 'th_tpr': [0.0292454623286801], 'norm_factor': [0.10995451360940933], 'pauc': [0.7464610790478652]}\n",
      "\n",
      "--- Start evaluating [screw] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:28:53,412 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:28:53,412 dlcliche.utils create_datasets [DEBUG]: all train files: 320, val files: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.1580 acc: 0.0000  val loss: 14.1498 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.149800\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.6741 acc: 0.0000  val loss: 12.5289 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.528943\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 12.5513 acc: 0.0000  val loss: 10.5486 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.548617\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 11.4589 acc: 0.0000  val loss: 8.3794 acc: 0.0156\n",
      "Update: Best val acc/loss: 0.015625/8.379398\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 10.5624 acc: 0.0000  val loss: 7.4244 acc: 0.0547\n",
      "Update: Best val acc/loss: 0.054688/7.424417\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 9.5369 acc: 0.0059  val loss: 5.8041 acc: 0.1953\n",
      "Update: Best val acc/loss: 0.195312/5.804080\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 8.9370 acc: 0.0176  val loss: 5.2260 acc: 0.2578\n",
      "Update: Best val acc/loss: 0.257812/5.225983\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 8.2160 acc: 0.0352  val loss: 5.1488 acc: 0.2969\n",
      "Update: Best val acc/loss: 0.296875/5.148785\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 7.7692 acc: 0.0273  val loss: 5.0514 acc: 0.2422\n",
      "Update: Best val acc/loss: 0.242188/5.051442\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 8.1476 acc: 0.0449  val loss: 5.1560 acc: 0.3203\n",
      "Training complete in 0m 29s\n",
      "Best val Acc/Loss: 0.242188/5.051442\n",
      "Epoch 0/50 lr:0.0000040  train loss: 7.4283 acc: 0.0684  val loss: 3.7886 acc: 0.5078\n",
      "Update: Best val acc/loss: 0.507812/3.788631\n",
      "Epoch 1/50 lr:0.0000052  train loss: 5.8547 acc: 0.1641  val loss: 2.2537 acc: 0.7422\n",
      "Update: Best val acc/loss: 0.742188/2.253741\n",
      "Epoch 2/50 lr:0.0000088  train loss: 4.0296 acc: 0.3496  val loss: 1.7651 acc: 0.8828\n",
      "Update: Best val acc/loss: 0.882812/1.765052\n",
      "Epoch 3/50 lr:0.0000145  train loss: 2.5728 acc: 0.5410  val loss: 1.0429 acc: 0.9453\n",
      "Update: Best val acc/loss: 0.945312/1.042904\n",
      "Epoch 4/50 lr:0.0000221  train loss: 1.3186 acc: 0.7188  val loss: 0.6249 acc: 0.9531\n",
      "Update: Best val acc/loss: 0.953125/0.624949\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.1070 acc: 0.7617  val loss: 0.3187 acc: 0.9922\n",
      "Update: Best val acc/loss: 0.992188/0.318709\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.7036 acc: 0.8535  val loss: 0.4047 acc: 0.9844\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.3169 acc: 0.9180  val loss: 0.3168 acc: 0.9922\n",
      "Update: Best val acc/loss: 0.992188/0.316809\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.3170 acc: 0.9434  val loss: 0.3538 acc: 0.9844\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.3222 acc: 0.9512  val loss: 0.1412 acc: 0.9844\n",
      "Update: Best val acc/loss: 0.984375/0.141246\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.3809 acc: 0.9570  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.0862 acc: 0.9727  val loss: 0.3644 acc: 0.9922\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.2734 acc: 0.9609  val loss: 0.3630 acc: 0.9922\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4456 acc: 0.9551  val loss: 0.2075 acc: 0.9922\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.2611 acc: 0.9727  val loss: 0.3588 acc: 0.9922\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.2526 acc: 0.9824  val loss: 0.7481 acc: 0.9766\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.3525 acc: 0.9746  val loss: 0.3343 acc: 0.9922\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.4976 acc: 0.9570  val loss: 0.3671 acc: 0.9922\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.1065 acc: 0.9805  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.0767 acc: 0.9941  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2567 acc: 0.9746  val loss: 0.3688 acc: 0.9922\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1193 acc: 0.9844  val loss: 0.4862 acc: 0.9766\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.3728 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.2834 acc: 0.9902  val loss: 0.3658 acc: 0.9922\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.0773 acc: 0.9980  val loss: 0.3658 acc: 0.9922\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.1608 acc: 0.9805  val loss: 0.4713 acc: 0.9844\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.2804 acc: 0.9629  val loss: 0.4590 acc: 0.9844\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.0497 acc: 0.9883  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0730 acc: 0.9980  val loss: 0.4739 acc: 0.9844\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1871 acc: 0.9746  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1797 acc: 0.9746  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0799 acc: 0.9961  val loss: 0.5013 acc: 0.9844\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0306 acc: 0.9922  val loss: 0.3716 acc: 0.9922\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0024 acc: 1.0000  val loss: 0.4285 acc: 0.9844\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.3125 acc: 0.9688  val loss: 0.5277 acc: 0.9844\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0100 acc: 0.9961  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0012 acc: 1.0000  val loss: 0.3645 acc: 0.9922\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1120 acc: 0.9844  val loss: 0.3589 acc: 0.9922\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0007 acc: 1.0000  val loss: 0.4459 acc: 0.9844\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0276 acc: 0.9941  val loss: 0.2521 acc: 0.9922\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0006 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0013 acc: 1.0000  val loss: 0.3668 acc: 0.9922\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0013 acc: 1.0000  val loss: 0.5223 acc: 0.9844\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0027 acc: 0.9980  val loss: 0.3790 acc: 0.9844\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0005 acc: 1.0000  val loss: 0.1977 acc: 0.9922\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0679 acc: 0.9980  val loss: 0.4245 acc: 0.9844\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0047 acc: 0.9980  val loss: 0.1773 acc: 0.9922\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0105 acc: 0.9961  val loss: 0.2522 acc: 0.9922\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0573 acc: 0.9980  val loss: 0.3626 acc: 0.9922\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.1396 acc: 0.9961  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 3m 12s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:32:33,959 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:32:33,990 dlcliche.utils create_model [INFO]:  using model weight: weights_screw\n",
      "2020-04-18 16:32:33,991 dlcliche.utils add_good_samples [DEBUG]: Adding 320 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:33:44,864 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:34:18,687 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:34:18,768 dlcliche.utils add_good_samples [DEBUG]: Adding 230 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.295150175885656 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 1.0393802772236427 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.39812673023313655 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.005785499233752489\n",
      "Results: {'target': ['screw'], 'auc': [0.5310514449682312], 'th_k_sigma': [3.295150175885656], 'th_fpr': [1.0393802772236427], 'th_tpr': [0.39812673023313655], 'norm_factor': [0.005785499233752489], 'pauc': [0.528268303470297]}\n",
      "\n",
      "--- Start evaluating [tile] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:35:25,266 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:35:25,267 dlcliche.utils create_datasets [DEBUG]: all train files: 230, val files: 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.2663 acc: 0.0000  val loss: 14.1880 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.187993\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.1307 acc: 0.0000  val loss: 14.0223 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.022313\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.7680 acc: 0.0000  val loss: 12.7370 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.737041\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.3152 acc: 0.0000  val loss: 11.9789 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.978876\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.7794 acc: 0.0000  val loss: 11.5107 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.510660\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 12.4667 acc: 0.0000  val loss: 10.6996 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.699595\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.1885 acc: 0.0000  val loss: 10.2754 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.275438\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.8709 acc: 0.0000  val loss: 9.5985 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.598542\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 11.9399 acc: 0.0000  val loss: 10.1421 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 11.8111 acc: 0.0000  val loss: 10.0892 acc: 0.0000\n",
      "Training complete in 0m 22s\n",
      "Best val Acc/Loss: 0.000000/9.598542\n",
      "Epoch 0/50 lr:0.0000040  train loss: 11.3745 acc: 0.0000  val loss: 8.5540 acc: 0.0109\n",
      "Update: Best val acc/loss: 0.010870/8.554033\n",
      "Epoch 1/50 lr:0.0000052  train loss: 10.5020 acc: 0.0000  val loss: 7.6057 acc: 0.1196\n",
      "Update: Best val acc/loss: 0.119565/7.605738\n",
      "Epoch 2/50 lr:0.0000088  train loss: 9.2793 acc: 0.0027  val loss: 4.9306 acc: 0.2717\n",
      "Update: Best val acc/loss: 0.271739/4.930550\n",
      "Epoch 3/50 lr:0.0000145  train loss: 7.4272 acc: 0.0462  val loss: 2.8875 acc: 0.4239\n",
      "Update: Best val acc/loss: 0.423913/2.887542\n",
      "Epoch 4/50 lr:0.0000221  train loss: 5.1697 acc: 0.1576  val loss: 1.7860 acc: 0.8696\n",
      "Update: Best val acc/loss: 0.869565/1.786008\n",
      "Epoch 5/50 lr:0.0000312  train loss: 3.0020 acc: 0.4837  val loss: 0.9996 acc: 0.9457\n",
      "Update: Best val acc/loss: 0.945652/0.999562\n",
      "Epoch 6/50 lr:0.0000413  train loss: 2.2226 acc: 0.6386  val loss: 1.2358 acc: 0.9348\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.3007 acc: 0.8071  val loss: 0.1618 acc: 0.9783\n",
      "Update: Best val acc/loss: 0.978261/0.161837\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.9010 acc: 0.8723  val loss: 1.2609 acc: 0.9565\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.8731 acc: 0.9049  val loss: 0.4082 acc: 0.9674\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.8062 acc: 0.8940  val loss: 1.2208 acc: 0.9674\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.4738 acc: 0.9457  val loss: 0.3497 acc: 0.9891\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.4694 acc: 0.9647  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.2649 acc: 0.9755  val loss: 0.0050 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.6137 acc: 0.9266  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.2645 acc: 0.9755  val loss: 0.1881 acc: 0.9891\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.9196 acc: 0.9429  val loss: 0.4378 acc: 0.9891\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2378 acc: 0.9864  val loss: 0.4778 acc: 0.9891\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2389 acc: 0.9728  val loss: 0.4746 acc: 0.9891\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.1308 acc: 0.9891  val loss: 0.5267 acc: 0.9783\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.6546 acc: 0.9239  val loss: 0.4657 acc: 0.9891\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1558 acc: 0.9837  val loss: 0.0271 acc: 0.9891\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.3659 acc: 0.9647  val loss: 0.9049 acc: 0.9783\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.1551 acc: 0.9701  val loss: 0.9257 acc: 0.9783\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.1556 acc: 0.9783  val loss: 0.4766 acc: 0.9891\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.2073 acc: 0.9755  val loss: 0.4809 acc: 0.9891\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1649 acc: 0.9946  val loss: 0.5778 acc: 0.9783\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1298 acc: 0.9891  val loss: 0.4810 acc: 0.9891\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.2200 acc: 0.9810  val loss: 0.4782 acc: 0.9891\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.3987 acc: 0.9429  val loss: 0.4836 acc: 0.9891\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0979 acc: 0.9973  val loss: 0.4875 acc: 0.9891\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1683 acc: 0.9755  val loss: 0.4774 acc: 0.9891\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1355 acc: 0.9837  val loss: 0.7712 acc: 0.9783\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1041 acc: 0.9946  val loss: 0.4809 acc: 0.9891\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.2561 acc: 0.9783  val loss: 0.4610 acc: 0.9891\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0984 acc: 0.9946  val loss: 0.8972 acc: 0.9783\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.2814 acc: 0.9837  val loss: 1.3671 acc: 0.9565\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1220 acc: 0.9837  val loss: 0.7549 acc: 0.9783\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1274 acc: 0.9946  val loss: 0.4878 acc: 0.9891\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1988 acc: 0.9864  val loss: 0.8465 acc: 0.9783\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1187 acc: 0.9946  val loss: 0.5120 acc: 0.9783\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0966 acc: 0.9973  val loss: 1.3714 acc: 0.9674\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.2133 acc: 0.9810  val loss: 0.4783 acc: 0.9891\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1851 acc: 0.9946  val loss: 0.6760 acc: 0.9783\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0972 acc: 0.9973  val loss: 0.4848 acc: 0.9891\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1051 acc: 0.9973  val loss: 0.3144 acc: 0.9891\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1856 acc: 0.9946  val loss: 1.4729 acc: 0.9565\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1436 acc: 0.9783  val loss: 0.4653 acc: 0.9891\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0997 acc: 0.9946  val loss: 0.7204 acc: 0.9783\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.1465 acc: 0.9837  val loss: 0.4740 acc: 0.9891\n",
      "Training complete in 3m 24s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:39:12,764 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:39:12,811 dlcliche.utils create_model [INFO]:  using model weight: weights_tile\n",
      "2020-04-18 16:39:12,812 dlcliche.utils add_good_samples [DEBUG]: Adding 230 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:40:26,784 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:41:04,826 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:41:04,914 dlcliche.utils add_good_samples [DEBUG]: Adding 60 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.5671908982131257 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.17902637302253685 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.08194676608867354 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.09285235404968262\n",
      "Results: {'target': ['tile'], 'auc': [0.939033189033189], 'th_k_sigma': [3.5671908982131257], 'th_fpr': [0.17902637302253685], 'th_tpr': [0.08194676608867354], 'norm_factor': [0.09285235404968262], 'pauc': [0.8465861623756361]}\n",
      "\n",
      "--- Start evaluating [toothbrush] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:41:35,203 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:41:35,204 dlcliche.utils create_datasets [DEBUG]: all train files: 60, val files: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3892 acc: 0.0000  val loss: 14.1749 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.174866\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.2789 acc: 0.0000  val loss: 14.0873 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.087252\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.7484 acc: 0.0000  val loss: 14.3344 acc: 0.0000\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 14.1548 acc: 0.0000  val loss: 13.9273 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.927321\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 14.2567 acc: 0.0000  val loss: 13.7872 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.787169\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.7921 acc: 0.0000  val loss: 13.6993 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.699323\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 13.7605 acc: 0.0000  val loss: 13.7007 acc: 0.0000\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 13.6658 acc: 0.0000  val loss: 13.6410 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.641023\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 13.7439 acc: 0.0000  val loss: 13.5539 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.553940\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 13.9453 acc: 0.0000  val loss: 13.4476 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.447571\n",
      "Training complete in 0m 18s\n",
      "Best val Acc/Loss: 0.000000/13.447571\n",
      "Epoch 0/50 lr:0.0000040  train loss: 13.5346 acc: 0.0000  val loss: 13.6176 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.617632\n",
      "Epoch 1/50 lr:0.0000052  train loss: 13.2944 acc: 0.0000  val loss: 13.4719 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.471937\n",
      "Epoch 2/50 lr:0.0000088  train loss: 13.6667 acc: 0.0000  val loss: 13.5033 acc: 0.0000\n",
      "Epoch 3/50 lr:0.0000145  train loss: 13.3487 acc: 0.0000  val loss: 13.1827 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.182750\n",
      "Epoch 4/50 lr:0.0000221  train loss: 12.7900 acc: 0.0000  val loss: 12.8115 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.811481\n",
      "Epoch 5/50 lr:0.0000312  train loss: 11.9425 acc: 0.0000  val loss: 12.0558 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.055779\n",
      "Epoch 6/50 lr:0.0000413  train loss: 11.2826 acc: 0.0000  val loss: 10.3512 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.351224\n",
      "Epoch 7/50 lr:0.0000520  train loss: 9.8029 acc: 0.0000  val loss: 7.9692 acc: 0.0417\n",
      "Update: Best val acc/loss: 0.041667/7.969232\n",
      "Epoch 8/50 lr:0.0000627  train loss: 8.6512 acc: 0.0000  val loss: 6.4906 acc: 0.2083\n",
      "Update: Best val acc/loss: 0.208333/6.490612\n",
      "Epoch 9/50 lr:0.0000728  train loss: 6.2643 acc: 0.0312  val loss: 4.6097 acc: 0.3750\n",
      "Update: Best val acc/loss: 0.375000/4.609686\n",
      "Epoch 10/50 lr:0.0000819  train loss: 3.8486 acc: 0.3542  val loss: 2.6820 acc: 0.7500\n",
      "Update: Best val acc/loss: 0.750000/2.682041\n",
      "Epoch 11/50 lr:0.0000895  train loss: 2.7338 acc: 0.5104  val loss: 1.5741 acc: 0.8750\n",
      "Update: Best val acc/loss: 0.875000/1.574140\n",
      "Epoch 12/50 lr:0.0000952  train loss: 1.5773 acc: 0.7604  val loss: 1.5794 acc: 0.9583\n",
      "Epoch 13/50 lr:0.0000988  train loss: 1.5293 acc: 0.8125  val loss: 1.6976 acc: 0.9583\n",
      "Epoch 14/50 lr:0.0001000  train loss: 1.1497 acc: 0.8958  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000003\n",
      "Epoch 15/50 lr:0.0000998  train loss: 1.6158 acc: 0.8750  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000002\n",
      "Epoch 16/50 lr:0.0000992  train loss: 1.2769 acc: 0.9062  val loss: 1.0290 acc: 0.9583\n",
      "Epoch 17/50 lr:0.0000982  train loss: 1.5013 acc: 0.8125  val loss: 1.3337 acc: 0.9583\n",
      "Epoch 18/50 lr:0.0000968  train loss: 2.7334 acc: 0.7292  val loss: 1.1393 acc: 0.9583\n",
      "Epoch 19/50 lr:0.0000951  train loss: 1.4008 acc: 0.8854  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 1.0473 acc: 0.9271  val loss: 1.1093 acc: 0.9583\n",
      "Epoch 21/50 lr:0.0000905  train loss: 1.1833 acc: 0.8958  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 22/50 lr:0.0000877  train loss: 1.2526 acc: 0.8958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.5894 acc: 0.7812  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 24/50 lr:0.0000812  train loss: 1.5730 acc: 0.9167  val loss: 1.0956 acc: 0.9583\n",
      "Epoch 25/50 lr:0.0000776  train loss: 2.2762 acc: 0.8750  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 2.0320 acc: 0.8646  val loss: 1.5012 acc: 0.9583\n",
      "Epoch 27/50 lr:0.0000697  train loss: 1.6007 acc: 0.9375  val loss: 2.0464 acc: 0.9167\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.7584 acc: 0.9375  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.9853 acc: 0.9479  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.9071 acc: 0.9271  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.8707 acc: 0.9583  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.7941 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.4909 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 1.0071 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.7131 acc: 0.9792  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 1.2853 acc: 0.8646  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.7039 acc: 0.8333  val loss: 1.4775 acc: 0.9583\n",
      "Epoch 38/50 lr:0.0000225  train loss: 1.1539 acc: 0.9167  val loss: 1.4663 acc: 0.9167\n",
      "Epoch 39/50 lr:0.0000189  train loss: 1.2184 acc: 0.9271  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.4301 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 1.9236 acc: 0.8542  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 1.8462 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 1.2075 acc: 0.9583  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.8321 acc: 0.9583  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.8659 acc: 0.9583  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.5879 acc: 0.9792  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.7119 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.7246 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 1.5025 acc: 0.8542  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 59s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:43:53,418 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:43:53,612 dlcliche.utils create_model [INFO]:  using model weight: weights_toothbrush\n",
      "2020-04-18 16:43:53,613 dlcliche.utils add_good_samples [DEBUG]: Adding 60 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:44:24,669 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:44:46,007 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:44:46,053 dlcliche.utils add_good_samples [DEBUG]: Adding 213 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 4.540639983366754 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.11252679316666837 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.06333913614083456 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.09919029474258423\n",
      "Results: {'target': ['toothbrush'], 'auc': [0.8416666666666667], 'th_k_sigma': [4.540639983366754], 'th_fpr': [0.11252679316666837], 'th_tpr': [0.06333913614083456], 'norm_factor': [0.09919029474258423], 'pauc': [0.7923976608187134]}\n",
      "\n",
      "--- Start evaluating [transistor] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:46:44,537 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:46:44,537 dlcliche.utils create_datasets [DEBUG]: all train files: 213, val files: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.2884 acc: 0.0000  val loss: 14.2428 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.242842\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.1461 acc: 0.0000  val loss: 13.7343 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.734318\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.8440 acc: 0.0000  val loss: 13.1027 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.102689\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.4223 acc: 0.0000  val loss: 12.7835 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.783458\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.0639 acc: 0.0000  val loss: 12.4635 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.463529\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.0046 acc: 0.0000  val loss: 11.6688 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.668810\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.7832 acc: 0.0000  val loss: 11.4446 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.444569\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 12.6736 acc: 0.0000  val loss: 11.4411 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.441123\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 12.6483 acc: 0.0000  val loss: 11.4804 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 12.4074 acc: 0.0000  val loss: 11.2567 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.256721\n",
      "Training complete in 0m 28s\n",
      "Best val Acc/Loss: 0.000000/11.256721\n",
      "Epoch 0/50 lr:0.0000040  train loss: 12.4561 acc: 0.0000  val loss: 10.2446 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.244624\n",
      "Epoch 1/50 lr:0.0000052  train loss: 11.7864 acc: 0.0000  val loss: 9.3873 acc: 0.0116\n",
      "Update: Best val acc/loss: 0.011628/9.387321\n",
      "Epoch 2/50 lr:0.0000088  train loss: 11.1108 acc: 0.0000  val loss: 7.4138 acc: 0.1395\n",
      "Update: Best val acc/loss: 0.139535/7.413781\n",
      "Epoch 3/50 lr:0.0000145  train loss: 9.8091 acc: 0.0147  val loss: 6.2059 acc: 0.2442\n",
      "Update: Best val acc/loss: 0.244186/6.205893\n",
      "Epoch 4/50 lr:0.0000221  train loss: 7.8007 acc: 0.0647  val loss: 4.4512 acc: 0.5465\n",
      "Update: Best val acc/loss: 0.546512/4.451153\n",
      "Epoch 5/50 lr:0.0000312  train loss: 5.1754 acc: 0.2294  val loss: 2.9208 acc: 0.7209\n",
      "Update: Best val acc/loss: 0.720930/2.920777\n",
      "Epoch 6/50 lr:0.0000413  train loss: 2.9434 acc: 0.5412  val loss: 1.7994 acc: 0.9070\n",
      "Update: Best val acc/loss: 0.906977/1.799358\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.8500 acc: 0.7059  val loss: 1.1426 acc: 0.9419\n",
      "Update: Best val acc/loss: 0.941860/1.142586\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.1616 acc: 0.8353  val loss: 0.2876 acc: 0.9767\n",
      "Update: Best val acc/loss: 0.976744/0.287565\n",
      "Epoch 9/50 lr:0.0000728  train loss: 1.4944 acc: 0.8147  val loss: 0.8491 acc: 0.9535\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.6101 acc: 0.9382  val loss: 0.4933 acc: 0.9767\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.4734 acc: 0.9353  val loss: 0.0900 acc: 0.9884\n",
      "Update: Best val acc/loss: 0.988372/0.090049\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.8211 acc: 0.9176  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000002\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4352 acc: 0.9588  val loss: 0.1642 acc: 0.9767\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.4520 acc: 0.9206  val loss: 0.4540 acc: 0.9767\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4441 acc: 0.9500  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2069 acc: 0.9500  val loss: 0.4575 acc: 0.9884\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.6415 acc: 0.9118  val loss: 0.7260 acc: 0.9651\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.5466 acc: 0.9500  val loss: 0.7869 acc: 0.9767\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.5023 acc: 0.9412  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.5407 acc: 0.9500  val loss: 0.7165 acc: 0.9767\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.3960 acc: 0.9794  val loss: 0.4805 acc: 0.9884\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.9547 acc: 0.9441  val loss: 2.9188 acc: 0.9186\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.9864 acc: 0.9353  val loss: 2.2346 acc: 0.9419\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.5224 acc: 0.9824  val loss: 0.4006 acc: 0.9884\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.9329 acc: 0.9265  val loss: 0.5212 acc: 0.9884\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.4606 acc: 0.9588  val loss: 0.5157 acc: 0.9884\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.4653 acc: 0.9500  val loss: 0.2314 acc: 0.9884\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.4836 acc: 0.9529  val loss: 0.2621 acc: 0.9884\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.3509 acc: 0.9676  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0112 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1551 acc: 0.9882  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.3490 acc: 0.9735  val loss: 0.5018 acc: 0.9884\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.2080 acc: 0.9706  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.2714 acc: 0.9794  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0730 acc: 0.9853  val loss: 0.8526 acc: 0.9767\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1536 acc: 0.9853  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1628 acc: 0.9706  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.3048 acc: 0.9588  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.5270 acc: 0.9706  val loss: 0.5181 acc: 0.9884\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1712 acc: 0.9853  val loss: 0.5136 acc: 0.9884\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0366 acc: 0.9824  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.2104 acc: 0.9912  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0133 acc: 0.9912  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0075 acc: 0.9971  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.4655 acc: 0.9647  val loss: 0.3237 acc: 0.9884\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1164 acc: 0.9912  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1635 acc: 0.9706  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0097 acc: 0.9971  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.4611 acc: 0.9471  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 49s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:50:01,911 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:50:01,941 dlcliche.utils create_model [INFO]:  using model weight: weights_transistor\n",
      "2020-04-18 16:50:01,942 dlcliche.utils add_good_samples [DEBUG]: Adding 213 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:51:59,972 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 16:52:55,209 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 16:52:55,298 dlcliche.utils add_good_samples [DEBUG]: Adding 247 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 6.852715347981886 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.15939499988798644 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.09680894054695498 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.038744982331991196\n",
      "Results: {'target': ['transistor'], 'auc': [0.8574999999999999], 'th_k_sigma': [6.852715347981886], 'th_fpr': [0.15939499988798644], 'th_tpr': [0.09680894054695498], 'norm_factor': [0.038744982331991196], 'pauc': [0.7171052631578947]}\n",
      "\n",
      "--- Start evaluating [wood] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:54:30,120 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:54:30,121 dlcliche.utils create_datasets [DEBUG]: all train files: 247, val files: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3569 acc: 0.0000  val loss: 14.2461 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.246139\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.9704 acc: 0.0000  val loss: 14.1005 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.100511\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.8103 acc: 0.0000  val loss: 13.3171 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.317094\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.6898 acc: 0.0000  val loss: 12.9053 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.905296\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.1834 acc: 0.0000  val loss: 12.2534 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.253351\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.0638 acc: 0.0000  val loss: 11.8945 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.894457\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.7645 acc: 0.0000  val loss: 11.9862 acc: 0.0000\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 12.6709 acc: 0.0000  val loss: 11.3779 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.377860\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 12.5961 acc: 0.0000  val loss: 11.2863 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.286317\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 12.5659 acc: 0.0000  val loss: 11.7709 acc: 0.0000\n",
      "Training complete in 0m 32s\n",
      "Best val Acc/Loss: 0.000000/11.286317\n",
      "Epoch 0/50 lr:0.0000040  train loss: 12.4342 acc: 0.0000  val loss: 10.6222 acc: 0.0100\n",
      "Update: Best val acc/loss: 0.010000/10.622178\n",
      "Epoch 1/50 lr:0.0000052  train loss: 11.5252 acc: 0.0025  val loss: 9.3563 acc: 0.0800\n",
      "Update: Best val acc/loss: 0.080000/9.356290\n",
      "Epoch 2/50 lr:0.0000088  train loss: 10.5565 acc: 0.0000  val loss: 7.6524 acc: 0.2000\n",
      "Update: Best val acc/loss: 0.200000/7.652389\n",
      "Epoch 3/50 lr:0.0000145  train loss: 8.5569 acc: 0.0102  val loss: 4.7947 acc: 0.3200\n",
      "Update: Best val acc/loss: 0.320000/4.794725\n",
      "Epoch 4/50 lr:0.0000221  train loss: 6.0509 acc: 0.1117  val loss: 2.1180 acc: 0.6400\n",
      "Update: Best val acc/loss: 0.640000/2.117952\n",
      "Epoch 5/50 lr:0.0000312  train loss: 3.2061 acc: 0.3604  val loss: 0.4277 acc: 0.9600\n",
      "Update: Best val acc/loss: 0.960000/0.427706\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.9236 acc: 0.6675  val loss: 0.6388 acc: 0.9700\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.1355 acc: 0.7843  val loss: 0.3126 acc: 0.9800\n",
      "Update: Best val acc/loss: 0.980000/0.312630\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.5515 acc: 0.9162  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000017\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.3668 acc: 0.9492  val loss: 0.1771 acc: 0.9900\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.5778 acc: 0.9365  val loss: 0.3644 acc: 0.9900\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.5401 acc: 0.9518  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.3751 acc: 0.9162  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.3901 acc: 0.9543  val loss: 0.0035 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.4755 acc: 0.9467  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.1490 acc: 0.9822  val loss: 0.4501 acc: 0.9900\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2119 acc: 0.9695  val loss: 0.2751 acc: 0.9900\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2826 acc: 0.9391  val loss: 0.0452 acc: 0.9900\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.1977 acc: 0.9670  val loss: 0.4226 acc: 0.9900\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.3209 acc: 0.9695  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2485 acc: 0.9848  val loss: 0.4343 acc: 0.9900\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2878 acc: 0.9569  val loss: 0.7797 acc: 0.9800\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1991 acc: 0.9898  val loss: 0.4448 acc: 0.9900\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.1914 acc: 0.9848  val loss: 0.4517 acc: 0.9900\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.1174 acc: 0.9924  val loss: 0.1805 acc: 0.9900\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.2340 acc: 0.9797  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.0030 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.0945 acc: 0.9975  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.1571 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1171 acc: 0.9822  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1002 acc: 0.9746  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1591 acc: 0.9898  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0211 acc: 0.9924  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1005 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.3614 acc: 0.9898  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1367 acc: 0.9797  val loss: 0.8730 acc: 0.9800\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0943 acc: 0.9975  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0008 acc: 1.0000  val loss: 0.4569 acc: 0.9900\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1813 acc: 0.9924  val loss: 0.2105 acc: 0.9900\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1193 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0941 acc: 0.9975  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0430 acc: 0.9924  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0040 acc: 1.0000  val loss: 0.3223 acc: 0.9900\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0919 acc: 0.9975  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.2851 acc: 0.9848  val loss: 0.4514 acc: 0.9900\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.2011 acc: 0.9569  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.2642 acc: 0.9898  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.2196 acc: 0.9898  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0127 acc: 0.9975  val loss: 0.4547 acc: 0.9900\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2113 acc: 0.9772  val loss: 0.4528 acc: 0.9900\n",
      "Training complete in 3m 10s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 16:58:14,070 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 16:58:14,100 dlcliche.utils create_model [INFO]:  using model weight: weights_wood\n",
      "2020-04-18 16:58:14,101 dlcliche.utils add_good_samples [DEBUG]: Adding 247 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 16:59:51,104 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-18 17:00:22,804 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-18 17:00:22,908 dlcliche.utils add_good_samples [DEBUG]: Adding 240 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.485308100686296 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.038338448950576705 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.038338448950576705 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.4442233741283417\n",
      "Results: {'target': ['wood'], 'auc': [1.0], 'th_k_sigma': [2.485308100686296], 'th_fpr': [0.038338448950576705], 'th_tpr': [0.038338448950576705], 'norm_factor': [0.4442233741283417], 'pauc': [1.0]}\n",
      "\n",
      "--- Start evaluating [zipper] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 17:01:03,673 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 17:01:03,673 dlcliche.utils create_datasets [DEBUG]: all train files: 240, val files: 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.0921 acc: 0.0000  val loss: 14.4493 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.449297\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.8049 acc: 0.0000  val loss: 13.1067 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.106748\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 12.8719 acc: 0.0000  val loss: 11.0395 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.039465\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.2277 acc: 0.0000  val loss: 9.9861 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.986105\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.4715 acc: 0.0000  val loss: 8.5847 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.584676\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 10.3913 acc: 0.0000  val loss: 7.8040 acc: 0.0208\n",
      "Update: Best val acc/loss: 0.020833/7.804047\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 9.9752 acc: 0.0000  val loss: 7.2337 acc: 0.0833\n",
      "Update: Best val acc/loss: 0.083333/7.233749\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 9.4613 acc: 0.0026  val loss: 6.4853 acc: 0.1458\n",
      "Update: Best val acc/loss: 0.145833/6.485320\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 9.3930 acc: 0.0052  val loss: 6.1989 acc: 0.1354\n",
      "Update: Best val acc/loss: 0.135417/6.198870\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.2765 acc: 0.0156  val loss: 6.3032 acc: 0.2083\n",
      "Training complete in 0m 23s\n",
      "Best val Acc/Loss: 0.135417/6.198870\n",
      "Epoch 0/50 lr:0.0000040  train loss: 8.5854 acc: 0.0182  val loss: 4.6999 acc: 0.3542\n",
      "Update: Best val acc/loss: 0.354167/4.699874\n",
      "Epoch 1/50 lr:0.0000052  train loss: 6.8778 acc: 0.0365  val loss: 2.6965 acc: 0.5833\n",
      "Update: Best val acc/loss: 0.583333/2.696469\n",
      "Epoch 2/50 lr:0.0000088  train loss: 4.9258 acc: 0.1536  val loss: 1.0722 acc: 0.8542\n",
      "Update: Best val acc/loss: 0.854167/1.072163\n",
      "Epoch 3/50 lr:0.0000145  train loss: 2.8766 acc: 0.3672  val loss: 1.0604 acc: 0.9479\n",
      "Update: Best val acc/loss: 0.947917/1.060414\n",
      "Epoch 4/50 lr:0.0000221  train loss: 1.2393 acc: 0.6536  val loss: 0.2065 acc: 0.9792\n",
      "Update: Best val acc/loss: 0.979167/0.206491\n",
      "Epoch 5/50 lr:0.0000312  train loss: 0.8681 acc: 0.8177  val loss: 0.2238 acc: 0.9896\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.4546 acc: 0.9089  val loss: 0.0049 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.004938\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.6933 acc: 0.8880  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.4928 acc: 0.8750  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.1154 acc: 0.9557  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.4385 acc: 0.8932  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.3513 acc: 0.8984  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.1987 acc: 0.9557  val loss: 0.0081 acc: 0.9896\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.3700 acc: 0.9427  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.1025 acc: 0.9922  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.0564 acc: 0.9844  val loss: 0.4660 acc: 0.9896\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.3501 acc: 0.9427  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2004 acc: 0.9792  val loss: 0.4658 acc: 0.9896\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.0617 acc: 0.9974  val loss: 0.4754 acc: 0.9896\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.1734 acc: 0.9922  val loss: 0.4200 acc: 0.9896\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2375 acc: 0.9844  val loss: 0.4767 acc: 0.9896\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1483 acc: 0.9766  val loss: 0.4595 acc: 0.9896\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.2715 acc: 0.9922  val loss: 0.4791 acc: 0.9896\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.0360 acc: 0.9844  val loss: 0.0865 acc: 0.9896\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2730 acc: 0.9427  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.3436 acc: 0.9766  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.0135 acc: 0.9922  val loss: 0.4860 acc: 0.9896\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.0682 acc: 0.9870  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.1307 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.0339 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0809 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0025 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0006 acc: 1.0000  val loss: 0.4567 acc: 0.9896\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0379 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0336 acc: 0.9896  val loss: 0.4737 acc: 0.9896\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0075 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0004 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0319 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0843 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0254 acc: 0.9974  val loss: 0.3164 acc: 0.9896\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0012 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.1296 acc: 0.9818  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0033 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0778 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0055 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0005 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0007 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0009 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0080 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.1512 acc: 0.9740  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 39s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-18 17:04:06,014 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-18 17:04:06,045 dlcliche.utils create_model [INFO]:  using model weight: weights_zipper\n",
      "2020-04-18 17:04:06,045 dlcliche.utils add_good_samples [DEBUG]: Adding 240 good samples to tmp/mvtecad_anotwin/good.\n",
      "2020-04-18 17:04:50,775 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 7.417700337316825 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.3224921452573215 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.2266680075251947 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.02076306752860546\n",
      "Results: {'target': ['zipper'], 'auc': [0.9338235294117647], 'th_k_sigma': [7.417700337316825], 'th_fpr': [0.3224921452573215], 'th_tpr': [0.2266680075251947], 'norm_factor': [0.02076306752860546], 'pauc': [0.9026979212737727]}\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_MVTecAD(dataroot, anotwin.AnoTwinDet , params,\n",
    "                           #test_targets=['toothbrush']  # uncomment if you try only what you are interested\n",
    "                           #skip_file_creation=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>auc</th>\n",
       "      <th>th_k_sigma</th>\n",
       "      <th>th_fpr</th>\n",
       "      <th>th_tpr</th>\n",
       "      <th>norm_factor</th>\n",
       "      <th>pauc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottle</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.899007</td>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.293448</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cable</td>\n",
       "      <td>0.858883</td>\n",
       "      <td>5.917267</td>\n",
       "      <td>0.426354</td>\n",
       "      <td>0.188067</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.627555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capsule</td>\n",
       "      <td>0.866773</td>\n",
       "      <td>6.076102</td>\n",
       "      <td>0.053753</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>0.071227</td>\n",
       "      <td>0.741986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carpet</td>\n",
       "      <td>0.913724</td>\n",
       "      <td>2.934571</td>\n",
       "      <td>0.181569</td>\n",
       "      <td>0.072028</td>\n",
       "      <td>0.183242</td>\n",
       "      <td>0.905381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid</td>\n",
       "      <td>0.681704</td>\n",
       "      <td>6.167545</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.069046</td>\n",
       "      <td>0.624060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hazelnut</td>\n",
       "      <td>0.980714</td>\n",
       "      <td>3.633565</td>\n",
       "      <td>0.041983</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.171978</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leather</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>2.309655</td>\n",
       "      <td>0.064624</td>\n",
       "      <td>0.037974</td>\n",
       "      <td>0.453504</td>\n",
       "      <td>0.994279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metal_nut</td>\n",
       "      <td>0.883187</td>\n",
       "      <td>5.554391</td>\n",
       "      <td>0.095615</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.071604</td>\n",
       "      <td>0.812728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pill</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>5.225254</td>\n",
       "      <td>0.045486</td>\n",
       "      <td>0.029245</td>\n",
       "      <td>0.109955</td>\n",
       "      <td>0.746461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>screw</td>\n",
       "      <td>0.531051</td>\n",
       "      <td>3.295150</td>\n",
       "      <td>1.039380</td>\n",
       "      <td>0.398127</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.528268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tile</td>\n",
       "      <td>0.939033</td>\n",
       "      <td>3.567191</td>\n",
       "      <td>0.179026</td>\n",
       "      <td>0.081947</td>\n",
       "      <td>0.092852</td>\n",
       "      <td>0.846586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>toothbrush</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>4.540640</td>\n",
       "      <td>0.112527</td>\n",
       "      <td>0.063339</td>\n",
       "      <td>0.099190</td>\n",
       "      <td>0.792398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transistor</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>6.852715</td>\n",
       "      <td>0.159395</td>\n",
       "      <td>0.096809</td>\n",
       "      <td>0.038745</td>\n",
       "      <td>0.717105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wood</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.485308</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.444223</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zipper</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>7.417700</td>\n",
       "      <td>0.322492</td>\n",
       "      <td>0.226668</td>\n",
       "      <td>0.020763</td>\n",
       "      <td>0.902698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target       auc  th_k_sigma    th_fpr    th_tpr  norm_factor  \\\n",
       "0       bottle  1.000000    2.899007  0.026182  0.026182     0.293448   \n",
       "1        cable  0.858883    5.917267  0.426354  0.188067     0.031875   \n",
       "2      capsule  0.866773    6.076102  0.053753  0.026489     0.071227   \n",
       "3       carpet  0.913724    2.934571  0.181569  0.072028     0.183242   \n",
       "4         grid  0.681704    6.167545  0.111724  0.029333     0.069046   \n",
       "5     hazelnut  0.980714    3.633565  0.041983  0.023697     0.171978   \n",
       "6      leather  0.997622    2.309655  0.064624  0.037974     0.453504   \n",
       "7    metal_nut  0.883187    5.554391  0.095615  0.064086     0.071604   \n",
       "8         pill  0.802510    5.225254  0.045486  0.029245     0.109955   \n",
       "9        screw  0.531051    3.295150  1.039380  0.398127     0.005785   \n",
       "10        tile  0.939033    3.567191  0.179026  0.081947     0.092852   \n",
       "11  toothbrush  0.841667    4.540640  0.112527  0.063339     0.099190   \n",
       "12  transistor  0.857500    6.852715  0.159395  0.096809     0.038745   \n",
       "13        wood  1.000000    2.485308  0.038338  0.038338     0.444223   \n",
       "14      zipper  0.933824    7.417700  0.322492  0.226668     0.020763   \n",
       "\n",
       "        pauc  \n",
       "0   1.000000  \n",
       "1   0.627555  \n",
       "2   0.741986  \n",
       "3   0.905381  \n",
       "4   0.624060  \n",
       "5   0.964286  \n",
       "6   0.994279  \n",
       "7   0.812728  \n",
       "8   0.746461  \n",
       "9   0.528268  \n",
       "10  0.846586  \n",
       "11  0.792398  \n",
       "12  0.717105  \n",
       "13  1.000000  \n",
       "14  0.902698  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params.scheduler = 'OneCycleLR' 0.0001\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataroot = Path(dataroot)\n",
    "test_target = 'transistor'\n",
    "\n",
    "target_data = dataroot/test_target\n",
    "train_files = sorted(target_data.glob(f'train/good/*.png'))\n",
    "test_files = sorted(target_data.glob(f'test/*/*.png'))\n",
    "test_labels = [f.parent.name for f in test_files]\n",
    "test_y_trues = [label != 'good' for label in test_labels]\n",
    "\n",
    "det = anotwin.AnoTwinDet(params=params)\n",
    "det.prepare_experiment()\n",
    "det.setup_train(train_files)\n",
    "det.train_model(train_files)\n",
    "values = det.evaluate_test(test_files, test_y_trues)\n",
    "# auc, pauc, norm_threshs, norm_factor, scores, raw_scores = values\n",
    "\n",
    "det.visualize_after_eval(values, test_files, test_labels, test_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
