{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *\n",
    "\n",
    "sys.path.append('..')\n",
    "import anotwin\n",
    "from utils import *\n",
    "from utils.mvtecad import evaluate_MVTecAD\n",
    "\n",
    "dataroot = '/data/mvtec_ad/original'\n",
    "project = 'mvtecad_anotwin'\n",
    "\n",
    "params = EasyDict()\n",
    "params.project = project\n",
    "params.work_folder = 'tmp'\n",
    "params.valid_pct = 0.1\n",
    "params.suffix = '.png'\n",
    "params.n_mosts = 4\n",
    "params.load_size = 256\n",
    "params.crop_size = 224\n",
    "params.batch_size = 16\n",
    "params.n_epochs = 50\n",
    "params.workers = 12\n",
    "params.model = 'arc_face'\n",
    "params.backbone = 'resnet18'\n",
    "params.train_album_tfm = None\n",
    "params.train_tfm = None\n",
    "params.dataset_cls = anotwin.DefectOnBlobDataset\n",
    "params.val_ds_cls = anotwin.AsIsDataset\n",
    "params.logger=None\n",
    "params.lr = 0.0001\n",
    "params.lr_step = 10\n",
    "params.weight_decay = 0.95\n",
    "params.scheduler = 'OneCycleLR'\n",
    "#params.scheduler = 'CyclicLR'\n",
    "params.data = {}\n",
    "params.data.width_min = 1\n",
    "params.data.width_max = 10\n",
    "params.data.length_max = 40\n",
    "params.data.color = True\n",
    "params.data.pre_crop_rect = None\n",
    "params.max_fpr = 0.1\n",
    "params.min_tpr = 1.0\n",
    "params.sigma_k = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n",
      "\n",
      "--- Start evaluating [bottle] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:35:47,198 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:35:47,199 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:35:47,199 dlcliche.utils create_datasets [DEBUG]: all train files: 209, val files: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.4310 acc: 0.0000  val loss: 13.8502 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.850217\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.1296 acc: 0.0000  val loss: 13.2850 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.284991\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.2924 acc: 0.0000  val loss: 11.9195 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.919457\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.1763 acc: 0.0000  val loss: 10.5141 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.514068\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.3201 acc: 0.0000  val loss: 9.8962 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.896216\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 10.7771 acc: 0.0000  val loss: 8.5753 acc: 0.0238\n",
      "Update: Best val acc/loss: 0.023810/8.575315\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.2525 acc: 0.0027  val loss: 8.2493 acc: 0.0476\n",
      "Update: Best val acc/loss: 0.047619/8.249282\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 9.5599 acc: 0.0053  val loss: 6.9492 acc: 0.1190\n",
      "Update: Best val acc/loss: 0.119048/6.949245\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 9.6761 acc: 0.0106  val loss: 6.8638 acc: 0.0952\n",
      "Update: Best val acc/loss: 0.095238/6.863768\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.3459 acc: 0.0133  val loss: 6.8499 acc: 0.1429\n",
      "Update: Best val acc/loss: 0.142857/6.849924\n",
      "Training complete in 0m 8s\n",
      "Best val Acc/Loss: 0.142857/6.849924\n",
      "Epoch 0/50 lr:0.0000040  train loss: 9.2911 acc: 0.0160  val loss: 5.7097 acc: 0.2381\n",
      "Update: Best val acc/loss: 0.238095/5.709730\n",
      "Epoch 1/50 lr:0.0000052  train loss: 7.9622 acc: 0.0372  val loss: 4.4109 acc: 0.4762\n",
      "Update: Best val acc/loss: 0.476190/4.410903\n",
      "Epoch 2/50 lr:0.0000088  train loss: 6.5627 acc: 0.1064  val loss: 4.3123 acc: 0.5238\n",
      "Update: Best val acc/loss: 0.523810/4.312278\n",
      "Epoch 3/50 lr:0.0000145  train loss: 5.2125 acc: 0.2527  val loss: 3.6877 acc: 0.7143\n",
      "Update: Best val acc/loss: 0.714286/3.687671\n",
      "Epoch 4/50 lr:0.0000221  train loss: 4.0684 acc: 0.4309  val loss: 4.0506 acc: 0.7619\n",
      "Epoch 5/50 lr:0.0000312  train loss: 2.5384 acc: 0.6356  val loss: 1.8715 acc: 0.9048\n",
      "Update: Best val acc/loss: 0.904762/1.871465\n",
      "Epoch 6/50 lr:0.0000413  train loss: 2.1615 acc: 0.6303  val loss: 2.6022 acc: 0.9048\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.4640 acc: 0.8298  val loss: 1.6906 acc: 0.9286\n",
      "Update: Best val acc/loss: 0.928571/1.690631\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.3890 acc: 0.8511  val loss: 1.9054 acc: 0.9286\n",
      "Epoch 9/50 lr:0.0000728  train loss: 1.1798 acc: 0.8324  val loss: 0.7228 acc: 0.9762\n",
      "Update: Best val acc/loss: 0.976190/0.722844\n",
      "Epoch 10/50 lr:0.0000819  train loss: 1.0304 acc: 0.8644  val loss: 1.7524 acc: 0.9524\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.4607 acc: 0.9468  val loss: 0.8898 acc: 0.9762\n",
      "Epoch 12/50 lr:0.0000952  train loss: 1.0280 acc: 0.8697  val loss: 1.0491 acc: 0.9762\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.8018 acc: 0.9096  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000077\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.7118 acc: 0.9415  val loss: 1.4571 acc: 0.9524\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.6085 acc: 0.9096  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.4036 acc: 0.9309  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.4883 acc: 0.9495  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.3316 acc: 0.9681  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.4730 acc: 0.9601  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.3523 acc: 0.9681  val loss: 0.0482 acc: 0.9762\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1749 acc: 0.9654  val loss: 0.9638 acc: 0.9762\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1754 acc: 0.9654  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3139 acc: 0.9761  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.1483 acc: 0.9681  val loss: 0.6863 acc: 0.9762\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.2709 acc: 0.9734  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1633 acc: 0.9761  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1746 acc: 0.9920  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.6923 acc: 0.9229  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.3948 acc: 0.9521  val loss: 1.1107 acc: 0.9762\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.2086 acc: 0.9707  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1970 acc: 0.9734  val loss: 0.2492 acc: 0.9762\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1165 acc: 0.9894  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.2374 acc: 0.9495  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.1062 acc: 0.9787  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.2898 acc: 0.9628  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1578 acc: 0.9814  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1418 acc: 0.9734  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1667 acc: 0.9707  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0680 acc: 0.9894  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1458 acc: 0.9894  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.3988 acc: 0.9495  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.1564 acc: 0.9761  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0075 acc: 0.9973  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.1322 acc: 0.9894  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1019 acc: 0.9894  val loss: 1.1050 acc: 0.9762\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0643 acc: 0.9761  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1898 acc: 0.9761  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0465 acc: 0.9761  val loss: 0.4367 acc: 0.9762\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2312 acc: 0.9787  val loss: 1.1234 acc: 0.9762\n",
      "Training complete in 1m 13s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:37:08,640 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.4783809941265176 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.03909943106394428 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.03909943106394428 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.40141797065734863\n",
      "Results: {'target': ['bottle'], 'auc': [1.0], 'th_k_sigma': [2.4783809941265176], 'th_fpr': [0.03909943106394428], 'th_tpr': [0.03909943106394428], 'norm_factor': [0.40141797065734863], 'pauc': [1.0]}\n",
      "\n",
      "--- Start evaluating [cable] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:37:29,056 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:37:29,057 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:37:29,057 dlcliche.utils create_datasets [DEBUG]: all train files: 224, val files: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.5926 acc: 0.0000  val loss: 14.4349 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.434868\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.3382 acc: 0.0000  val loss: 14.1562 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.156219\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 14.2747 acc: 0.0000  val loss: 13.9116 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.911633\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.9900 acc: 0.0000  val loss: 13.6163 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.616288\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 14.1211 acc: 0.0000  val loss: 13.6156 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.615588\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.7903 acc: 0.0000  val loss: 13.3490 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.349019\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 13.6181 acc: 0.0000  val loss: 13.4549 acc: 0.0000\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 13.5243 acc: 0.0000  val loss: 13.4118 acc: 0.0000\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 13.4409 acc: 0.0000  val loss: 13.5359 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 13.4666 acc: 0.0000  val loss: 13.2981 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.298057\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.000000/13.298057\n",
      "Epoch 0/50 lr:0.0000040  train loss: 13.4667 acc: 0.0000  val loss: 13.0051 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.005136\n",
      "Epoch 1/50 lr:0.0000052  train loss: 13.3322 acc: 0.0000  val loss: 12.6816 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.681602\n",
      "Epoch 2/50 lr:0.0000088  train loss: 13.2441 acc: 0.0000  val loss: 12.2959 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.295929\n",
      "Epoch 3/50 lr:0.0000145  train loss: 13.0586 acc: 0.0000  val loss: 12.1044 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.104449\n",
      "Epoch 4/50 lr:0.0000221  train loss: 12.6493 acc: 0.0000  val loss: 11.8184 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.818419\n",
      "Epoch 5/50 lr:0.0000312  train loss: 12.1158 acc: 0.0000  val loss: 11.2434 acc: 0.0217\n",
      "Update: Best val acc/loss: 0.021739/11.243354\n",
      "Epoch 6/50 lr:0.0000413  train loss: 11.2543 acc: 0.0025  val loss: 10.1572 acc: 0.0652\n",
      "Update: Best val acc/loss: 0.065217/10.157191\n",
      "Epoch 7/50 lr:0.0000520  train loss: 10.0377 acc: 0.0124  val loss: 8.3109 acc: 0.2391\n",
      "Update: Best val acc/loss: 0.239130/8.310900\n",
      "Epoch 8/50 lr:0.0000627  train loss: 8.5465 acc: 0.0871  val loss: 7.8460 acc: 0.3043\n",
      "Update: Best val acc/loss: 0.304348/7.846009\n",
      "Epoch 9/50 lr:0.0000728  train loss: 6.5891 acc: 0.1965  val loss: 5.1187 acc: 0.4565\n",
      "Update: Best val acc/loss: 0.456522/5.118694\n",
      "Epoch 10/50 lr:0.0000819  train loss: 5.7547 acc: 0.4080  val loss: 4.9533 acc: 0.6739\n",
      "Update: Best val acc/loss: 0.673913/4.953349\n",
      "Epoch 11/50 lr:0.0000895  train loss: 4.0263 acc: 0.5697  val loss: 4.7960 acc: 0.7609\n",
      "Update: Best val acc/loss: 0.760870/4.796035\n",
      "Epoch 12/50 lr:0.0000952  train loss: 4.9255 acc: 0.5498  val loss: 4.5797 acc: 0.7174\n",
      "Update: Best val acc/loss: 0.717391/4.579692\n",
      "Epoch 13/50 lr:0.0000988  train loss: 4.7877 acc: 0.5995  val loss: 3.3089 acc: 0.7609\n",
      "Update: Best val acc/loss: 0.760870/3.308871\n",
      "Epoch 14/50 lr:0.0001000  train loss: 4.2634 acc: 0.6592  val loss: 4.4324 acc: 0.8478\n",
      "Epoch 15/50 lr:0.0000998  train loss: 4.2090 acc: 0.6144  val loss: 4.4764 acc: 0.8478\n",
      "Epoch 16/50 lr:0.0000992  train loss: 3.8060 acc: 0.6692  val loss: 4.5983 acc: 0.8696\n",
      "Epoch 17/50 lr:0.0000982  train loss: 3.6190 acc: 0.7015  val loss: 3.3549 acc: 0.8913\n",
      "Epoch 18/50 lr:0.0000968  train loss: 3.8185 acc: 0.7189  val loss: 3.5802 acc: 0.9130\n",
      "Epoch 19/50 lr:0.0000951  train loss: 3.1404 acc: 0.7736  val loss: 3.8322 acc: 0.8913\n",
      "Epoch 20/50 lr:0.0000929  train loss: 2.7678 acc: 0.7910  val loss: 3.7501 acc: 0.8696\n",
      "Epoch 21/50 lr:0.0000905  train loss: 2.6883 acc: 0.7761  val loss: 3.6608 acc: 0.8913\n",
      "Epoch 22/50 lr:0.0000877  train loss: 2.1495 acc: 0.8109  val loss: 3.7835 acc: 0.8913\n",
      "Epoch 23/50 lr:0.0000846  train loss: 2.1480 acc: 0.8483  val loss: 3.3036 acc: 0.8696\n",
      "Update: Best val acc/loss: 0.869565/3.303610\n",
      "Epoch 24/50 lr:0.0000812  train loss: 3.0762 acc: 0.7562  val loss: 3.2568 acc: 0.8913\n",
      "Update: Best val acc/loss: 0.891304/3.256775\n",
      "Epoch 25/50 lr:0.0000776  train loss: 1.9275 acc: 0.8458  val loss: 2.9321 acc: 0.8913\n",
      "Update: Best val acc/loss: 0.891304/2.932066\n",
      "Epoch 26/50 lr:0.0000737  train loss: 1.8559 acc: 0.8458  val loss: 3.2505 acc: 0.9130\n",
      "Epoch 27/50 lr:0.0000697  train loss: 2.1893 acc: 0.8483  val loss: 1.8250 acc: 0.9130\n",
      "Update: Best val acc/loss: 0.913043/1.825047\n",
      "Epoch 28/50 lr:0.0000655  train loss: 2.3433 acc: 0.8408  val loss: 1.0750 acc: 0.9565\n",
      "Update: Best val acc/loss: 0.956522/1.075010\n",
      "Epoch 29/50 lr:0.0000611  train loss: 2.0761 acc: 0.8433  val loss: 0.9158 acc: 0.9783\n",
      "Update: Best val acc/loss: 0.978261/0.915841\n",
      "Epoch 30/50 lr:0.0000567  train loss: 1.7852 acc: 0.8682  val loss: 1.4375 acc: 0.9565\n",
      "Epoch 31/50 lr:0.0000523  train loss: 1.5373 acc: 0.8731  val loss: 1.1063 acc: 0.9130\n",
      "Epoch 32/50 lr:0.0000478  train loss: 2.0797 acc: 0.8408  val loss: 0.9445 acc: 0.9783\n",
      "Epoch 33/50 lr:0.0000433  train loss: 1.8445 acc: 0.8557  val loss: 1.7715 acc: 0.9565\n",
      "Epoch 34/50 lr:0.0000389  train loss: 1.7265 acc: 0.8682  val loss: 1.7642 acc: 0.9565\n",
      "Epoch 35/50 lr:0.0000346  train loss: 2.1897 acc: 0.8284  val loss: 1.8600 acc: 0.9565\n",
      "Epoch 36/50 lr:0.0000304  train loss: 1.8022 acc: 0.8483  val loss: 1.2500 acc: 0.9348\n",
      "Epoch 37/50 lr:0.0000263  train loss: 1.8782 acc: 0.8557  val loss: 0.9146 acc: 0.9348\n",
      "Update: Best val acc/loss: 0.934783/0.914558\n",
      "Epoch 38/50 lr:0.0000225  train loss: 2.3285 acc: 0.8433  val loss: 1.8156 acc: 0.9348\n",
      "Epoch 39/50 lr:0.0000189  train loss: 2.0545 acc: 0.8433  val loss: 0.0336 acc: 0.9783\n",
      "Update: Best val acc/loss: 0.978261/0.033602\n",
      "Epoch 40/50 lr:0.0000155  train loss: 1.7307 acc: 0.8905  val loss: 1.1560 acc: 0.9565\n",
      "Epoch 41/50 lr:0.0000124  train loss: 1.7194 acc: 0.8856  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000006\n",
      "Epoch 42/50 lr:0.0000096  train loss: 1.3270 acc: 0.8781  val loss: 0.6612 acc: 0.9565\n",
      "Epoch 43/50 lr:0.0000071  train loss: 1.7371 acc: 0.8632  val loss: 0.3578 acc: 0.9783\n",
      "Epoch 44/50 lr:0.0000050  train loss: 1.6685 acc: 0.8905  val loss: 2.3859 acc: 0.9348\n",
      "Epoch 45/50 lr:0.0000032  train loss: 1.6490 acc: 0.8856  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000003\n",
      "Epoch 46/50 lr:0.0000018  train loss: 1.7723 acc: 0.8532  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 47/50 lr:0.0000008  train loss: 1.9668 acc: 0.8607  val loss: 0.0006 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 2.3257 acc: 0.8706  val loss: 0.9547 acc: 0.9783\n",
      "Epoch 49/50 lr:0.0000000  train loss: 1.7140 acc: 0.8632  val loss: 0.9552 acc: 0.9783\n",
      "Training complete in 1m 17s\n",
      "Best val Acc/Loss: 1.000000/0.000001\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:38:55,760 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.53237843242519 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.7229127910845128 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.47661799193727 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.08174382150173187\n",
      "Results: {'target': ['cable'], 'auc': [0.9374062968515743], 'th_k_sigma': [2.53237843242519], 'th_fpr': [0.7229127910845128], 'th_tpr': [0.47661799193727], 'norm_factor': [0.08174382150173187], 'pauc': [0.8613193403298351]}\n",
      "\n",
      "--- Start evaluating [capsule] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:39:18,885 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:39:18,885 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:39:18,886 dlcliche.utils create_datasets [DEBUG]: all train files: 219, val files: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 132\n",
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.4025 acc: 0.0000  val loss: 14.1737 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.173670\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.9212 acc: 0.0000  val loss: 12.9186 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.918628\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.0406 acc: 0.0000  val loss: 11.7366 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.736611\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.1035 acc: 0.0000  val loss: 10.3700 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.370007\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.2683 acc: 0.0000  val loss: 9.2796 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.279570\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 10.4913 acc: 0.0000  val loss: 8.2532 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.253241\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.1867 acc: 0.0025  val loss: 7.6468 acc: 0.1818\n",
      "Update: Best val acc/loss: 0.181818/7.646847\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 9.4525 acc: 0.0051  val loss: 7.2033 acc: 0.1364\n",
      "Update: Best val acc/loss: 0.136364/7.203266\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 9.0670 acc: 0.0051  val loss: 6.7566 acc: 0.1591\n",
      "Update: Best val acc/loss: 0.159091/6.756564\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.1028 acc: 0.0051  val loss: 8.0587 acc: 0.1591\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.159091/6.756564\n",
      "Epoch 0/50 lr:0.0000040  train loss: 8.5528 acc: 0.0102  val loss: 5.4926 acc: 0.3182\n",
      "Update: Best val acc/loss: 0.318182/5.492619\n",
      "Epoch 1/50 lr:0.0000052  train loss: 7.4941 acc: 0.0431  val loss: 4.6240 acc: 0.5000\n",
      "Update: Best val acc/loss: 0.500000/4.623991\n",
      "Epoch 2/50 lr:0.0000088  train loss: 5.7195 acc: 0.1447  val loss: 2.4236 acc: 0.6591\n",
      "Update: Best val acc/loss: 0.659091/2.423647\n",
      "Epoch 3/50 lr:0.0000145  train loss: 4.0388 acc: 0.3553  val loss: 2.2114 acc: 0.8182\n",
      "Update: Best val acc/loss: 0.818182/2.211419\n",
      "Epoch 4/50 lr:0.0000221  train loss: 2.5695 acc: 0.5406  val loss: 2.8056 acc: 0.8864\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.7540 acc: 0.7056  val loss: 1.2747 acc: 0.9318\n",
      "Update: Best val acc/loss: 0.931818/1.274655\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.9576 acc: 0.8299  val loss: 0.9371 acc: 0.9545\n",
      "Update: Best val acc/loss: 0.954545/0.937137\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.9402 acc: 0.8299  val loss: 1.7084 acc: 0.9545\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.8984 acc: 0.8503  val loss: 0.0008 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000798\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.5221 acc: 0.9036  val loss: 0.4274 acc: 0.9773\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.5264 acc: 0.9391  val loss: 0.7105 acc: 0.9773\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.9391 acc: 0.8503  val loss: 1.0153 acc: 0.9773\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.4681 acc: 0.9492  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4523 acc: 0.9670  val loss: 0.0002 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.2452 acc: 0.9721  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.3026 acc: 0.9467  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.1974 acc: 0.9492  val loss: 0.1716 acc: 0.9773\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.3513 acc: 0.9467  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.4573 acc: 0.9492  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.2989 acc: 0.9594  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.3076 acc: 0.9695  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.1420 acc: 0.9772  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1157 acc: 0.9822  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3553 acc: 0.9822  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2076 acc: 0.9569  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.3153 acc: 0.9645  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1641 acc: 0.9721  val loss: 0.0009 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1957 acc: 0.9695  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.1892 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1478 acc: 0.9594  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1488 acc: 0.9772  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0316 acc: 0.9949  val loss: 0.4676 acc: 0.9773\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0008 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1046 acc: 0.9695  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0163 acc: 0.9924  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1619 acc: 0.9670  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0022 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0799 acc: 0.9797  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1112 acc: 0.9822  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0918 acc: 0.9721  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1060 acc: 0.9873  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0384 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0585 acc: 0.9924  val loss: 0.0003 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0037 acc: 0.9975  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0508 acc: 0.9873  val loss: 0.1680 acc: 0.9773\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0558 acc: 0.9898  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0656 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1206 acc: 0.9695  val loss: 0.3069 acc: 0.9773\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1360 acc: 0.9721  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0370 acc: 0.9924  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 16s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:40:43,974 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 6.521822551929972 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.10254801982197427 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.06785692856414487 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.035326968878507614\n",
      "Results: {'target': ['capsule'], 'auc': [0.8855205424810529], 'th_k_sigma': [6.521822551929972], 'th_fpr': [0.10254801982197427], 'th_tpr': [0.06785692856414487], 'norm_factor': [0.035326968878507614], 'pauc': [0.7335880586988013]}\n",
      "\n",
      "--- Start evaluating [carpet] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:41:02,103 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:41:02,103 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:41:02,104 dlcliche.utils create_datasets [DEBUG]: all train files: 280, val files: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3386 acc: 0.0000  val loss: 14.0777 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.077739\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.0622 acc: 0.0000  val loss: 13.4863 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.486337\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.7424 acc: 0.0000  val loss: 12.6131 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.613145\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.1192 acc: 0.0000  val loss: 11.6826 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.682643\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.9415 acc: 0.0000  val loss: 11.3181 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.318119\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 12.3737 acc: 0.0000  val loss: 10.5601 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.560080\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 11.8177 acc: 0.0000  val loss: 10.1132 acc: 0.0179\n",
      "Update: Best val acc/loss: 0.017857/10.113185\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.5957 acc: 0.0000  val loss: 9.9243 acc: 0.0179\n",
      "Update: Best val acc/loss: 0.017857/9.924259\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 11.6363 acc: 0.0000  val loss: 9.4828 acc: 0.0357\n",
      "Update: Best val acc/loss: 0.035714/9.482785\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 11.4906 acc: 0.0000  val loss: 9.3826 acc: 0.0357\n",
      "Update: Best val acc/loss: 0.035714/9.382629\n",
      "Training complete in 0m 10s\n",
      "Best val Acc/Loss: 0.035714/9.382629\n",
      "Epoch 0/50 lr:0.0000040  train loss: 11.4123 acc: 0.0000  val loss: 7.9638 acc: 0.0536\n",
      "Update: Best val acc/loss: 0.053571/7.963777\n",
      "Epoch 1/50 lr:0.0000052  train loss: 10.3231 acc: 0.0040  val loss: 6.2377 acc: 0.2143\n",
      "Update: Best val acc/loss: 0.214286/6.237736\n",
      "Epoch 2/50 lr:0.0000088  train loss: 9.0820 acc: 0.0218  val loss: 5.4809 acc: 0.2679\n",
      "Update: Best val acc/loss: 0.267857/5.480898\n",
      "Epoch 3/50 lr:0.0000145  train loss: 7.2010 acc: 0.1052  val loss: 3.6756 acc: 0.6250\n",
      "Update: Best val acc/loss: 0.625000/3.675633\n",
      "Epoch 4/50 lr:0.0000221  train loss: 5.2840 acc: 0.2520  val loss: 2.5263 acc: 0.8036\n",
      "Update: Best val acc/loss: 0.803571/2.526315\n",
      "Epoch 5/50 lr:0.0000312  train loss: 3.1612 acc: 0.5615  val loss: 1.3696 acc: 0.9286\n",
      "Update: Best val acc/loss: 0.928571/1.369622\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.8443 acc: 0.7341  val loss: 0.8769 acc: 0.9643\n",
      "Update: Best val acc/loss: 0.964286/0.876934\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.4174 acc: 0.8433  val loss: 0.3995 acc: 0.9643\n",
      "Update: Best val acc/loss: 0.964286/0.399511\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.1765 acc: 0.8552  val loss: 0.8741 acc: 0.9643\n",
      "Epoch 9/50 lr:0.0000728  train loss: 1.2959 acc: 0.8690  val loss: 0.4694 acc: 0.9821\n",
      "Epoch 10/50 lr:0.0000819  train loss: 1.0011 acc: 0.8909  val loss: 0.8175 acc: 0.9821\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.6243 acc: 0.9524  val loss: 0.8002 acc: 0.9821\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.3959 acc: 0.9325  val loss: 0.8165 acc: 0.9821\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.5646 acc: 0.9286  val loss: 1.1688 acc: 0.9643\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.5266 acc: 0.9603  val loss: 0.7307 acc: 0.9821\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4196 acc: 0.9444  val loss: 0.7339 acc: 0.9821\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.5432 acc: 0.9544  val loss: 0.1720 acc: 0.9821\n",
      "Update: Best val acc/loss: 0.982143/0.171958\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.3644 acc: 0.9683  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000101\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2326 acc: 0.9821  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000015\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.0725 acc: 0.9782  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2717 acc: 0.9683  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2418 acc: 0.9643  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.2070 acc: 0.9702  val loss: 0.1863 acc: 0.9821\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.2086 acc: 0.9742  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.4402 acc: 0.9405  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.1465 acc: 0.9802  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1363 acc: 0.9643  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1726 acc: 0.9544  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.1549 acc: 0.9881  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1679 acc: 0.9821  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1266 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1697 acc: 0.9683  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0477 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0867 acc: 0.9901  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.1098 acc: 0.9881  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1306 acc: 0.9663  val loss: 0.8452 acc: 0.9821\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1544 acc: 0.9901  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1075 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1009 acc: 0.9881  val loss: 0.8420 acc: 0.9821\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.2557 acc: 0.9722  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0524 acc: 0.9921  val loss: 0.8483 acc: 0.9821\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.1014 acc: 0.9861  val loss: 0.8586 acc: 0.9821\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0085 acc: 1.0000  val loss: 0.8518 acc: 0.9821\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1430 acc: 0.9841  val loss: 0.8550 acc: 0.9821\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0216 acc: 0.9921  val loss: 0.8445 acc: 0.9821\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1894 acc: 0.9921  val loss: 0.8537 acc: 0.9821\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.2300 acc: 0.9762  val loss: 0.8514 acc: 0.9821\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0232 acc: 0.9940  val loss: 0.8484 acc: 0.9821\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1166 acc: 0.9782  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0547 acc: 0.9881  val loss: 0.8483 acc: 0.9821\n",
      "Training complete in 1m 31s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:42:43,395 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.1861020795577377 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.06639871365345007 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.0294332438842073 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.13854578137397766\n",
      "Results: {'target': ['carpet'], 'auc': [0.9293739967897271], 'th_k_sigma': [3.1861020795577377], 'th_fpr': [0.06639871365345007], 'th_tpr': [0.0294332438842073], 'norm_factor': [0.13854578137397766], 'pauc': [0.8867956407873616]}\n",
      "\n",
      "--- Start evaluating [grid] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:42:52,607 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:42:52,607 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:42:52,608 dlcliche.utils create_datasets [DEBUG]: all train files: 264, val files: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77 78\n",
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.2386 acc: 0.0000  val loss: 13.8483 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.848309\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.9895 acc: 0.0000  val loss: 13.5435 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.543500\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.4338 acc: 0.0000  val loss: 12.5471 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.547101\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.8165 acc: 0.0000  val loss: 11.4999 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.499855\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.3374 acc: 0.0000  val loss: 10.7560 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.756026\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 11.7323 acc: 0.0000  val loss: 9.9992 acc: 0.0185\n",
      "Update: Best val acc/loss: 0.018519/9.999219\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 11.1989 acc: 0.0000  val loss: 9.0345 acc: 0.0556\n",
      "Update: Best val acc/loss: 0.055556/9.034470\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.0702 acc: 0.0000  val loss: 9.2593 acc: 0.0556\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 11.1071 acc: 0.0000  val loss: 9.2896 acc: 0.0556\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 10.7417 acc: 0.0000  val loss: 8.9652 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.965241\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.000000/8.965241\n",
      "Epoch 0/50 lr:0.0000040  train loss: 10.3348 acc: 0.0021  val loss: 7.3167 acc: 0.1111\n",
      "Update: Best val acc/loss: 0.111111/7.316657\n",
      "Epoch 1/50 lr:0.0000052  train loss: 8.9650 acc: 0.0063  val loss: 5.5343 acc: 0.2037\n",
      "Update: Best val acc/loss: 0.203704/5.534306\n",
      "Epoch 2/50 lr:0.0000088  train loss: 7.1475 acc: 0.0464  val loss: 3.2632 acc: 0.4444\n",
      "Update: Best val acc/loss: 0.444444/3.263158\n",
      "Epoch 3/50 lr:0.0000145  train loss: 5.3900 acc: 0.1308  val loss: 1.8389 acc: 0.7593\n",
      "Update: Best val acc/loss: 0.759259/1.838862\n",
      "Epoch 4/50 lr:0.0000221  train loss: 3.0264 acc: 0.3671  val loss: 0.9707 acc: 0.9444\n",
      "Update: Best val acc/loss: 0.944444/0.970660\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.8568 acc: 0.6329  val loss: 0.7329 acc: 0.9444\n",
      "Update: Best val acc/loss: 0.944444/0.732931\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.0316 acc: 0.7911  val loss: 0.0184 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.018423\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.5021 acc: 0.8945  val loss: 0.1310 acc: 0.9815\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.6413 acc: 0.9135  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000002\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.4528 acc: 0.8945  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.2967 acc: 0.9430  val loss: 0.8110 acc: 0.9815\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.3953 acc: 0.9198  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.3311 acc: 0.9409  val loss: 0.4198 acc: 0.9815\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.3249 acc: 0.9515  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.2857 acc: 0.9536  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.2892 acc: 0.9494  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.1843 acc: 0.9620  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.1601 acc: 0.9873  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2656 acc: 0.9662  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.2001 acc: 0.9578  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2705 acc: 0.9536  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2013 acc: 0.9810  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1981 acc: 0.9473  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.0892 acc: 0.9852  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.1590 acc: 0.9620  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.0768 acc: 0.9726  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.0161 acc: 0.9979  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1800 acc: 0.9641  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0345 acc: 0.9895  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.0190 acc: 0.9937  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0972 acc: 0.9852  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1277 acc: 0.9873  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1798 acc: 0.9684  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1994 acc: 0.9726  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0185 acc: 0.9937  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1084 acc: 0.9852  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0595 acc: 0.9810  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1096 acc: 0.9662  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0589 acc: 0.9789  val loss: 0.8924 acc: 0.9815\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0189 acc: 0.9937  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0351 acc: 0.9852  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0074 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0119 acc: 0.9958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1207 acc: 0.9662  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.1586 acc: 0.9620  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0758 acc: 0.9958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.0606 acc: 0.9979  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0236 acc: 0.9916  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1102 acc: 0.9895  val loss: 0.8884 acc: 0.9815\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.1009 acc: 0.9852  val loss: 0.8879 acc: 0.9815\n",
      "Training complete in 1m 26s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:44:28,836 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 5.641072691072009 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.07371761671806648 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.02146909525981529 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.04448742792010307\n",
      "Results: {'target': ['grid'], 'auc': [0.8095238095238095], 'th_k_sigma': [5.641072691072009], 'th_fpr': [0.07371761671806648], 'th_tpr': [0.02146909525981529], 'norm_factor': [0.04448742792010307], 'pauc': [0.722551994020138]}\n",
      "\n",
      "--- Start evaluating [hazelnut] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:44:59,255 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:44:59,257 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:44:59,258 dlcliche.utils create_datasets [DEBUG]: all train files: 391, val files: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3921 acc: 0.0000  val loss: 14.6697 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.669731\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.0117 acc: 0.0000  val loss: 13.1795 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.179550\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.1668 acc: 0.0000  val loss: 11.6474 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.647368\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.1941 acc: 0.0000  val loss: 10.2381 acc: 0.0125\n",
      "Update: Best val acc/loss: 0.012500/10.238099\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 11.4747 acc: 0.0000  val loss: 8.8534 acc: 0.0375\n",
      "Update: Best val acc/loss: 0.037500/8.853368\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 10.7585 acc: 0.0043  val loss: 7.4584 acc: 0.0750\n",
      "Update: Best val acc/loss: 0.075000/7.458409\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.2232 acc: 0.0214  val loss: 7.3523 acc: 0.1750\n",
      "Update: Best val acc/loss: 0.175000/7.352346\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 9.6142 acc: 0.0256  val loss: 6.6372 acc: 0.2250\n",
      "Update: Best val acc/loss: 0.225000/6.637222\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 9.5407 acc: 0.0427  val loss: 6.6111 acc: 0.2500\n",
      "Update: Best val acc/loss: 0.250000/6.611094\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 9.3043 acc: 0.0256  val loss: 6.0035 acc: 0.3000\n",
      "Update: Best val acc/loss: 0.300000/6.003524\n",
      "Training complete in 0m 12s\n",
      "Best val Acc/Loss: 0.300000/6.003524\n",
      "Epoch 0/50 lr:0.0000040  train loss: 8.9716 acc: 0.0427  val loss: 5.1271 acc: 0.4500\n",
      "Update: Best val acc/loss: 0.450000/5.127140\n",
      "Epoch 1/50 lr:0.0000052  train loss: 7.6791 acc: 0.1054  val loss: 3.8798 acc: 0.5500\n",
      "Update: Best val acc/loss: 0.550000/3.879847\n",
      "Epoch 2/50 lr:0.0000088  train loss: 6.3633 acc: 0.1980  val loss: 3.4695 acc: 0.6625\n",
      "Update: Best val acc/loss: 0.662500/3.469454\n",
      "Epoch 3/50 lr:0.0000145  train loss: 4.6578 acc: 0.3704  val loss: 2.7299 acc: 0.8500\n",
      "Update: Best val acc/loss: 0.850000/2.729880\n",
      "Epoch 4/50 lr:0.0000221  train loss: 3.0421 acc: 0.5926  val loss: 1.3756 acc: 0.9125\n",
      "Update: Best val acc/loss: 0.912500/1.375592\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.7402 acc: 0.7635  val loss: 1.3667 acc: 0.9500\n",
      "Update: Best val acc/loss: 0.950000/1.366746\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.3293 acc: 0.8362  val loss: 1.4598 acc: 0.9500\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.3072 acc: 0.8675  val loss: 1.4462 acc: 0.9500\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.9420 acc: 0.8761  val loss: 0.1485 acc: 0.9750\n",
      "Update: Best val acc/loss: 0.975000/0.148469\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.7938 acc: 0.9074  val loss: 0.6178 acc: 0.9750\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.6811 acc: 0.9444  val loss: 1.1003 acc: 0.9625\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.4936 acc: 0.9459  val loss: 0.5647 acc: 0.9750\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.7095 acc: 0.9530  val loss: 0.9916 acc: 0.9750\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.8891 acc: 0.9088  val loss: 0.5693 acc: 0.9875\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.5176 acc: 0.9516  val loss: 0.5685 acc: 0.9875\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4876 acc: 0.9587  val loss: 0.1209 acc: 0.9875\n",
      "Update: Best val acc/loss: 0.987500/0.120881\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.6109 acc: 0.9530  val loss: 0.2919 acc: 0.9750\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2805 acc: 0.9672  val loss: 0.0012 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.001204\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2111 acc: 0.9715  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000046\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.2204 acc: 0.9858  val loss: 0.0067 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2347 acc: 0.9715  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2912 acc: 0.9758  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1833 acc: 0.9843  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.2997 acc: 0.9772  val loss: 0.5029 acc: 0.9875\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2223 acc: 0.9786  val loss: 0.5579 acc: 0.9875\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.4307 acc: 0.9672  val loss: 0.8132 acc: 0.9750\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.3047 acc: 0.9815  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.2014 acc: 0.9900  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.1625 acc: 0.9872  val loss: 0.2081 acc: 0.9875\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1329 acc: 0.9815  val loss: 1.1379 acc: 0.9750\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1230 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0726 acc: 0.9915  val loss: 0.5748 acc: 0.9875\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.2459 acc: 0.9858  val loss: 0.3538 acc: 0.9875\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1686 acc: 0.9829  val loss: 0.5662 acc: 0.9875\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.1719 acc: 0.9843  val loss: 0.8487 acc: 0.9750\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.2731 acc: 0.9886  val loss: 0.5568 acc: 0.9875\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1636 acc: 0.9900  val loss: 0.0098 acc: 0.9875\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0088 acc: 0.9972  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1529 acc: 0.9872  val loss: 0.5531 acc: 0.9875\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0094 acc: 0.9972  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1279 acc: 0.9900  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.1115 acc: 0.9915  val loss: 0.4698 acc: 0.9875\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0842 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0367 acc: 0.9972  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0009 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1081 acc: 0.9886  val loss: 0.5139 acc: 0.9875\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1243 acc: 0.9929  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0480 acc: 0.9843  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0886 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0929 acc: 0.9872  val loss: 0.5517 acc: 0.9875\n",
      "Training complete in 1m 56s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:47:07,498 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.932768108197112 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.057144421296968916 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.057144421296968916 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.17692364752292633\n",
      "Results: {'target': ['hazelnut'], 'auc': [0.9928571428571429], 'th_k_sigma': [2.932768108197112], 'th_fpr': [0.057144421296968916], 'th_tpr': [0.057144421296968916], 'norm_factor': [0.17692364752292633], 'pauc': [0.9624060150375939]}\n",
      "\n",
      "--- Start evaluating [leather] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:47:24,355 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:47:24,355 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:47:24,356 dlcliche.utils create_datasets [DEBUG]: all train files: 245, val files: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.4125 acc: 0.0000  val loss: 14.2652 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.265184\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.1652 acc: 0.0000  val loss: 13.7372 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.737190\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.6166 acc: 0.0000  val loss: 12.6543 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.654312\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 12.7703 acc: 0.0000  val loss: 11.5492 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.549183\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.2723 acc: 0.0000  val loss: 10.5079 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.507930\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 11.3218 acc: 0.0000  val loss: 8.5193 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.519346\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 10.8952 acc: 0.0000  val loss: 7.8593 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/7.859322\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 10.6549 acc: 0.0000  val loss: 7.7994 acc: 0.0200\n",
      "Update: Best val acc/loss: 0.020000/7.799419\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 10.3017 acc: 0.0000  val loss: 8.6011 acc: 0.0400\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 10.2627 acc: 0.0000  val loss: 8.0930 acc: 0.0400\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.020000/7.799419\n",
      "Epoch 0/50 lr:0.0000040  train loss: 9.9961 acc: 0.0023  val loss: 5.9810 acc: 0.1800\n",
      "Update: Best val acc/loss: 0.180000/5.981021\n",
      "Epoch 1/50 lr:0.0000052  train loss: 8.5430 acc: 0.0091  val loss: 5.0657 acc: 0.2800\n",
      "Update: Best val acc/loss: 0.280000/5.065675\n",
      "Epoch 2/50 lr:0.0000088  train loss: 7.1587 acc: 0.0455  val loss: 3.3908 acc: 0.3400\n",
      "Update: Best val acc/loss: 0.340000/3.390847\n",
      "Epoch 3/50 lr:0.0000145  train loss: 5.1504 acc: 0.1727  val loss: 2.9148 acc: 0.7800\n",
      "Update: Best val acc/loss: 0.780000/2.914789\n",
      "Epoch 4/50 lr:0.0000221  train loss: 3.7408 acc: 0.4114  val loss: 1.6566 acc: 0.8400\n",
      "Update: Best val acc/loss: 0.840000/1.656637\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.7627 acc: 0.6341  val loss: 0.3818 acc: 0.9600\n",
      "Update: Best val acc/loss: 0.960000/0.381845\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.2037 acc: 0.7864  val loss: 0.4342 acc: 0.9800\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.2639 acc: 0.8318  val loss: 0.8307 acc: 0.9600\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.8254 acc: 0.9091  val loss: 1.2830 acc: 0.9600\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.4927 acc: 0.8955  val loss: 0.0389 acc: 0.9800\n",
      "Update: Best val acc/loss: 0.980000/0.038859\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.4639 acc: 0.9182  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.5499 acc: 0.9295  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.5674 acc: 0.9341  val loss: 0.9230 acc: 0.9800\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4188 acc: 0.9273  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.2131 acc: 0.9659  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.3100 acc: 0.9659  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.4597 acc: 0.9273  val loss: 0.0490 acc: 0.9800\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.4736 acc: 0.9455  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2655 acc: 0.9545  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.4224 acc: 0.9659  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.1796 acc: 0.9682  val loss: 0.8464 acc: 0.9800\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2034 acc: 0.9727  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.0813 acc: 0.9795  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.0630 acc: 0.9818  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.2264 acc: 0.9636  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.1756 acc: 0.9636  val loss: 0.8646 acc: 0.9800\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.3012 acc: 0.9523  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.2698 acc: 0.9500  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0376 acc: 0.9955  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1064 acc: 0.9864  val loss: 0.5419 acc: 0.9800\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.3038 acc: 0.9727  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0407 acc: 0.9818  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0230 acc: 0.9955  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0389 acc: 0.9909  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0741 acc: 0.9909  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0081 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1383 acc: 0.9841  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0521 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0234 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0151 acc: 0.9955  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0172 acc: 0.9932  val loss: 0.3309 acc: 0.9800\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0513 acc: 0.9977  val loss: 0.9509 acc: 0.9800\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.4221 acc: 0.9205  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0247 acc: 0.9932  val loss: 0.5899 acc: 0.9800\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0979 acc: 0.9727  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1519 acc: 0.9795  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1753 acc: 0.9955  val loss: 0.9290 acc: 0.9800\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1715 acc: 0.9818  val loss: 0.3812 acc: 0.9800\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0725 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0284 acc: 0.9864  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 22s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:48:56,278 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 2.634011610052253 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.09380750633457267 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.09380750633457267 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.22926636040210724\n",
      "Results: {'target': ['leather'], 'auc': [1.0], 'th_k_sigma': [2.634011610052253], 'th_fpr': [0.09380750633457267], 'th_tpr': [0.09380750633457267], 'norm_factor': [0.22926636040210724], 'pauc': [1.0]}\n",
      "\n",
      "--- Start evaluating [metal_nut] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:49:09,001 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:49:09,001 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:49:09,002 dlcliche.utils create_datasets [DEBUG]: all train files: 220, val files: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3297 acc: 0.0000  val loss: 14.3220 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.321986\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.2460 acc: 0.0000  val loss: 13.9594 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.959373\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.4118 acc: 0.0000  val loss: 12.9718 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.971770\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.3895 acc: 0.0000  val loss: 12.3573 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.357263\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 12.8073 acc: 0.0000  val loss: 11.5083 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.508322\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 12.2449 acc: 0.0000  val loss: 11.1920 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.191965\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 11.9907 acc: 0.0000  val loss: 10.1509 acc: 0.0227\n",
      "Update: Best val acc/loss: 0.022727/10.150866\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.7477 acc: 0.0000  val loss: 10.2453 acc: 0.0000\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 11.5397 acc: 0.0000  val loss: 10.3140 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 11.5781 acc: 0.0000  val loss: 9.8175 acc: 0.0227\n",
      "Update: Best val acc/loss: 0.022727/9.817463\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.022727/9.817463\n",
      "Epoch 0/50 lr:0.0000040  train loss: 11.3423 acc: 0.0000  val loss: 8.7152 acc: 0.0227\n",
      "Update: Best val acc/loss: 0.022727/8.715216\n",
      "Epoch 1/50 lr:0.0000052  train loss: 10.8774 acc: 0.0000  val loss: 8.5075 acc: 0.0455\n",
      "Update: Best val acc/loss: 0.045455/8.507547\n",
      "Epoch 2/50 lr:0.0000088  train loss: 9.7597 acc: 0.0076  val loss: 6.6815 acc: 0.2045\n",
      "Update: Best val acc/loss: 0.204545/6.681513\n",
      "Epoch 3/50 lr:0.0000145  train loss: 7.8681 acc: 0.0354  val loss: 5.3120 acc: 0.4545\n",
      "Update: Best val acc/loss: 0.454545/5.311962\n",
      "Epoch 4/50 lr:0.0000221  train loss: 5.8733 acc: 0.1869  val loss: 3.0392 acc: 0.7955\n",
      "Update: Best val acc/loss: 0.795455/3.039230\n",
      "Epoch 5/50 lr:0.0000312  train loss: 3.0922 acc: 0.4798  val loss: 2.3120 acc: 0.8864\n",
      "Update: Best val acc/loss: 0.886364/2.312040\n",
      "Epoch 6/50 lr:0.0000413  train loss: 2.1710 acc: 0.6515  val loss: 1.7084 acc: 0.9545\n",
      "Update: Best val acc/loss: 0.954545/1.708375\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.2156 acc: 0.8207  val loss: 1.2021 acc: 0.9545\n",
      "Update: Best val acc/loss: 0.954545/1.202069\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.9933 acc: 0.8636  val loss: 0.9598 acc: 0.9773\n",
      "Update: Best val acc/loss: 0.977273/0.959815\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.8234 acc: 0.8864  val loss: 1.3209 acc: 0.9545\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.7244 acc: 0.8965  val loss: 0.9126 acc: 0.9773\n",
      "Update: Best val acc/loss: 0.977273/0.912610\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.6636 acc: 0.9369  val loss: 0.9563 acc: 0.9773\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.5420 acc: 0.9343  val loss: 1.0006 acc: 0.9545\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.5791 acc: 0.9419  val loss: 1.4936 acc: 0.9545\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.2655 acc: 0.9697  val loss: 1.2048 acc: 0.9545\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.6939 acc: 0.9545  val loss: 0.9524 acc: 0.9773\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2628 acc: 0.9747  val loss: 0.4539 acc: 0.9773\n",
      "Update: Best val acc/loss: 0.977273/0.453867\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.1094 acc: 0.9848  val loss: 0.0018 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.001766\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.7319 acc: 0.9192  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.7347 acc: 0.9419  val loss: 1.3793 acc: 0.9545\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.3747 acc: 0.9444  val loss: 0.0004 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.4984 acc: 0.9646  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.7337 acc: 0.8889  val loss: 0.2061 acc: 0.9773\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.3230 acc: 0.9823  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.3255 acc: 0.9874  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.4988 acc: 0.9495  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.4034 acc: 0.9596  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.4527 acc: 0.9571  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.4537 acc: 0.9419  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.2531 acc: 0.9773  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.3861 acc: 0.9571  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.6147 acc: 0.9672  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.2597 acc: 0.9773  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1108 acc: 0.9899  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.1814 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1403 acc: 0.9899  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.2717 acc: 0.9672  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.3251 acc: 0.9672  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.2198 acc: 0.9899  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1244 acc: 0.9899  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.2340 acc: 0.9747  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.2361 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.1079 acc: 0.9798  val loss: 1.0458 acc: 0.9773\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0945 acc: 0.9823  val loss: 1.0520 acc: 0.9773\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.2551 acc: 0.9444  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0962 acc: 0.9924  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1318 acc: 0.9823  val loss: 1.0467 acc: 0.9773\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1549 acc: 0.9773  val loss: 1.0540 acc: 0.9773\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.2122 acc: 0.9798  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2787 acc: 0.9747  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 16s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:50:34,310 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 4.0125026781437985 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.07711275836072463 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.0475846947480339 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.08714596927165985\n",
      "Results: {'target': ['metal_nut'], 'auc': [0.9232649071358748], 'th_k_sigma': [4.0125026781437985], 'th_fpr': [0.07711275836072463], 'th_tpr': [0.0475846947480339], 'norm_factor': [0.08714596927165985], 'pauc': [0.8991613932191181]}\n",
      "\n",
      "--- Start evaluating [pill] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:50:56,608 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:50:56,608 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:50:56,609 dlcliche.utils create_datasets [DEBUG]: all train files: 267, val files: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.4474 acc: 0.0000  val loss: 14.3222 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.322187\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.6822 acc: 0.0000  val loss: 12.6302 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.630182\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 12.6793 acc: 0.0000  val loss: 10.7055 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.705514\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 11.6273 acc: 0.0000  val loss: 9.5426 acc: 0.0185\n",
      "Update: Best val acc/loss: 0.018519/9.542574\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 10.7223 acc: 0.0000  val loss: 7.9992 acc: 0.0556\n",
      "Update: Best val acc/loss: 0.055556/7.999196\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 9.9178 acc: 0.0083  val loss: 6.6304 acc: 0.1481\n",
      "Update: Best val acc/loss: 0.148148/6.630379\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 9.2241 acc: 0.0167  val loss: 6.6907 acc: 0.2407\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 8.8716 acc: 0.0250  val loss: 6.4534 acc: 0.2963\n",
      "Update: Best val acc/loss: 0.296296/6.453390\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 8.8063 acc: 0.0417  val loss: 6.3117 acc: 0.2593\n",
      "Update: Best val acc/loss: 0.259259/6.311670\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 8.3763 acc: 0.0292  val loss: 6.1123 acc: 0.2963\n",
      "Update: Best val acc/loss: 0.296296/6.112315\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.296296/6.112315\n",
      "Epoch 0/50 lr:0.0000040  train loss: 7.8649 acc: 0.0729  val loss: 3.0785 acc: 0.5370\n",
      "Update: Best val acc/loss: 0.537037/3.078529\n",
      "Epoch 1/50 lr:0.0000052  train loss: 6.5620 acc: 0.1479  val loss: 3.3072 acc: 0.6852\n",
      "Epoch 2/50 lr:0.0000088  train loss: 4.7586 acc: 0.3000  val loss: 2.7920 acc: 0.7778\n",
      "Update: Best val acc/loss: 0.777778/2.791967\n",
      "Epoch 3/50 lr:0.0000145  train loss: 3.1109 acc: 0.5292  val loss: 2.0413 acc: 0.8519\n",
      "Update: Best val acc/loss: 0.851852/2.041322\n",
      "Epoch 4/50 lr:0.0000221  train loss: 2.1029 acc: 0.6354  val loss: 2.0668 acc: 0.9074\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.6252 acc: 0.7708  val loss: 1.8142 acc: 0.9444\n",
      "Update: Best val acc/loss: 0.944444/1.814177\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.9804 acc: 0.8375  val loss: 1.1011 acc: 0.9444\n",
      "Update: Best val acc/loss: 0.944444/1.101147\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.7698 acc: 0.8917  val loss: 0.5119 acc: 0.9815\n",
      "Update: Best val acc/loss: 0.981481/0.511887\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.6954 acc: 0.9000  val loss: 1.1419 acc: 0.9630\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.5184 acc: 0.9104  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.4263 acc: 0.9396  val loss: 0.2948 acc: 0.9815\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.7168 acc: 0.9146  val loss: 0.0574 acc: 0.9815\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.3068 acc: 0.9396  val loss: 0.8370 acc: 0.9815\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.2719 acc: 0.9646  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.3843 acc: 0.9271  val loss: 0.0353 acc: 0.9815\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.3015 acc: 0.9667  val loss: 0.7063 acc: 0.9815\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2111 acc: 0.9562  val loss: 0.0045 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2676 acc: 0.9708  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.1342 acc: 0.9729  val loss: 0.8693 acc: 0.9815\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.0126 acc: 0.9938  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.1390 acc: 0.9771  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.0603 acc: 0.9771  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1209 acc: 0.9833  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.0934 acc: 0.9750  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.0079 acc: 0.9938  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.0193 acc: 0.9938  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.0323 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.0520 acc: 0.9917  val loss: 0.2502 acc: 0.9815\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0596 acc: 0.9833  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.0283 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0007 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.0282 acc: 0.9979  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.2331 acc: 0.9771  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0809 acc: 0.9938  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0262 acc: 0.9917  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0007 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0535 acc: 0.9854  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0015 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0497 acc: 0.9833  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0679 acc: 0.9875  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0073 acc: 0.9958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0634 acc: 0.9854  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0140 acc: 0.9958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0003 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0651 acc: 0.9875  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0661 acc: 0.9875  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.3104 acc: 0.9750  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0180 acc: 0.9938  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0271 acc: 0.9958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0126 acc: 0.9958  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 27s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:52:33,450 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 5.35001713582774 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.10137817694231754 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.06081253827036744 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.07052382826805115\n",
      "Results: {'target': ['pill'], 'auc': [0.8998908892525913], 'th_k_sigma': [5.35001713582774], 'th_fpr': [0.10137817694231754], 'th_tpr': [0.06081253827036744], 'norm_factor': [0.07052382826805115], 'pauc': [0.7886697102822522]}\n",
      "\n",
      "--- Start evaluating [screw] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:52:45,664 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:52:45,666 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:52:45,666 dlcliche.utils create_datasets [DEBUG]: all train files: 320, val files: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.4483 acc: 0.0000  val loss: 14.5979 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.597893\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.7505 acc: 0.0000  val loss: 12.9491 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.949091\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 12.4392 acc: 0.0000  val loss: 10.4704 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.470362\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 11.1853 acc: 0.0000  val loss: 8.0005 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.000478\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 10.1135 acc: 0.0017  val loss: 6.9118 acc: 0.0938\n",
      "Update: Best val acc/loss: 0.093750/6.911783\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 8.7427 acc: 0.0122  val loss: 6.3801 acc: 0.2812\n",
      "Update: Best val acc/loss: 0.281250/6.380054\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 7.8934 acc: 0.0347  val loss: 5.5821 acc: 0.4375\n",
      "Update: Best val acc/loss: 0.437500/5.582075\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 7.4053 acc: 0.0660  val loss: 3.9811 acc: 0.4531\n",
      "Update: Best val acc/loss: 0.453125/3.981145\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 7.1408 acc: 0.0729  val loss: 4.6171 acc: 0.4531\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 7.0558 acc: 0.0608  val loss: 4.8346 acc: 0.5781\n",
      "Training complete in 0m 10s\n",
      "Best val Acc/Loss: 0.453125/3.981145\n",
      "Epoch 0/50 lr:0.0000040  train loss: 6.8217 acc: 0.1215  val loss: 4.1460 acc: 0.6719\n",
      "Update: Best val acc/loss: 0.671875/4.146019\n",
      "Epoch 1/50 lr:0.0000052  train loss: 5.3469 acc: 0.2135  val loss: 3.8448 acc: 0.6562\n",
      "Update: Best val acc/loss: 0.656250/3.844793\n",
      "Epoch 2/50 lr:0.0000088  train loss: 4.6164 acc: 0.3403  val loss: 2.2061 acc: 0.8438\n",
      "Update: Best val acc/loss: 0.843750/2.206121\n",
      "Epoch 3/50 lr:0.0000145  train loss: 2.9692 acc: 0.5382  val loss: 1.6882 acc: 0.9062\n",
      "Update: Best val acc/loss: 0.906250/1.688151\n",
      "Epoch 4/50 lr:0.0000221  train loss: 2.2407 acc: 0.6545  val loss: 1.6488 acc: 0.9062\n",
      "Update: Best val acc/loss: 0.906250/1.648836\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.5019 acc: 0.7969  val loss: 1.8116 acc: 0.9219\n",
      "Epoch 6/50 lr:0.0000413  train loss: 1.1377 acc: 0.8247  val loss: 2.1201 acc: 0.9062\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.7757 acc: 0.8681  val loss: 0.6617 acc: 0.9844\n",
      "Update: Best val acc/loss: 0.984375/0.661662\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.8461 acc: 0.9080  val loss: 0.2562 acc: 0.9531\n",
      "Update: Best val acc/loss: 0.953125/0.256203\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.4384 acc: 0.9080  val loss: 0.0624 acc: 0.9844\n",
      "Update: Best val acc/loss: 0.984375/0.062381\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.5027 acc: 0.9253  val loss: 0.3636 acc: 0.9844\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.2189 acc: 0.9549  val loss: 0.4476 acc: 0.9531\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.2303 acc: 0.9549  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000022\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4932 acc: 0.9184  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000002\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.2454 acc: 0.9653  val loss: 0.0058 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4684 acc: 0.9479  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2954 acc: 0.9514  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.3410 acc: 0.9479  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2938 acc: 0.9479  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.1259 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.1382 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.0422 acc: 0.9878  val loss: 1.2861 acc: 0.9688\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1397 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.1774 acc: 0.9809  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.0786 acc: 0.9931  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.5330 acc: 0.9497  val loss: 1.2327 acc: 0.9531\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.4888 acc: 0.9635  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.2622 acc: 0.9757  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0833 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1255 acc: 0.9826  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.2007 acc: 0.9740  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1423 acc: 0.9948  val loss: 0.6239 acc: 0.9844\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0795 acc: 0.9948  val loss: 0.7608 acc: 0.9844\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0096 acc: 0.9965  val loss: 0.4465 acc: 0.9844\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0715 acc: 0.9983  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0835 acc: 0.9931  val loss: 0.7523 acc: 0.9844\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0511 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1976 acc: 0.9792  val loss: 0.7325 acc: 0.9844\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0819 acc: 0.9861  val loss: 0.3690 acc: 0.9844\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0596 acc: 0.9878  val loss: 0.7670 acc: 0.9844\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0825 acc: 0.9913  val loss: 0.7570 acc: 0.9844\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0086 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0697 acc: 0.9983  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0585 acc: 0.9983  val loss: 0.3079 acc: 0.9844\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0804 acc: 0.9913  val loss: 0.7646 acc: 0.9844\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.2293 acc: 0.9635  val loss: 0.0004 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1657 acc: 0.9705  val loss: 0.7649 acc: 0.9844\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1052 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1617 acc: 0.9931  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0835 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 39s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:54:35,266 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 1.9202427395824708 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 1.2899344820754526 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.5036511803096231 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.0032224184833467007\n",
      "Results: {'target': ['screw'], 'auc': [0.42713670834187334], 'th_k_sigma': [1.9202427395824708], 'th_fpr': [1.2899344820754526], 'th_tpr': [0.5036511803096231], 'norm_factor': [0.0032224184833467007], 'pauc': [0.5241691028144249]}\n",
      "\n",
      "--- Start evaluating [tile] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:54:48,152 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:54:48,152 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:54:48,153 dlcliche.utils create_datasets [DEBUG]: all train files: 230, val files: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 117\n",
      " training...\n",
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.2863 acc: 0.0000  val loss: 14.7647 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.764723\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.2120 acc: 0.0000  val loss: 13.8117 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.811674\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.7410 acc: 0.0000  val loss: 13.3213 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.321255\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.3502 acc: 0.0000  val loss: 12.1811 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.181055\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.0527 acc: 0.0000  val loss: 11.8194 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.819386\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 12.4693 acc: 0.0000  val loss: 11.7136 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.713572\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.3999 acc: 0.0000  val loss: 11.3323 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.332293\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 11.8985 acc: 0.0000  val loss: 10.8947 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.894686\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 11.8871 acc: 0.0000  val loss: 10.6968 acc: 0.0217\n",
      "Update: Best val acc/loss: 0.021739/10.696795\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 11.8808 acc: 0.0000  val loss: 10.6635 acc: 0.0217\n",
      "Update: Best val acc/loss: 0.021739/10.663457\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.021739/10.663457\n",
      "Epoch 0/50 lr:0.0000040  train loss: 11.5748 acc: 0.0000  val loss: 9.7193 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.719267\n",
      "Epoch 1/50 lr:0.0000052  train loss: 10.9289 acc: 0.0000  val loss: 7.8139 acc: 0.0870\n",
      "Update: Best val acc/loss: 0.086957/7.813903\n",
      "Epoch 2/50 lr:0.0000088  train loss: 9.7790 acc: 0.0000  val loss: 6.4514 acc: 0.1957\n",
      "Update: Best val acc/loss: 0.195652/6.451371\n",
      "Epoch 3/50 lr:0.0000145  train loss: 7.8376 acc: 0.0193  val loss: 4.1203 acc: 0.3478\n",
      "Update: Best val acc/loss: 0.347826/4.120350\n",
      "Epoch 4/50 lr:0.0000221  train loss: 5.5545 acc: 0.1425  val loss: 2.6028 acc: 0.6739\n",
      "Update: Best val acc/loss: 0.673913/2.602775\n",
      "Epoch 5/50 lr:0.0000312  train loss: 3.3693 acc: 0.4614  val loss: 2.7051 acc: 0.8913\n",
      "Epoch 6/50 lr:0.0000413  train loss: 2.0794 acc: 0.6304  val loss: 2.4733 acc: 0.9130\n",
      "Update: Best val acc/loss: 0.913043/2.473288\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.5301 acc: 0.8309  val loss: 1.9407 acc: 0.9130\n",
      "Update: Best val acc/loss: 0.913043/1.940661\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.1688 acc: 0.8478  val loss: 0.8401 acc: 0.9348\n",
      "Update: Best val acc/loss: 0.934783/0.840073\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.8142 acc: 0.9420  val loss: 0.5788 acc: 0.9565\n",
      "Update: Best val acc/loss: 0.956522/0.578797\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.9738 acc: 0.8502  val loss: 1.0688 acc: 0.9565\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.4523 acc: 0.9203  val loss: 0.0606 acc: 0.9783\n",
      "Update: Best val acc/loss: 0.978261/0.060556\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.8471 acc: 0.8986  val loss: 0.1906 acc: 0.9783\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.4815 acc: 0.9324  val loss: 0.3522 acc: 0.9783\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.5179 acc: 0.9420  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000114\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.4244 acc: 0.9444  val loss: 0.4351 acc: 0.9783\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.2393 acc: 0.9565  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.2737 acc: 0.9710  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2460 acc: 0.9734  val loss: 0.7065 acc: 0.9783\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.3706 acc: 0.9614  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2968 acc: 0.9638  val loss: 0.3656 acc: 0.9783\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.0970 acc: 0.9903  val loss: 0.9999 acc: 0.9783\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.3192 acc: 0.9686  val loss: 0.0008 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.2456 acc: 0.9638  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.3948 acc: 0.9517  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.3074 acc: 0.9662  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.3661 acc: 0.9420  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.2661 acc: 0.9758  val loss: 0.1232 acc: 0.9783\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.2559 acc: 0.9710  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1931 acc: 0.9734  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.1880 acc: 0.9783  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.2324 acc: 0.9638  val loss: 0.3044 acc: 0.9783\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.1577 acc: 0.9855  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.2285 acc: 0.9734  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.2307 acc: 0.9831  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.2993 acc: 0.9686  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.1302 acc: 0.9734  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1551 acc: 0.9807  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1946 acc: 0.9903  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.0904 acc: 0.9976  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1555 acc: 0.9589  val loss: 1.0131 acc: 0.9783\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0307 acc: 0.9952  val loss: 1.0074 acc: 0.9783\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0723 acc: 0.9879  val loss: 0.3850 acc: 0.9783\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1714 acc: 0.9807  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.2849 acc: 0.9541  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.1562 acc: 0.9686  val loss: 0.9899 acc: 0.9783\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.3151 acc: 0.9638  val loss: 0.9983 acc: 0.9783\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0881 acc: 0.9976  val loss: 1.0011 acc: 0.9783\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1118 acc: 0.9855  val loss: 1.0060 acc: 0.9783\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.2411 acc: 0.9614  val loss: 0.7052 acc: 0.9783\n",
      "Training complete in 1m 19s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:56:16,698 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.6114519238107614 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.08286376870292862 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.054955874652124204 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.07888013124465942\n",
      "Results: {'target': ['tile'], 'auc': [0.9603174603174603], 'th_k_sigma': [3.6114519238107614], 'th_fpr': [0.08286376870292862], 'th_tpr': [0.054955874652124204], 'norm_factor': [0.07888013124465942], 'pauc': [0.9025974025974026]}\n",
      "\n",
      "--- Start evaluating [toothbrush] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:56:22,957 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:56:22,957 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:56:22,958 dlcliche.utils create_datasets [DEBUG]: all train files: 60, val files: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3422 acc: 0.0000  val loss: 14.4629 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.462863\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.1249 acc: 0.0000  val loss: 14.3467 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.346725\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 13.9921 acc: 0.0000  val loss: 13.8260 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.826003\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 14.1522 acc: 0.0000  val loss: 13.8848 acc: 0.0000\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 14.0431 acc: 0.0000  val loss: 14.1523 acc: 0.0000\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.6789 acc: 0.0000  val loss: 14.2096 acc: 0.0000\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 13.7907 acc: 0.0000  val loss: 14.2359 acc: 0.0000\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 13.7612 acc: 0.0000  val loss: 13.8835 acc: 0.0000\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 13.8027 acc: 0.0000  val loss: 14.2750 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 13.6219 acc: 0.0000  val loss: 14.0111 acc: 0.0000\n",
      "Training complete in 0m 5s\n",
      "Best val Acc/Loss: 0.000000/13.826003\n",
      "Epoch 0/50 lr:0.0000040  train loss: 13.5624 acc: 0.0000  val loss: 13.4993 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.499270\n",
      "Epoch 1/50 lr:0.0000052  train loss: 13.6167 acc: 0.0000  val loss: 12.8883 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.888316\n",
      "Epoch 2/50 lr:0.0000088  train loss: 13.4454 acc: 0.0000  val loss: 12.9762 acc: 0.0000\n",
      "Epoch 3/50 lr:0.0000145  train loss: 13.5981 acc: 0.0000  val loss: 12.9810 acc: 0.0000\n",
      "Epoch 4/50 lr:0.0000221  train loss: 13.0569 acc: 0.0000  val loss: 13.5945 acc: 0.0000\n",
      "Epoch 5/50 lr:0.0000312  train loss: 12.7119 acc: 0.0000  val loss: 13.2000 acc: 0.0000\n",
      "Epoch 6/50 lr:0.0000413  train loss: 11.6373 acc: 0.0000  val loss: 12.8711 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.871133\n",
      "Epoch 7/50 lr:0.0000520  train loss: 10.5678 acc: 0.0000  val loss: 10.5451 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.545094\n",
      "Epoch 8/50 lr:0.0000627  train loss: 8.7598 acc: 0.0185  val loss: 7.3837 acc: 0.0833\n",
      "Update: Best val acc/loss: 0.083333/7.383675\n",
      "Epoch 9/50 lr:0.0000728  train loss: 6.8328 acc: 0.0926  val loss: 5.4431 acc: 0.5000\n",
      "Update: Best val acc/loss: 0.500000/5.443072\n",
      "Epoch 10/50 lr:0.0000819  train loss: 5.0101 acc: 0.3148  val loss: 5.1868 acc: 0.5000\n",
      "Update: Best val acc/loss: 0.500000/5.186846\n",
      "Epoch 11/50 lr:0.0000895  train loss: 4.8471 acc: 0.3889  val loss: 4.0430 acc: 0.8333\n",
      "Update: Best val acc/loss: 0.833333/4.042990\n",
      "Epoch 12/50 lr:0.0000952  train loss: 3.1596 acc: 0.6019  val loss: 3.1599 acc: 0.9167\n",
      "Update: Best val acc/loss: 0.916667/3.159945\n",
      "Epoch 13/50 lr:0.0000988  train loss: 2.9168 acc: 0.6481  val loss: 2.9061 acc: 0.9167\n",
      "Update: Best val acc/loss: 0.916667/2.906132\n",
      "Epoch 14/50 lr:0.0001000  train loss: 1.2329 acc: 0.8241  val loss: 1.8909 acc: 0.9167\n",
      "Update: Best val acc/loss: 0.916667/1.890945\n",
      "Epoch 15/50 lr:0.0000998  train loss: 1.0743 acc: 0.8241  val loss: 1.3473 acc: 0.9167\n",
      "Update: Best val acc/loss: 0.916667/1.347299\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.8538 acc: 0.9074  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000016\n",
      "Epoch 17/50 lr:0.0000982  train loss: 1.2367 acc: 0.8796  val loss: 0.0018 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 2.0609 acc: 0.8148  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.6677 acc: 0.9722  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 1.6207 acc: 0.8704  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 1.2159 acc: 0.8889  val loss: 1.1105 acc: 0.9167\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.7136 acc: 0.9630  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.2770 acc: 0.9259  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 2.0227 acc: 0.8333  val loss: 0.2974 acc: 0.9167\n",
      "Epoch 25/50 lr:0.0000776  train loss: 1.6301 acc: 0.8889  val loss: 0.2076 acc: 0.9167\n",
      "Epoch 26/50 lr:0.0000737  train loss: 1.8148 acc: 0.9074  val loss: 3.3414 acc: 0.9167\n",
      "Epoch 27/50 lr:0.0000697  train loss: 1.1635 acc: 0.9537  val loss: 0.3706 acc: 0.9167\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.8727 acc: 0.9352  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 1.1302 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.9181 acc: 0.9630  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 1.2735 acc: 0.8426  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.9197 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.4837 acc: 0.9537  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.4117 acc: 0.9352  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.3052 acc: 0.9815  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.7377 acc: 0.9722  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.6820 acc: 0.9630  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 1.4427 acc: 0.8519  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.6436 acc: 0.9722  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.8744 acc: 0.8704  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.9110 acc: 0.9259  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.9699 acc: 0.9259  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 1.4104 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 1.3307 acc: 0.9352  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 1.1180 acc: 0.9537  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.5212 acc: 0.9537  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.9957 acc: 0.9352  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 1.1505 acc: 0.9352  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 1.0275 acc: 0.9352  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 0m 36s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:57:05,220 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.7689605734328753 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.14102222822740937 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.09453034103824659 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.12186340987682343\n",
      "Results: {'target': ['toothbrush'], 'auc': [0.9138888888888889], 'th_k_sigma': [3.7689605734328753], 'th_fpr': [0.14102222822740937], 'th_tpr': [0.09453034103824659], 'norm_factor': [0.12186340987682343], 'pauc': [0.9122807017543859]}\n",
      "\n",
      "--- Start evaluating [transistor] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:57:24,753 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:57:24,753 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:57:24,754 dlcliche.utils create_datasets [DEBUG]: all train files: 213, val files: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.5373 acc: 0.0000  val loss: 14.5969 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.596892\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.3003 acc: 0.0000  val loss: 14.1318 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.131840\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 14.0569 acc: 0.0000  val loss: 13.5531 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.553110\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.7315 acc: 0.0000  val loss: 13.2578 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.257766\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.5436 acc: 0.0000  val loss: 12.9861 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.986083\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.2255 acc: 0.0000  val loss: 12.2672 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.267189\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 12.9585 acc: 0.0000  val loss: 12.3364 acc: 0.0000\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 12.7917 acc: 0.0000  val loss: 12.1157 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.115666\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 12.6551 acc: 0.0000  val loss: 12.4004 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 12.5709 acc: 0.0000  val loss: 11.6488 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.648812\n",
      "Training complete in 0m 8s\n",
      "Best val Acc/Loss: 0.000000/11.648812\n",
      "Epoch 0/50 lr:0.0000040  train loss: 12.6079 acc: 0.0000  val loss: 11.3118 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.311813\n",
      "Epoch 1/50 lr:0.0000052  train loss: 12.3340 acc: 0.0000  val loss: 10.7456 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.745580\n",
      "Epoch 2/50 lr:0.0000088  train loss: 11.8047 acc: 0.0000  val loss: 9.2879 acc: 0.0455\n",
      "Update: Best val acc/loss: 0.045455/9.287949\n",
      "Epoch 3/50 lr:0.0000145  train loss: 10.5775 acc: 0.0026  val loss: 8.6301 acc: 0.1591\n",
      "Update: Best val acc/loss: 0.159091/8.630138\n",
      "Epoch 4/50 lr:0.0000221  train loss: 9.2084 acc: 0.0262  val loss: 5.3366 acc: 0.2955\n",
      "Update: Best val acc/loss: 0.295455/5.336553\n",
      "Epoch 5/50 lr:0.0000312  train loss: 6.6913 acc: 0.1571  val loss: 3.5100 acc: 0.5227\n",
      "Update: Best val acc/loss: 0.522727/3.510041\n",
      "Epoch 6/50 lr:0.0000413  train loss: 4.3494 acc: 0.3874  val loss: 3.2870 acc: 0.8182\n",
      "Update: Best val acc/loss: 0.818182/3.287025\n",
      "Epoch 7/50 lr:0.0000520  train loss: 2.2918 acc: 0.6387  val loss: 0.9847 acc: 0.9091\n",
      "Update: Best val acc/loss: 0.909091/0.984689\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.6749 acc: 0.7880  val loss: 2.1135 acc: 0.9091\n",
      "Epoch 9/50 lr:0.0000728  train loss: 1.4118 acc: 0.8455  val loss: 0.3730 acc: 0.9773\n",
      "Update: Best val acc/loss: 0.977273/0.372959\n",
      "Epoch 10/50 lr:0.0000819  train loss: 1.4942 acc: 0.8037  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000007\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.8698 acc: 0.8796  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.6325 acc: 0.8953  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.8386 acc: 0.9084  val loss: 0.0848 acc: 0.9773\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.3019 acc: 0.9503  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.2819 acc: 0.9581  val loss: 0.0027 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.5470 acc: 0.9372  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.6024 acc: 0.9136  val loss: 0.0003 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.6388 acc: 0.9215  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.5956 acc: 0.9241  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2271 acc: 0.9555  val loss: 0.0006 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2531 acc: 0.9817  val loss: 1.0125 acc: 0.9545\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.3940 acc: 0.9607  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.4734 acc: 0.9529  val loss: 0.0082 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.4304 acc: 0.9476  val loss: 0.0197 acc: 0.9773\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.4769 acc: 0.9372  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.1817 acc: 0.9712  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.3672 acc: 0.9529  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.2760 acc: 0.9555  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.2983 acc: 0.9791  val loss: 0.4758 acc: 0.9773\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.3103 acc: 0.9398  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.3714 acc: 0.9607  val loss: 0.6302 acc: 0.9773\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.4395 acc: 0.9267  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.1874 acc: 0.9764  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.1338 acc: 0.9817  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1144 acc: 0.9764  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0808 acc: 0.9738  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1252 acc: 0.9738  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1133 acc: 0.9764  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.2405 acc: 0.9555  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0111 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0627 acc: 0.9869  val loss: 0.0002 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.1774 acc: 0.9869  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0077 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.2822 acc: 0.9529  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0861 acc: 0.9764  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.2370 acc: 0.9764  val loss: 0.9939 acc: 0.9773\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.1393 acc: 0.9817  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0150 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0119 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 14s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:58:47,822 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 6.867415358691658 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.1541716608297715 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.07928895774189153 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.0353197306394577\n",
      "Results: {'target': ['transistor'], 'auc': [0.8624999999999999], 'th_k_sigma': [6.867415358691658], 'th_fpr': [0.1541716608297715], 'th_tpr': [0.07928895774189153], 'norm_factor': [0.0353197306394577], 'pauc': [0.7543859649122807]}\n",
      "\n",
      "--- Start evaluating [wood] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 01:59:08,344 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 01:59:08,344 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 01:59:08,345 dlcliche.utils create_datasets [DEBUG]: all train files: 247, val files: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.5150 acc: 0.0000  val loss: 14.3736 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.373581\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 14.4783 acc: 0.0000  val loss: 14.2007 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.200675\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 14.2252 acc: 0.0000  val loss: 13.8691 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.869072\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 13.7395 acc: 0.0000  val loss: 13.5842 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.584199\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 13.4995 acc: 0.0000  val loss: 13.2364 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.236389\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 13.3437 acc: 0.0000  val loss: 12.8785 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.878526\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 13.2123 acc: 0.0000  val loss: 12.6023 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.602347\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 12.9803 acc: 0.0000  val loss: 12.1749 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.174931\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 12.8994 acc: 0.0000  val loss: 12.5560 acc: 0.0000\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 12.8365 acc: 0.0000  val loss: 12.5407 acc: 0.0000\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.000000/12.174931\n",
      "Epoch 0/50 lr:0.0000040  train loss: 12.7660 acc: 0.0000  val loss: 11.4474 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.447354\n",
      "Epoch 1/50 lr:0.0000052  train loss: 12.1249 acc: 0.0000  val loss: 11.1858 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.185833\n",
      "Epoch 2/50 lr:0.0000088  train loss: 11.1997 acc: 0.0000  val loss: 9.6109 acc: 0.0400\n",
      "Update: Best val acc/loss: 0.040000/9.610947\n",
      "Epoch 3/50 lr:0.0000145  train loss: 9.9536 acc: 0.0068  val loss: 7.2844 acc: 0.2400\n",
      "Update: Best val acc/loss: 0.240000/7.284371\n",
      "Epoch 4/50 lr:0.0000221  train loss: 7.4625 acc: 0.0495  val loss: 4.0362 acc: 0.3600\n",
      "Update: Best val acc/loss: 0.360000/4.036208\n",
      "Epoch 5/50 lr:0.0000312  train loss: 4.4887 acc: 0.2455  val loss: 1.5573 acc: 0.7800\n",
      "Update: Best val acc/loss: 0.780000/1.557280\n",
      "Epoch 6/50 lr:0.0000413  train loss: 2.3296 acc: 0.5676  val loss: 0.4438 acc: 0.9200\n",
      "Update: Best val acc/loss: 0.920000/0.443810\n",
      "Epoch 7/50 lr:0.0000520  train loss: 1.3307 acc: 0.7635  val loss: 1.1648 acc: 0.9600\n",
      "Epoch 8/50 lr:0.0000627  train loss: 1.0108 acc: 0.8536  val loss: 1.0126 acc: 0.9600\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.6085 acc: 0.9009  val loss: 0.7385 acc: 0.9400\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.9945 acc: 0.8671  val loss: 0.0872 acc: 0.9800\n",
      "Update: Best val acc/loss: 0.980000/0.087206\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.5677 acc: 0.9437  val loss: 0.1367 acc: 0.9800\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.6964 acc: 0.8919  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.5077 acc: 0.9392  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.4721 acc: 0.9527  val loss: 0.1170 acc: 0.9800\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.2184 acc: 0.9730  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.6689 acc: 0.9167  val loss: 0.0016 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.3592 acc: 0.9414  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.2978 acc: 0.9392  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.1535 acc: 0.9775  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.2800 acc: 0.9707  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2932 acc: 0.9662  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1569 acc: 0.9797  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.1053 acc: 0.9887  val loss: 0.2696 acc: 0.9800\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.5903 acc: 0.9279  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.3167 acc: 0.9640  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.2783 acc: 0.9685  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.4738 acc: 0.9527  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.3203 acc: 0.9437  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.1441 acc: 0.9550  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0879 acc: 0.9865  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1422 acc: 0.9775  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0331 acc: 0.9910  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0483 acc: 0.9955  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0961 acc: 0.9932  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.0409 acc: 0.9887  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0531 acc: 0.9820  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.0050 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.1607 acc: 0.9775  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.1829 acc: 0.9685  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.1082 acc: 0.9820  val loss: 1.0676 acc: 0.9600\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0372 acc: 0.9842  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0091 acc: 0.9955  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.1112 acc: 0.9932  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.2157 acc: 0.9842  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0896 acc: 0.9932  val loss: 0.9416 acc: 0.9800\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.1333 acc: 0.9797  val loss: 0.9423 acc: 0.9800\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0893 acc: 0.9955  val loss: 0.9426 acc: 0.9800\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.1702 acc: 0.9887  val loss: 0.9453 acc: 0.9800\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0658 acc: 0.9932  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 22s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 02:00:39,362 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 3.062473451839259 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.015920702475547582 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.011050733587509855 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.249141663312912\n",
      "Results: {'target': ['wood'], 'auc': [0.9859649122807018], 'th_k_sigma': [3.062473451839259], 'th_fpr': [0.015920702475547582], 'th_tpr': [0.011050733587509855], 'norm_factor': [0.249141663312912], 'pauc': [0.9866112650046168]}\n",
      "\n",
      "--- Start evaluating [zipper] ----\n",
      " preprocessing...\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240\n",
      " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151\n",
      " training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 02:00:48,693 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-20 02:00:48,694 dlcliche.utils setup_train [INFO]: Random seed: 0\n",
      "2020-04-20 02:00:48,694 dlcliche.utils create_datasets [DEBUG]: all train files: 240, val files: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 lr:0.0000040 m:0.95000  train loss: 14.3685 acc: 0.0000  val loss: 13.9311 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.931107\n",
      "Epoch 1/10 lr:0.0000520 m:0.90000  train loss: 13.8857 acc: 0.0000  val loss: 12.5171 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.517084\n",
      "Epoch 2/10 lr:0.0001000 m:0.85000  train loss: 12.6693 acc: 0.0000  val loss: 10.3340 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.333954\n",
      "Epoch 3/10 lr:0.0000950 m:0.85495  train loss: 11.4869 acc: 0.0000  val loss: 8.9237 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.923723\n",
      "Epoch 4/10 lr:0.0000812 m:0.86883  train loss: 10.6070 acc: 0.0000  val loss: 7.1840 acc: 0.0208\n",
      "Update: Best val acc/loss: 0.020833/7.184019\n",
      "Epoch 5/10 lr:0.0000611 m:0.88887  train loss: 9.3387 acc: 0.0000  val loss: 7.4036 acc: 0.1250\n",
      "Epoch 6/10 lr:0.0000389 m:0.91113  train loss: 8.3687 acc: 0.0023  val loss: 5.4291 acc: 0.1667\n",
      "Update: Best val acc/loss: 0.166667/5.429148\n",
      "Epoch 7/10 lr:0.0000188 m:0.93117  train loss: 8.3301 acc: 0.0139  val loss: 5.4320 acc: 0.2500\n",
      "Epoch 8/10 lr:0.0000050 m:0.94505  train loss: 7.9024 acc: 0.0208  val loss: 5.7610 acc: 0.2708\n",
      "Epoch 9/10 lr:0.0000000 m:0.95000  train loss: 7.6436 acc: 0.0231  val loss: 4.5356 acc: 0.1875\n",
      "Update: Best val acc/loss: 0.187500/4.535620\n",
      "Training complete in 0m 9s\n",
      "Best val Acc/Loss: 0.187500/4.535620\n",
      "Epoch 0/50 lr:0.0000040  train loss: 7.2518 acc: 0.0463  val loss: 2.7438 acc: 0.4167\n",
      "Update: Best val acc/loss: 0.416667/2.743792\n",
      "Epoch 1/50 lr:0.0000052  train loss: 5.5478 acc: 0.1157  val loss: 3.2761 acc: 0.5833\n",
      "Epoch 2/50 lr:0.0000088  train loss: 4.5012 acc: 0.2477  val loss: 1.9412 acc: 0.7292\n",
      "Update: Best val acc/loss: 0.729167/1.941214\n",
      "Epoch 3/50 lr:0.0000145  train loss: 3.2204 acc: 0.4398  val loss: 1.8841 acc: 0.8542\n",
      "Update: Best val acc/loss: 0.854167/1.884133\n",
      "Epoch 4/50 lr:0.0000221  train loss: 2.3917 acc: 0.6296  val loss: 0.7844 acc: 0.9583\n",
      "Update: Best val acc/loss: 0.958333/0.784356\n",
      "Epoch 5/50 lr:0.0000312  train loss: 1.5144 acc: 0.7593  val loss: 0.6540 acc: 0.9375\n",
      "Update: Best val acc/loss: 0.937500/0.654000\n",
      "Epoch 6/50 lr:0.0000413  train loss: 0.7497 acc: 0.8449  val loss: 0.3746 acc: 0.9792\n",
      "Update: Best val acc/loss: 0.979167/0.374553\n",
      "Epoch 7/50 lr:0.0000520  train loss: 0.9651 acc: 0.8750  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000007\n",
      "Epoch 8/50 lr:0.0000627  train loss: 0.6545 acc: 0.8843  val loss: 0.9376 acc: 0.9583\n",
      "Epoch 9/50 lr:0.0000728  train loss: 0.3676 acc: 0.9282  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 10/50 lr:0.0000819  train loss: 0.4387 acc: 0.9329  val loss: 0.0002 acc: 1.0000\n",
      "Epoch 11/50 lr:0.0000895  train loss: 0.3352 acc: 0.9537  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 12/50 lr:0.0000952  train loss: 0.2634 acc: 0.9444  val loss: 0.0002 acc: 1.0000\n",
      "Epoch 13/50 lr:0.0000988  train loss: 0.0930 acc: 0.9815  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 14/50 lr:0.0001000  train loss: 0.1259 acc: 0.9769  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 15/50 lr:0.0000998  train loss: 0.0831 acc: 0.9722  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 16/50 lr:0.0000992  train loss: 0.1753 acc: 0.9653  val loss: 0.0114 acc: 1.0000\n",
      "Epoch 17/50 lr:0.0000982  train loss: 0.0687 acc: 0.9676  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.0000968  train loss: 0.0505 acc: 0.9838  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 19/50 lr:0.0000951  train loss: 0.0818 acc: 0.9815  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.0000929  train loss: 0.1457 acc: 0.9815  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 21/50 lr:0.0000905  train loss: 0.2370 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.0000877  train loss: 0.1491 acc: 0.9722  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.0000846  train loss: 0.1638 acc: 0.9699  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.0000812  train loss: 0.0840 acc: 0.9815  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.0000776  train loss: 0.0845 acc: 0.9838  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.0000737  train loss: 0.0659 acc: 0.9884  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.0000697  train loss: 0.1049 acc: 0.9838  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.0000655  train loss: 0.0724 acc: 0.9907  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.0000611  train loss: 0.0074 acc: 0.9977  val loss: 0.0019 acc: 1.0000\n",
      "Epoch 30/50 lr:0.0000567  train loss: 0.0594 acc: 0.9792  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.0000523  train loss: 0.1000 acc: 0.9745  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.0000478  train loss: 0.0269 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.0000433  train loss: 0.0081 acc: 0.9954  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.0000389  train loss: 0.0048 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.0000346  train loss: 0.1244 acc: 0.9884  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.0000304  train loss: 0.0042 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.0000263  train loss: 0.1517 acc: 0.9861  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.0000225  train loss: 0.0054 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.0000189  train loss: 0.2204 acc: 0.9606  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.0000155  train loss: 0.0656 acc: 0.9884  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.0000124  train loss: 0.0070 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.0000096  train loss: 0.0278 acc: 0.9861  val loss: 0.0103 acc: 1.0000\n",
      "Epoch 43/50 lr:0.0000071  train loss: 0.0079 acc: 0.9977  val loss: 0.9973 acc: 0.9792\n",
      "Epoch 44/50 lr:0.0000050  train loss: 0.0248 acc: 0.9977  val loss: 0.9230 acc: 0.9792\n",
      "Epoch 45/50 lr:0.0000032  train loss: 0.0570 acc: 0.9792  val loss: 0.8357 acc: 0.9792\n",
      "Epoch 46/50 lr:0.0000018  train loss: 0.2025 acc: 0.9653  val loss: 1.0115 acc: 0.9792\n",
      "Epoch 47/50 lr:0.0000008  train loss: 0.0403 acc: 0.9884  val loss: 0.8808 acc: 0.9792\n",
      "Epoch 48/50 lr:0.0000002  train loss: 0.0047 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.0000000  train loss: 0.0314 acc: 0.9907  val loss: 0.8600 acc: 0.9792\n",
      "Training complete in 1m 20s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-20 02:02:17,975 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_threshold: 6.262478673778186 # Threshold k-sigma [2.0]\n",
      "distance_threshold: 0.17656530066135634 # Threshold max FPR [0.1]\n",
      "distance_threshold: 0.1193174549428296 # Threshold min TPR [1.0]\n",
      "distance_norm_factor: 0.023907307535409927\n",
      "Results: {'target': ['zipper'], 'auc': [0.928046218487395], 'th_k_sigma': [6.262478673778186], 'th_fpr': [0.17656530066135634], 'th_tpr': [0.1193174549428296], 'norm_factor': [0.023907307535409927], 'pauc': [0.8534940291906237]}\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_MVTecAD(dataroot, anotwin.AnoTwinDet , params,\n",
    "                           # test_targets=['toothbrush'],  # uncomment if you try only what you are interested\n",
    "                           # skip_preprocess=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>auc</th>\n",
       "      <th>th_k_sigma</th>\n",
       "      <th>th_fpr</th>\n",
       "      <th>th_tpr</th>\n",
       "      <th>norm_factor</th>\n",
       "      <th>pauc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottle</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.478381</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.401418</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cable</td>\n",
       "      <td>0.937406</td>\n",
       "      <td>2.532378</td>\n",
       "      <td>0.722913</td>\n",
       "      <td>0.476618</td>\n",
       "      <td>0.081744</td>\n",
       "      <td>0.861319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capsule</td>\n",
       "      <td>0.885521</td>\n",
       "      <td>6.521823</td>\n",
       "      <td>0.102548</td>\n",
       "      <td>0.067857</td>\n",
       "      <td>0.035327</td>\n",
       "      <td>0.733588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carpet</td>\n",
       "      <td>0.929374</td>\n",
       "      <td>3.186102</td>\n",
       "      <td>0.066399</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.138546</td>\n",
       "      <td>0.886796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>5.641073</td>\n",
       "      <td>0.073718</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>0.722552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hazelnut</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>2.932768</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>0.176924</td>\n",
       "      <td>0.962406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leather</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.634012</td>\n",
       "      <td>0.093808</td>\n",
       "      <td>0.093808</td>\n",
       "      <td>0.229266</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metal_nut</td>\n",
       "      <td>0.923265</td>\n",
       "      <td>4.012503</td>\n",
       "      <td>0.077113</td>\n",
       "      <td>0.047585</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.899161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pill</td>\n",
       "      <td>0.899891</td>\n",
       "      <td>5.350017</td>\n",
       "      <td>0.101378</td>\n",
       "      <td>0.060813</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.788670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>screw</td>\n",
       "      <td>0.427137</td>\n",
       "      <td>1.920243</td>\n",
       "      <td>1.289934</td>\n",
       "      <td>0.503651</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.524169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tile</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>3.611452</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>0.054956</td>\n",
       "      <td>0.078880</td>\n",
       "      <td>0.902597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>toothbrush</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>3.768961</td>\n",
       "      <td>0.141022</td>\n",
       "      <td>0.094530</td>\n",
       "      <td>0.121863</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transistor</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>6.867415</td>\n",
       "      <td>0.154172</td>\n",
       "      <td>0.079289</td>\n",
       "      <td>0.035320</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wood</td>\n",
       "      <td>0.985965</td>\n",
       "      <td>3.062473</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>0.249142</td>\n",
       "      <td>0.986611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zipper</td>\n",
       "      <td>0.928046</td>\n",
       "      <td>6.262479</td>\n",
       "      <td>0.176565</td>\n",
       "      <td>0.119317</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>0.853494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target       auc  th_k_sigma    th_fpr    th_tpr  norm_factor  \\\n",
       "0       bottle  1.000000    2.478381  0.039099  0.039099     0.401418   \n",
       "1        cable  0.937406    2.532378  0.722913  0.476618     0.081744   \n",
       "2      capsule  0.885521    6.521823  0.102548  0.067857     0.035327   \n",
       "3       carpet  0.929374    3.186102  0.066399  0.029433     0.138546   \n",
       "4         grid  0.809524    5.641073  0.073718  0.021469     0.044487   \n",
       "5     hazelnut  0.992857    2.932768  0.057144  0.057144     0.176924   \n",
       "6      leather  1.000000    2.634012  0.093808  0.093808     0.229266   \n",
       "7    metal_nut  0.923265    4.012503  0.077113  0.047585     0.087146   \n",
       "8         pill  0.899891    5.350017  0.101378  0.060813     0.070524   \n",
       "9        screw  0.427137    1.920243  1.289934  0.503651     0.003222   \n",
       "10        tile  0.960317    3.611452  0.082864  0.054956     0.078880   \n",
       "11  toothbrush  0.913889    3.768961  0.141022  0.094530     0.121863   \n",
       "12  transistor  0.862500    6.867415  0.154172  0.079289     0.035320   \n",
       "13        wood  0.985965    3.062473  0.015921  0.011051     0.249142   \n",
       "14      zipper  0.928046    6.262479  0.176565  0.119317     0.023907   \n",
       "\n",
       "        pauc  \n",
       "0   1.000000  \n",
       "1   0.861319  \n",
       "2   0.733588  \n",
       "3   0.886796  \n",
       "4   0.722552  \n",
       "5   0.962406  \n",
       "6   1.000000  \n",
       "7   0.899161  \n",
       "8   0.788670  \n",
       "9   0.524169  \n",
       "10  0.902597  \n",
       "11  0.912281  \n",
       "12  0.754386  \n",
       "13  0.986611  \n",
       "14  0.853494  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params.scheduler = 'OneCycleLR' 0.0001\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataroot = Path(dataroot)\n",
    "test_target = 'toothbrush'\n",
    "\n",
    "target_data = dataroot/test_target\n",
    "train_files = sorted(target_data.glob(f'train/good/*.png'))\n",
    "test_files = sorted(target_data.glob(f'test/*/*.png'))\n",
    "test_labels = [f.parent.name for f in test_files]\n",
    "test_y_trues = [label != 'good' for label in test_labels]\n",
    "\n",
    "det = anotwin.AnoTwinDet(params=params)\n",
    "det.prepare_experiment()\n",
    "det.create_model()\n",
    "det.setup_train(train_files)\n",
    "det.train_model(train_files)\n",
    "\n",
    "det.setup_runtime(train_files)\n",
    "values = det.evaluate_test(test_files, test_y_trues, test_labels=test_labels)\n",
    "# auc, pauc, norm_threshs, norm_factor, scores, raw_scores = values\n",
    "\n",
    "det.visualize_after_eval(values, test_files, test_labels, test_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det.show_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det.show_twin_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det.close_up_test(start=10, end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
