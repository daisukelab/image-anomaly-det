{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             anomaly_gray: False                         \n",
      "            app_album_tfm: none                          \n",
      "        app_dataset_class: default                       \n",
      "                 backbone: resnet34                      \n",
      "               batch_size: 16                            \n",
      "                crop_size: 224                           \t[default: 256]\n",
      "                 dataroot: /data/mvtec_ad/original       \t[default: None]\n",
      "                  gpu_ids: 0                             \n",
      "                load_size: 256                           \t[default: 286]\n",
      "                       lr: 0.0003                        \t[default: 0.001]\n",
      "                  lr_step: 10                            \n",
      "                    model: arc_face                      \n",
      "                 n_epochs: 50                            \t[default: 30]\n",
      "                  no_norm: False                         \n",
      "              num_threads: 12                            \t[default: 4]\n",
      "                  project: mvtecad_anotwin               \t[default: your_project]\n",
      "                   suffix: .png                          \n",
      "             weight_decay: 0.95                          \n",
      "                  weights:                               \n",
      "                     work: work                          \n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *\n",
    "\n",
    "sys.path.append('..')\n",
    "import anotwin\n",
    "from utils import *\n",
    "\n",
    "opt = Options((\"--dataroot /data/mvtec_ad/original \"\n",
    "               \"--project mvtecad_anotwin \"\n",
    "               \"--load_size 256 \"\n",
    "               \"--crop_size 224 \"\n",
    "               \"--suffix .png \"\n",
    "               \"--n_epochs 50 \"\n",
    "               \"--lr 0.0003 \"\n",
    "               \"--num_threads 12 \"\n",
    "               \"--backbone resnet34 \"\n",
    "              )).parse()\n",
    "\n",
    "\n",
    "params = EasyDict()\n",
    "params.project = opt.project\n",
    "params.work_folder = 'tmp'\n",
    "params.valid_pct = 0.2\n",
    "params.suffix = opt.suffix\n",
    "params.n_mosts = 4\n",
    "params.load_size = opt.load_size\n",
    "params.crop_size = opt.crop_size\n",
    "params.batch_size = opt.batch_size\n",
    "params.n_epochs = opt.n_epochs\n",
    "params.workers = opt.num_threads\n",
    "params.model = 'arc_face'\n",
    "params.backbone = opt.backbone\n",
    "params.train_album_tfm = None\n",
    "params.train_tfm = None\n",
    "params.dataset_cls = anotwin.DefectOnBlobDataset\n",
    "params.val_ds_cls = anotwin.AsIsDataset\n",
    "params.logger=None\n",
    "params.lr = opt.lr\n",
    "params.lr_step = opt.lr_step\n",
    "params.weight_decay = opt.weight_decay\n",
    "params.data = {}\n",
    "params.data.width_min = 1\n",
    "params.data.width_max = 10\n",
    "params.data.length_max = 40\n",
    "params.data.color = not opt.anomaly_gray\n",
    "params.data.pre_crop_rect = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-31 23:59:56,150 dlcliche.utils add_good_samples [DEBUG]: Adding 209 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n",
      "\n",
      "--- Start evaluating [bottle] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-31 23:59:58,087 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.6093 acc: 0.0000  val loss: 14.4624 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.462369\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.2573 acc: 0.0000  val loss: 14.0323 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.032298\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.0452 acc: 0.0000  val loss: 13.6333 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.633331\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.6111 acc: 0.0000  val loss: 13.0654 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.065431\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.5498 acc: 0.0000  val loss: 12.6737 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.673702\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.1449 acc: 0.0000  val loss: 12.3485 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.348530\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 12.9345 acc: 0.0000  val loss: 11.9289 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.928944\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 12.6277 acc: 0.0000  val loss: 11.0929 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.092942\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 12.4139 acc: 0.0000  val loss: 11.1116 acc: 0.0000\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 12.3123 acc: 0.0000  val loss: 10.2764 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.276446\n",
      "Training complete in 0m 17s\n",
      "Best val Acc/Loss: 0.000000/10.276446\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 11.4601 acc: 0.0000  val loss: 8.8374 acc: 0.0357\n",
      "Update: Best val acc/loss: 0.035714/8.837362\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 10.1747 acc: 0.0000  val loss: 7.1716 acc: 0.1190\n",
      "Update: Best val acc/loss: 0.119048/7.171595\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 8.6158 acc: 0.0210  val loss: 4.9031 acc: 0.3571\n",
      "Update: Best val acc/loss: 0.357143/4.903070\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 6.6972 acc: 0.0838  val loss: 4.3045 acc: 0.6190\n",
      "Update: Best val acc/loss: 0.619048/4.304506\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 4.9476 acc: 0.2455  val loss: 3.5035 acc: 0.7500\n",
      "Update: Best val acc/loss: 0.750000/3.503475\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 4.2916 acc: 0.4431  val loss: 3.2543 acc: 0.7976\n",
      "Update: Best val acc/loss: 0.797619/3.254273\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 3.2651 acc: 0.5599  val loss: 2.5550 acc: 0.8571\n",
      "Update: Best val acc/loss: 0.857143/2.555027\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 2.5434 acc: 0.6826  val loss: 1.3944 acc: 0.9286\n",
      "Update: Best val acc/loss: 0.928571/1.394368\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.7616 acc: 0.7545  val loss: 2.2198 acc: 0.9048\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.7389 acc: 0.7246  val loss: 1.1321 acc: 0.9643\n",
      "Update: Best val acc/loss: 0.964286/1.132071\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 0.9562 acc: 0.8713  val loss: 1.4228 acc: 0.9286\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 1.0005 acc: 0.8413  val loss: 0.5688 acc: 0.9643\n",
      "Update: Best val acc/loss: 0.964286/0.568844\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 1.0341 acc: 0.8234  val loss: 1.0819 acc: 0.9524\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.9435 acc: 0.8503  val loss: 1.5869 acc: 0.9524\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.7367 acc: 0.8713  val loss: 0.5028 acc: 0.9881\n",
      "Update: Best val acc/loss: 0.988095/0.502806\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.7840 acc: 0.9162  val loss: 0.9718 acc: 0.9643\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 1.2720 acc: 0.8623  val loss: 0.8148 acc: 0.9643\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.6916 acc: 0.9401  val loss: 0.0014 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.001436\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.5176 acc: 0.9371  val loss: 1.4019 acc: 0.9643\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.6122 acc: 0.9311  val loss: 0.1465 acc: 0.9881\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.4478 acc: 0.9551  val loss: 0.5141 acc: 0.9881\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.7360 acc: 0.9042  val loss: 0.9702 acc: 0.9762\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.5216 acc: 0.9551  val loss: 0.0859 acc: 0.9881\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.7046 acc: 0.9341  val loss: 1.0063 acc: 0.9762\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.5836 acc: 0.9311  val loss: 0.9646 acc: 0.9762\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.2146 acc: 0.9611  val loss: 0.9758 acc: 0.9762\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.2710 acc: 0.9790  val loss: 0.8674 acc: 0.9762\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.5647 acc: 0.9162  val loss: 1.0581 acc: 0.9762\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.4593 acc: 0.9251  val loss: 1.0749 acc: 0.9762\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.0615 acc: 0.9671  val loss: 0.5311 acc: 0.9881\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.5601 acc: 0.9162  val loss: 0.5034 acc: 0.9881\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.5023 acc: 0.9012  val loss: 0.5323 acc: 0.9881\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.6726 acc: 0.9162  val loss: 0.5314 acc: 0.9881\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.2803 acc: 0.9820  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.3038 acc: 0.9551  val loss: 1.0820 acc: 0.9762\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.1111 acc: 0.9850  val loss: 0.9506 acc: 0.9762\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.3440 acc: 0.9820  val loss: 0.5469 acc: 0.9881\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.4696 acc: 0.9431  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.0741 acc: 0.9701  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.3303 acc: 0.9850  val loss: 0.5423 acc: 0.9881\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.1282 acc: 0.9880  val loss: 1.0846 acc: 0.9762\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.2621 acc: 0.9790  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.0701 acc: 0.9731  val loss: 1.0767 acc: 0.9762\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.2203 acc: 0.9940  val loss: 0.0306 acc: 0.9881\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.7690 acc: 0.9222  val loss: 0.5390 acc: 0.9762\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.1152 acc: 0.9910  val loss: 0.5356 acc: 0.9881\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.0190 acc: 0.9940  val loss: 0.5364 acc: 0.9881\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.2207 acc: 0.9790  val loss: 0.5492 acc: 0.9881\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.1084 acc: 0.9970  val loss: 0.0489 acc: 0.9881\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.1122 acc: 0.9970  val loss: 0.5442 acc: 0.9881\n",
      "Training complete in 1m 56s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:02:11,116 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:02:11,149 dlcliche.utils create_model [INFO]:  using model weight: weights_bottle\n",
      "2020-04-01 00:02:12,149 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:02:12,973 dlcliche.utils add_good_samples [DEBUG]: Adding 224 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['bottle'], 'auc': [1.0]}\n",
      "\n",
      "--- Start evaluating [cable] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:02:14,125 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.4504 acc: 0.0000  val loss: 14.2417 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.241716\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.2824 acc: 0.0000  val loss: 14.1187 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.118657\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.2981 acc: 0.0000  val loss: 13.9697 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.969709\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 14.2374 acc: 0.0000  val loss: 13.9468 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.946774\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 14.2743 acc: 0.0000  val loss: 13.8101 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.810065\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 14.1093 acc: 0.0000  val loss: 13.6902 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.690226\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 14.0240 acc: 0.0000  val loss: 13.6821 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.682076\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.8921 acc: 0.0000  val loss: 13.6295 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.629530\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 13.8991 acc: 0.0000  val loss: 13.4507 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.450723\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 13.8245 acc: 0.0000  val loss: 13.3414 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.341416\n",
      "Training complete in 0m 26s\n",
      "Best val Acc/Loss: 0.000000/13.341416\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 13.8798 acc: 0.0000  val loss: 13.0159 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.015862\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 13.6255 acc: 0.0000  val loss: 12.6311 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.631070\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 13.2701 acc: 0.0000  val loss: 12.4445 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.444511\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 12.9225 acc: 0.0000  val loss: 11.3850 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.384986\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 12.1353 acc: 0.0000  val loss: 9.7992 acc: 0.0333\n",
      "Update: Best val acc/loss: 0.033333/9.799228\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 11.2116 acc: 0.0000  val loss: 7.9636 acc: 0.1889\n",
      "Update: Best val acc/loss: 0.188889/7.963562\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 9.5316 acc: 0.0196  val loss: 5.2883 acc: 0.3222\n",
      "Update: Best val acc/loss: 0.322222/5.288297\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 7.4922 acc: 0.0978  val loss: 4.2996 acc: 0.4889\n",
      "Update: Best val acc/loss: 0.488889/4.299622\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 5.1885 acc: 0.2542  val loss: 3.4218 acc: 0.7333\n",
      "Update: Best val acc/loss: 0.733333/3.421813\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 3.7390 acc: 0.4134  val loss: 1.9689 acc: 0.8111\n",
      "Update: Best val acc/loss: 0.811111/1.968933\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 2.9183 acc: 0.5866  val loss: 2.5040 acc: 0.8444\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 2.4269 acc: 0.6872  val loss: 1.6748 acc: 0.9111\n",
      "Update: Best val acc/loss: 0.911111/1.674787\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 1.8838 acc: 0.7263  val loss: 1.7285 acc: 0.9333\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 1.6410 acc: 0.8464  val loss: 1.7408 acc: 0.9333\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 1.6763 acc: 0.7849  val loss: 1.2244 acc: 0.9556\n",
      "Update: Best val acc/loss: 0.955556/1.224417\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 1.3995 acc: 0.8575  val loss: 1.4584 acc: 0.9444\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 1.3952 acc: 0.8464  val loss: 1.7296 acc: 0.9556\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 1.2072 acc: 0.8436  val loss: 1.5392 acc: 0.9556\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 1.4622 acc: 0.8743  val loss: 1.6889 acc: 0.9333\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 1.2647 acc: 0.8827  val loss: 1.2812 acc: 0.9556\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 1.2120 acc: 0.9162  val loss: 1.3712 acc: 0.9667\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 1.2467 acc: 0.9246  val loss: 1.1058 acc: 0.9556\n",
      "Update: Best val acc/loss: 0.955556/1.105848\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 1.2157 acc: 0.9050  val loss: 2.0943 acc: 0.9444\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 1.4349 acc: 0.8966  val loss: 2.2232 acc: 0.9333\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 1.5147 acc: 0.8911  val loss: 1.3570 acc: 0.9667\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 1.5298 acc: 0.8436  val loss: 1.2180 acc: 0.9556\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 1.1084 acc: 0.9078  val loss: 1.2358 acc: 0.9333\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 1.3849 acc: 0.8771  val loss: 1.8413 acc: 0.9556\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 1.1502 acc: 0.9022  val loss: 1.1887 acc: 0.9556\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 1.2977 acc: 0.9050  val loss: 0.9725 acc: 0.9667\n",
      "Update: Best val acc/loss: 0.966667/0.972519\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.7693 acc: 0.9413  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000005\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.9514 acc: 0.9246  val loss: 0.9547 acc: 0.9667\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.5820 acc: 0.9553  val loss: 1.3710 acc: 0.9667\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.8894 acc: 0.9469  val loss: 1.5897 acc: 0.9556\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.8657 acc: 0.9637  val loss: 0.9320 acc: 0.9778\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.3392 acc: 0.9832  val loss: 1.0812 acc: 0.9667\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 1.1061 acc: 0.8883  val loss: 1.7913 acc: 0.9556\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 1.0422 acc: 0.8911  val loss: 0.8538 acc: 0.9667\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.9579 acc: 0.9078  val loss: 1.5569 acc: 0.9556\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.8093 acc: 0.9469  val loss: 1.0337 acc: 0.9556\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 1.0729 acc: 0.9274  val loss: 1.6033 acc: 0.9556\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.3348 acc: 0.9804  val loss: 0.6429 acc: 0.9778\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.8067 acc: 0.9441  val loss: 0.6684 acc: 0.9778\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.9677 acc: 0.9302  val loss: 1.4233 acc: 0.9667\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.6854 acc: 0.9721  val loss: 1.2527 acc: 0.9667\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.7017 acc: 0.9441  val loss: 1.7524 acc: 0.9444\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 1.1503 acc: 0.9022  val loss: 0.4775 acc: 0.9889\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.8706 acc: 0.9693  val loss: 0.8914 acc: 0.9778\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.7743 acc: 0.9553  val loss: 1.7509 acc: 0.9556\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 1.2218 acc: 0.8687  val loss: 1.1833 acc: 0.9556\n",
      "Training complete in 2m 29s\n",
      "Best val Acc/Loss: 1.000000/0.000005\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:05:08,829 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:05:08,862 dlcliche.utils create_model [INFO]:  using model weight: weights_cable\n",
      "2020-04-01 00:05:10,267 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:05:11,838 dlcliche.utils add_good_samples [DEBUG]: Adding 219 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['cable'], 'auc': [0.9338455772113943]}\n",
      "\n",
      "--- Start evaluating [capsule] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:05:12,633 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.0344 acc: 0.0000  val loss: 13.3708 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.370750\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.6696 acc: 0.0000  val loss: 13.0028 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.002799\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.2183 acc: 0.0000  val loss: 12.2639 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.263926\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 12.8154 acc: 0.0000  val loss: 11.7209 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.720862\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 12.6210 acc: 0.0000  val loss: 10.7468 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.746833\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 12.3543 acc: 0.0000  val loss: 10.7817 acc: 0.0000\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 11.8670 acc: 0.0000  val loss: 9.9091 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.909082\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 11.4817 acc: 0.0000  val loss: 8.7570 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.757028\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 11.1118 acc: 0.0000  val loss: 8.6731 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.673055\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 10.9315 acc: 0.0000  val loss: 7.9189 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/7.918871\n",
      "Training complete in 0m 25s\n",
      "Best val Acc/Loss: 0.000000/7.918871\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 9.9996 acc: 0.0029  val loss: 5.5229 acc: 0.2727\n",
      "Update: Best val acc/loss: 0.272727/5.522913\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 7.9807 acc: 0.0143  val loss: 3.7725 acc: 0.5114\n",
      "Update: Best val acc/loss: 0.511364/3.772506\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 6.2963 acc: 0.1229  val loss: 2.7287 acc: 0.7273\n",
      "Update: Best val acc/loss: 0.727273/2.728666\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 4.2351 acc: 0.3429  val loss: 2.3982 acc: 0.8523\n",
      "Update: Best val acc/loss: 0.852273/2.398168\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 2.8872 acc: 0.5457  val loss: 1.6535 acc: 0.9318\n",
      "Update: Best val acc/loss: 0.931818/1.653460\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 2.0679 acc: 0.6486  val loss: 1.8526 acc: 0.8864\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 1.7823 acc: 0.7143  val loss: 1.7597 acc: 0.9205\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 1.0424 acc: 0.8371  val loss: 0.4632 acc: 0.9659\n",
      "Update: Best val acc/loss: 0.965909/0.463176\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 0.8321 acc: 0.8743  val loss: 0.3170 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.317042\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.4637 acc: 0.7943  val loss: 0.4474 acc: 0.9886\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 0.5634 acc: 0.9229  val loss: 0.0441 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.044052\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.9693 acc: 0.8429  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000149\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.9489 acc: 0.8629  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000109\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.1958 acc: 0.9229  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.5370 acc: 0.9286  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.7150 acc: 0.8943  val loss: 0.2325 acc: 0.9886\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.5155 acc: 0.9314  val loss: 0.1127 acc: 0.9886\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.1888 acc: 0.9686  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.7416 acc: 0.9143  val loss: 0.0017 acc: 1.0000\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.5026 acc: 0.9257  val loss: 0.3146 acc: 0.9773\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.3446 acc: 0.9429  val loss: 0.1639 acc: 0.9886\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.3536 acc: 0.9571  val loss: 0.5802 acc: 0.9773\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.3218 acc: 0.9486  val loss: 0.6273 acc: 0.9773\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.3472 acc: 0.9171  val loss: 0.1843 acc: 0.9886\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.4168 acc: 0.9429  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.1368 acc: 0.9457  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.2331 acc: 0.9829  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.2440 acc: 0.9629  val loss: 0.2748 acc: 0.9659\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.1676 acc: 0.9743  val loss: 0.4970 acc: 0.9886\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.1622 acc: 0.9600  val loss: 0.2139 acc: 0.9886\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.4627 acc: 0.9571  val loss: 0.3643 acc: 0.9886\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.1584 acc: 0.9743  val loss: 0.2201 acc: 0.9886\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.0462 acc: 0.9886  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.1521 acc: 0.9743  val loss: 0.1661 acc: 0.9773\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.0154 acc: 0.9914  val loss: 0.5142 acc: 0.9773\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.1555 acc: 0.9800  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.1900 acc: 0.9600  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.0531 acc: 0.9800  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.1776 acc: 0.9571  val loss: 0.4886 acc: 0.9773\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.1078 acc: 0.9743  val loss: 0.0961 acc: 0.9886\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0038 acc: 1.0000  val loss: 0.0090 acc: 0.9886\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0751 acc: 0.9829  val loss: 0.1424 acc: 0.9886\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.0322 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.0215 acc: 0.9943  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.0413 acc: 0.9829  val loss: 0.1026 acc: 0.9886\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.0032 acc: 1.0000  val loss: 0.0399 acc: 0.9886\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.0874 acc: 0.9857  val loss: 0.0553 acc: 0.9886\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.0064 acc: 0.9971  val loss: 0.0602 acc: 0.9886\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.0791 acc: 0.9771  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.1320 acc: 0.9600  val loss: 0.2140 acc: 0.9886\n",
      "Training complete in 2m 23s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:08:00,635 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:08:00,664 dlcliche.utils create_model [INFO]:  using model weight: weights_capsule\n",
      "2020-04-01 00:08:02,114 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:08:03,376 dlcliche.utils add_good_samples [DEBUG]: Adding 280 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['capsule'], 'auc': [0.8703629836457919]}\n",
      "\n",
      "--- Start evaluating [carpet] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:08:04,941 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.2929 acc: 0.0000  val loss: 14.4252 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.425153\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.2799 acc: 0.0000  val loss: 13.9135 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.913532\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.0369 acc: 0.0000  val loss: 13.5659 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.565918\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.8656 acc: 0.0000  val loss: 13.3169 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.316922\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.5193 acc: 0.0000  val loss: 12.9695 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.969459\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.4324 acc: 0.0000  val loss: 12.7173 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.717282\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 13.2992 acc: 0.0000  val loss: 12.4906 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.490552\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.0709 acc: 0.0000  val loss: 12.0647 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.064676\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 12.8787 acc: 0.0000  val loss: 11.8417 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.841670\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 12.8012 acc: 0.0000  val loss: 11.3373 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.337336\n",
      "Training complete in 0m 30s\n",
      "Best val Acc/Loss: 0.000000/11.337336\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 12.3422 acc: 0.0000  val loss: 10.2845 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.284541\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 11.4952 acc: 0.0000  val loss: 8.4527 acc: 0.1429\n",
      "Update: Best val acc/loss: 0.142857/8.452749\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 10.0232 acc: 0.0156  val loss: 6.9919 acc: 0.2500\n",
      "Update: Best val acc/loss: 0.250000/6.991914\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 8.3326 acc: 0.0558  val loss: 5.4727 acc: 0.2857\n",
      "Update: Best val acc/loss: 0.285714/5.472733\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 6.4369 acc: 0.1496  val loss: 3.1997 acc: 0.5982\n",
      "Update: Best val acc/loss: 0.598214/3.199695\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 4.5927 acc: 0.3415  val loss: 2.5660 acc: 0.7768\n",
      "Update: Best val acc/loss: 0.776786/2.565992\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 3.6928 acc: 0.4442  val loss: 1.4868 acc: 0.9107\n",
      "Update: Best val acc/loss: 0.910714/1.486789\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 2.6774 acc: 0.5871  val loss: 1.3910 acc: 0.9018\n",
      "Update: Best val acc/loss: 0.901786/1.390987\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.9675 acc: 0.7210  val loss: 1.4211 acc: 0.9464\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 2.0093 acc: 0.7254  val loss: 1.2274 acc: 0.9554\n",
      "Update: Best val acc/loss: 0.955357/1.227359\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 1.6466 acc: 0.7991  val loss: 1.3596 acc: 0.9464\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 1.0171 acc: 0.8750  val loss: 0.3935 acc: 0.9821\n",
      "Update: Best val acc/loss: 0.982143/0.393490\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.9063 acc: 0.8839  val loss: 0.7151 acc: 0.9821\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.8895 acc: 0.8705  val loss: 0.7306 acc: 0.9732\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 1.3831 acc: 0.8415  val loss: 1.0349 acc: 0.9732\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.7293 acc: 0.9196  val loss: 1.4435 acc: 0.9643\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 1.2547 acc: 0.8661  val loss: 1.4812 acc: 0.9643\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.7214 acc: 0.9420  val loss: 1.8262 acc: 0.9554\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.7788 acc: 0.9353  val loss: 1.1297 acc: 0.9732\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.9520 acc: 0.9219  val loss: 0.9699 acc: 0.9732\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.8747 acc: 0.9174  val loss: 0.9203 acc: 0.9732\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.7482 acc: 0.9487  val loss: 0.7504 acc: 0.9821\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.6315 acc: 0.9554  val loss: 0.7586 acc: 0.9821\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.9243 acc: 0.9464  val loss: 0.7448 acc: 0.9821\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.5262 acc: 0.9621  val loss: 1.0692 acc: 0.9732\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.4635 acc: 0.9576  val loss: 0.3943 acc: 0.9911\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.6556 acc: 0.9219  val loss: 1.1843 acc: 0.9732\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.3197 acc: 0.9732  val loss: 0.7798 acc: 0.9821\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.7117 acc: 0.9621  val loss: 0.3748 acc: 0.9911\n",
      "Update: Best val acc/loss: 0.991071/0.374817\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.3890 acc: 0.9777  val loss: 0.3935 acc: 0.9911\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.5149 acc: 0.9554  val loss: 0.3938 acc: 0.9911\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.5489 acc: 0.9643  val loss: 0.6241 acc: 0.9821\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.4151 acc: 0.9531  val loss: 0.7295 acc: 0.9821\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.4953 acc: 0.9531  val loss: 0.3642 acc: 0.9911\n",
      "Update: Best val acc/loss: 0.991071/0.364191\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.3200 acc: 0.9442  val loss: 0.3934 acc: 0.9911\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.2317 acc: 0.9821  val loss: 0.3962 acc: 0.9911\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.3425 acc: 0.9754  val loss: 0.9450 acc: 0.9732\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.3082 acc: 0.9821  val loss: 0.4005 acc: 0.9911\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.4715 acc: 0.9487  val loss: 0.5478 acc: 0.9732\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.3980 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.3183 acc: 0.9643  val loss: 0.3871 acc: 0.9911\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.3432 acc: 0.9799  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.5503 acc: 0.9219  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.4524 acc: 0.9509  val loss: 0.7903 acc: 0.9821\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.2026 acc: 0.9777  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.4996 acc: 0.9442  val loss: 1.0247 acc: 0.9732\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.2717 acc: 0.9732  val loss: 0.6118 acc: 0.9821\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.3715 acc: 0.9777  val loss: 1.0557 acc: 0.9732\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.4049 acc: 0.9643  val loss: 1.0027 acc: 0.9732\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.2037 acc: 0.9911  val loss: 1.1825 acc: 0.9732\n",
      "Training complete in 2m 47s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:11:22,563 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:11:22,595 dlcliche.utils create_model [INFO]:  using model weight: weights_carpet\n",
      "2020-04-01 00:11:24,239 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:11:25,848 dlcliche.utils add_good_samples [DEBUG]: Adding 264 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['carpet'], 'auc': [0.8952648475120385]}\n",
      "\n",
      "--- Start evaluating [grid] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:11:26,470 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.2889 acc: 0.0000  val loss: 13.8787 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.878670\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.0628 acc: 0.0000  val loss: 13.7239 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.723905\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.9641 acc: 0.0000  val loss: 13.2679 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.267867\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.5782 acc: 0.0000  val loss: 13.0817 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.081669\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.1386 acc: 0.0000  val loss: 12.4251 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.425075\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.0540 acc: 0.0000  val loss: 11.7681 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.768105\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 12.8324 acc: 0.0000  val loss: 11.5294 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.529443\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 12.6360 acc: 0.0000  val loss: 11.0220 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.022013\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 12.2746 acc: 0.0000  val loss: 10.7697 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.769657\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 11.9659 acc: 0.0000  val loss: 10.3604 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.360377\n",
      "Training complete in 0m 15s\n",
      "Best val Acc/Loss: 0.000000/10.360377\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 11.4904 acc: 0.0000  val loss: 7.6790 acc: 0.1038\n",
      "Update: Best val acc/loss: 0.103774/7.679042\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 9.8905 acc: 0.0000  val loss: 6.3539 acc: 0.2170\n",
      "Update: Best val acc/loss: 0.216981/6.353907\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 7.8651 acc: 0.0261  val loss: 3.8434 acc: 0.4245\n",
      "Update: Best val acc/loss: 0.424528/3.843430\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 5.4595 acc: 0.1280  val loss: 2.0395 acc: 0.6321\n",
      "Update: Best val acc/loss: 0.632075/2.039469\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 3.4310 acc: 0.3104  val loss: 1.4741 acc: 0.8868\n",
      "Update: Best val acc/loss: 0.886792/1.474092\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 2.5894 acc: 0.5118  val loss: 0.9061 acc: 0.9340\n",
      "Update: Best val acc/loss: 0.933962/0.906082\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 1.8939 acc: 0.6682  val loss: 0.1118 acc: 0.9528\n",
      "Update: Best val acc/loss: 0.952830/0.111816\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 1.4178 acc: 0.7441  val loss: 0.4171 acc: 0.9811\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.0322 acc: 0.8199  val loss: 0.3988 acc: 0.9811\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.2883 acc: 0.7251  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000043\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 0.6667 acc: 0.8839  val loss: 0.7620 acc: 0.9811\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.5692 acc: 0.8910  val loss: 0.3916 acc: 0.9906\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.6816 acc: 0.8555  val loss: 0.3803 acc: 0.9906\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.4442 acc: 0.9313  val loss: 0.4133 acc: 0.9906\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.7084 acc: 0.8910  val loss: 0.0003 acc: 1.0000\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.5454 acc: 0.8910  val loss: 0.3956 acc: 0.9906\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.2782 acc: 0.9028  val loss: 0.6163 acc: 0.9811\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.3696 acc: 0.9526  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.5262 acc: 0.9100  val loss: 0.6034 acc: 0.9811\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.3332 acc: 0.9502  val loss: 0.4135 acc: 0.9906\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.3539 acc: 0.9526  val loss: 0.4011 acc: 0.9906\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.2024 acc: 0.9787  val loss: 0.4441 acc: 0.9811\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.2435 acc: 0.9336  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.0990 acc: 0.9763  val loss: 0.4229 acc: 0.9906\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.1697 acc: 0.9550  val loss: 0.8279 acc: 0.9811\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.3194 acc: 0.9645  val loss: 0.4515 acc: 0.9811\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.3562 acc: 0.9692  val loss: 0.4209 acc: 0.9906\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.3431 acc: 0.9526  val loss: 0.4017 acc: 0.9906\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.0708 acc: 0.9882  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.1250 acc: 0.9692  val loss: 0.1940 acc: 0.9906\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.2448 acc: 0.9550  val loss: 0.5071 acc: 0.9811\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.5784 acc: 0.9194  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.2000 acc: 0.9668  val loss: 0.3995 acc: 0.9906\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.2693 acc: 0.9621  val loss: 0.4351 acc: 0.9906\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.1862 acc: 0.9692  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.2653 acc: 0.9479  val loss: 0.4303 acc: 0.9906\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.2070 acc: 0.9787  val loss: 0.4321 acc: 0.9906\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.1692 acc: 0.9739  val loss: 0.4310 acc: 0.9906\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.1661 acc: 0.9882  val loss: 0.4261 acc: 0.9906\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.3365 acc: 0.9550  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0630 acc: 0.9858  val loss: 0.4344 acc: 0.9906\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.2637 acc: 0.9384  val loss: 0.0173 acc: 0.9906\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.0488 acc: 0.9858  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.1966 acc: 0.9858  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.2399 acc: 0.9597  val loss: 0.4218 acc: 0.9906\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.1462 acc: 0.9692  val loss: 0.0411 acc: 0.9906\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.1647 acc: 0.9668  val loss: 0.4409 acc: 0.9906\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.0695 acc: 0.9763  val loss: 0.0428 acc: 0.9906\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.0186 acc: 0.9905  val loss: 0.0004 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.1335 acc: 0.9834  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 1s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:13:42,641 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:13:42,672 dlcliche.utils create_model [INFO]:  using model weight: weights_grid\n",
      "2020-04-01 00:13:43,426 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:13:44,057 dlcliche.utils add_good_samples [DEBUG]: Adding 391 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['grid'], 'auc': [0.8304093567251463]}\n",
      "\n",
      "--- Start evaluating [hazelnut] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:13:45,362 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.4388 acc: 0.0000  val loss: 13.9789 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.978917\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.9294 acc: 0.0000  val loss: 13.5679 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.567938\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.8155 acc: 0.0000  val loss: 12.8860 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.886009\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.3606 acc: 0.0000  val loss: 12.2004 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.200415\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 12.9773 acc: 0.0000  val loss: 11.5684 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.568387\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 12.7013 acc: 0.0000  val loss: 11.1463 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.146270\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 12.3994 acc: 0.0000  val loss: 10.3360 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.336023\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 11.9422 acc: 0.0000  val loss: 9.8795 acc: 0.0063\n",
      "Update: Best val acc/loss: 0.006329/9.879548\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 11.5154 acc: 0.0000  val loss: 9.3832 acc: 0.0127\n",
      "Update: Best val acc/loss: 0.012658/9.383218\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 11.1344 acc: 0.0000  val loss: 8.7404 acc: 0.0380\n",
      "Update: Best val acc/loss: 0.037975/8.740400\n",
      "Training complete in 0m 35s\n",
      "Best val Acc/Loss: 0.037975/8.740400\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 10.3676 acc: 0.0048  val loss: 6.4119 acc: 0.2152\n",
      "Update: Best val acc/loss: 0.215190/6.411924\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 8.3465 acc: 0.0353  val loss: 4.3606 acc: 0.4367\n",
      "Update: Best val acc/loss: 0.436709/4.360574\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 6.4344 acc: 0.1907  val loss: 2.6053 acc: 0.7468\n",
      "Update: Best val acc/loss: 0.746835/2.605324\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 4.2792 acc: 0.4022  val loss: 1.9808 acc: 0.8228\n",
      "Update: Best val acc/loss: 0.822785/1.980773\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 2.8171 acc: 0.6122  val loss: 1.4090 acc: 0.8987\n",
      "Update: Best val acc/loss: 0.898734/1.409021\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 2.2556 acc: 0.6827  val loss: 1.5113 acc: 0.9177\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 1.9119 acc: 0.7692  val loss: 0.3980 acc: 0.9684\n",
      "Update: Best val acc/loss: 0.968354/0.397984\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 1.5372 acc: 0.8157  val loss: 0.6059 acc: 0.9620\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.3190 acc: 0.8462  val loss: 0.9385 acc: 0.9620\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.0445 acc: 0.8782  val loss: 0.7793 acc: 0.9810\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 0.8095 acc: 0.8958  val loss: 1.3639 acc: 0.9430\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.9120 acc: 0.8958  val loss: 0.5805 acc: 0.9747\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.8541 acc: 0.8990  val loss: 0.0137 acc: 0.9937\n",
      "Update: Best val acc/loss: 0.993671/0.013694\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.6129 acc: 0.9054  val loss: 0.5612 acc: 0.9873\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.7503 acc: 0.9295  val loss: 0.5312 acc: 0.9873\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.3917 acc: 0.9551  val loss: 0.2534 acc: 0.9937\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.2630 acc: 0.9599  val loss: 0.3263 acc: 0.9873\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.4995 acc: 0.9439  val loss: 1.0559 acc: 0.9684\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.4825 acc: 0.9423  val loss: 0.8240 acc: 0.9810\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.4054 acc: 0.9599  val loss: 0.7924 acc: 0.9810\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.5998 acc: 0.9503  val loss: 0.5475 acc: 0.9810\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.5034 acc: 0.9615  val loss: 0.7066 acc: 0.9810\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.3979 acc: 0.9696  val loss: 0.3214 acc: 0.9873\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.4600 acc: 0.9728  val loss: 0.5869 acc: 0.9810\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.5877 acc: 0.9535  val loss: 0.4961 acc: 0.9873\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.2616 acc: 0.9808  val loss: 0.2907 acc: 0.9937\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.0855 acc: 0.9856  val loss: 0.2903 acc: 0.9937\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.4345 acc: 0.9583  val loss: 0.2903 acc: 0.9937\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.1684 acc: 0.9904  val loss: 0.5590 acc: 0.9873\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.2498 acc: 0.9728  val loss: 0.8703 acc: 0.9747\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.3896 acc: 0.9663  val loss: 0.8011 acc: 0.9810\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.2993 acc: 0.9760  val loss: 0.6647 acc: 0.9810\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.3053 acc: 0.9599  val loss: 0.5786 acc: 0.9810\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.3914 acc: 0.9647  val loss: 1.0022 acc: 0.9747\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.2755 acc: 0.9792  val loss: 0.7888 acc: 0.9810\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.3745 acc: 0.9856  val loss: 0.8721 acc: 0.9747\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.1280 acc: 0.9936  val loss: 0.3680 acc: 0.9873\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.2842 acc: 0.9824  val loss: 0.7452 acc: 0.9810\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.3214 acc: 0.9647  val loss: 0.3649 acc: 0.9810\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.2479 acc: 0.9776  val loss: 0.9083 acc: 0.9684\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.3209 acc: 0.9824  val loss: 0.8481 acc: 0.9747\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0815 acc: 0.9936  val loss: 0.4416 acc: 0.9873\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.2668 acc: 0.9808  val loss: 0.5380 acc: 0.9873\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.2532 acc: 0.9728  val loss: 0.2948 acc: 0.9937\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.1386 acc: 0.9952  val loss: 0.2624 acc: 0.9937\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.1412 acc: 0.9872  val loss: 0.4986 acc: 0.9873\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.1667 acc: 0.9776  val loss: 0.2647 acc: 0.9937\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.1223 acc: 0.9744  val loss: 0.2532 acc: 0.9937\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.1317 acc: 0.9824  val loss: 0.5656 acc: 0.9873\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.1203 acc: 0.9936  val loss: 0.1961 acc: 0.9937\n",
      "Training complete in 3m 18s\n",
      "Best val Acc/Loss: 0.993671/0.013694\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:17:38,831 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:17:38,864 dlcliche.utils create_model [INFO]:  using model weight: weights_hazelnut\n",
      "2020-04-01 00:17:40,545 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:17:41,745 dlcliche.utils add_good_samples [DEBUG]: Adding 245 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['hazelnut'], 'auc': [1.0]}\n",
      "\n",
      "--- Start evaluating [leather] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:17:42,738 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.0837 acc: 0.0000  val loss: 14.2660 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.266034\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.8077 acc: 0.0000  val loss: 13.5861 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.586122\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.6457 acc: 0.0000  val loss: 12.7620 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.762035\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.2853 acc: 0.0000  val loss: 12.1918 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.191775\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.2598 acc: 0.0000  val loss: 11.6983 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.698296\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 12.8819 acc: 0.0000  val loss: 11.6084 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.608391\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 12.6760 acc: 0.0000  val loss: 10.7500 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.749984\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 12.4717 acc: 0.0000  val loss: 10.0386 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.038597\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 12.0267 acc: 0.0000  val loss: 9.7553 acc: 0.0102\n",
      "Update: Best val acc/loss: 0.010204/9.755271\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 11.6562 acc: 0.0000  val loss: 9.5108 acc: 0.0408\n",
      "Update: Best val acc/loss: 0.040816/9.510786\n",
      "Training complete in 0m 22s\n",
      "Best val Acc/Loss: 0.040816/9.510786\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 11.0523 acc: 0.0000  val loss: 8.0135 acc: 0.1633\n",
      "Update: Best val acc/loss: 0.163265/8.013546\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 9.8595 acc: 0.0128  val loss: 5.8717 acc: 0.2755\n",
      "Update: Best val acc/loss: 0.275510/5.871698\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 8.3690 acc: 0.0536  val loss: 4.2695 acc: 0.3980\n",
      "Update: Best val acc/loss: 0.397959/4.269486\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 6.5539 acc: 0.1378  val loss: 2.5680 acc: 0.6122\n",
      "Update: Best val acc/loss: 0.612245/2.568039\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 5.1000 acc: 0.2526  val loss: 2.2884 acc: 0.8265\n",
      "Update: Best val acc/loss: 0.826531/2.288393\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 3.6033 acc: 0.4260  val loss: 0.8150 acc: 0.9286\n",
      "Update: Best val acc/loss: 0.928571/0.814983\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 2.1044 acc: 0.6199  val loss: 0.9434 acc: 0.9490\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 2.0487 acc: 0.6684  val loss: 1.0945 acc: 0.9490\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.5362 acc: 0.7194  val loss: 0.3895 acc: 0.9796\n",
      "Update: Best val acc/loss: 0.979592/0.389501\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.3073 acc: 0.8010  val loss: 0.5743 acc: 0.9796\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 1.3913 acc: 0.8138  val loss: 0.6925 acc: 0.9694\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 1.0115 acc: 0.8240  val loss: 0.0768 acc: 0.9898\n",
      "Update: Best val acc/loss: 0.989796/0.076754\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 1.0461 acc: 0.8444  val loss: 0.2627 acc: 0.9898\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.8424 acc: 0.8699  val loss: 0.6577 acc: 0.9796\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.9985 acc: 0.8342  val loss: 0.0118 acc: 0.9898\n",
      "Update: Best val acc/loss: 0.989796/0.011830\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.6307 acc: 0.9005  val loss: 0.1790 acc: 0.9898\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.3551 acc: 0.9643  val loss: 0.4463 acc: 0.9898\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.2503 acc: 0.9617  val loss: 0.4418 acc: 0.9898\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.2540 acc: 0.9745  val loss: 0.2905 acc: 0.9898\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.5457 acc: 0.8903  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000115\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.4969 acc: 0.9286  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000080\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.5928 acc: 0.8827  val loss: 0.0893 acc: 0.9898\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.8057 acc: 0.9260  val loss: 0.0002 acc: 1.0000\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.1595 acc: 0.9694  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.2149 acc: 0.9694  val loss: 0.1821 acc: 0.9898\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.1559 acc: 0.9719  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.3071 acc: 0.9668  val loss: 0.8055 acc: 0.9796\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.1996 acc: 0.9617  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.0679 acc: 0.9898  val loss: 0.0346 acc: 0.9898\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.5569 acc: 0.9388  val loss: 0.5445 acc: 0.9796\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.7067 acc: 0.9235  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.1858 acc: 0.9821  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.0453 acc: 0.9898  val loss: 0.4131 acc: 0.9898\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.0250 acc: 0.9847  val loss: 0.4606 acc: 0.9898\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.1469 acc: 0.9668  val loss: 0.8609 acc: 0.9796\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.0393 acc: 0.9796  val loss: 0.4672 acc: 0.9898\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.1926 acc: 0.9796  val loss: 0.9900 acc: 0.9694\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.1668 acc: 0.9719  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.2764 acc: 0.9643  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.0573 acc: 0.9923  val loss: 0.0299 acc: 0.9898\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0353 acc: 0.9898  val loss: 0.4170 acc: 0.9898\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0049 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.2557 acc: 0.9388  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.2201 acc: 0.9745  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.2524 acc: 0.9592  val loss: 0.4624 acc: 0.9898\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.2119 acc: 0.9745  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.0916 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.1586 acc: 0.9668  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.0705 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.0238 acc: 0.9872  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 21s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:20:26,024 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:20:26,053 dlcliche.utils create_model [INFO]:  using model weight: weights_leather\n",
      "2020-04-01 00:20:27,234 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:20:28,639 dlcliche.utils add_good_samples [DEBUG]: Adding 220 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['leather'], 'auc': [1.0]}\n",
      "\n",
      "--- Start evaluating [metal_nut] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:20:29,186 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.3211 acc: 0.0000  val loss: 13.9751 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.975141\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.3192 acc: 0.0000  val loss: 13.8865 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.886531\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.2935 acc: 0.0000  val loss: 13.8859 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.885884\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 14.1484 acc: 0.0000  val loss: 13.5419 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.541916\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.8717 acc: 0.0000  val loss: 13.6476 acc: 0.0000\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.6618 acc: 0.0000  val loss: 13.3375 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.337530\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 13.6880 acc: 0.0000  val loss: 13.0603 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.060270\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.4804 acc: 0.0000  val loss: 12.5692 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.569187\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 13.5431 acc: 0.0000  val loss: 12.7772 acc: 0.0000\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 13.1544 acc: 0.0000  val loss: 12.5388 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.538786\n",
      "Training complete in 0m 15s\n",
      "Best val Acc/Loss: 0.000000/12.538786\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 13.0970 acc: 0.0000  val loss: 11.4075 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.407498\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 12.5931 acc: 0.0000  val loss: 10.5053 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.505315\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 11.6289 acc: 0.0000  val loss: 9.2819 acc: 0.0455\n",
      "Update: Best val acc/loss: 0.045455/9.281892\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 10.9440 acc: 0.0000  val loss: 7.0004 acc: 0.1705\n",
      "Update: Best val acc/loss: 0.170455/7.000422\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 8.9224 acc: 0.0398  val loss: 6.0254 acc: 0.3295\n",
      "Update: Best val acc/loss: 0.329545/6.025440\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 7.3345 acc: 0.1023  val loss: 3.7184 acc: 0.6250\n",
      "Update: Best val acc/loss: 0.625000/3.718409\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 5.9806 acc: 0.2301  val loss: 3.6204 acc: 0.7727\n",
      "Update: Best val acc/loss: 0.772727/3.620412\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 3.9362 acc: 0.4716  val loss: 2.7215 acc: 0.8523\n",
      "Update: Best val acc/loss: 0.852273/2.721456\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 3.1808 acc: 0.5597  val loss: 2.8285 acc: 0.8750\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 3.0034 acc: 0.6335  val loss: 2.7679 acc: 0.8977\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 1.9971 acc: 0.7670  val loss: 2.5041 acc: 0.9091\n",
      "Update: Best val acc/loss: 0.909091/2.504095\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 2.2653 acc: 0.7188  val loss: 1.1931 acc: 0.9545\n",
      "Update: Best val acc/loss: 0.954545/1.193076\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 1.4363 acc: 0.8580  val loss: 1.5879 acc: 0.9545\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 1.2640 acc: 0.8295  val loss: 1.5068 acc: 0.9318\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 1.2738 acc: 0.8352  val loss: 0.5454 acc: 0.9659\n",
      "Update: Best val acc/loss: 0.965909/0.545446\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 1.3568 acc: 0.8438  val loss: 1.8395 acc: 0.9432\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.9139 acc: 0.8949  val loss: 0.9577 acc: 0.9659\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 1.1606 acc: 0.8920  val loss: 0.4587 acc: 0.9886\n",
      "Update: Best val acc/loss: 0.988636/0.458715\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.8085 acc: 0.9233  val loss: 1.4326 acc: 0.9659\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 1.1802 acc: 0.8949  val loss: 0.9894 acc: 0.9659\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 1.0778 acc: 0.8778  val loss: 0.9830 acc: 0.9659\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.8503 acc: 0.9403  val loss: 1.1239 acc: 0.9659\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.5460 acc: 0.9432  val loss: 1.3631 acc: 0.9545\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.6442 acc: 0.9545  val loss: 1.3429 acc: 0.9659\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.6409 acc: 0.9261  val loss: 1.0407 acc: 0.9659\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.9430 acc: 0.8892  val loss: 0.9695 acc: 0.9773\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.3515 acc: 0.9688  val loss: 0.8806 acc: 0.9773\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.6420 acc: 0.9545  val loss: 0.4926 acc: 0.9886\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.5652 acc: 0.9517  val loss: 0.4885 acc: 0.9886\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.5362 acc: 0.9517  val loss: 0.4902 acc: 0.9886\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.3689 acc: 0.9517  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.4307 acc: 0.9517  val loss: 0.4931 acc: 0.9886\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.2587 acc: 0.9801  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.5710 acc: 0.9375  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.4800 acc: 0.9801  val loss: 0.2599 acc: 0.9886\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.6446 acc: 0.8977  val loss: 0.4590 acc: 0.9773\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.3858 acc: 0.9602  val loss: 0.5093 acc: 0.9886\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.3194 acc: 0.9659  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.1190 acc: 0.9858  val loss: 0.9804 acc: 0.9773\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.5698 acc: 0.9574  val loss: 0.4720 acc: 0.9886\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.3534 acc: 0.9631  val loss: 1.0043 acc: 0.9773\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0292 acc: 0.9915  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.4121 acc: 0.9574  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.3473 acc: 0.9432  val loss: 0.6018 acc: 0.9773\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.3605 acc: 0.9659  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.3448 acc: 0.9773  val loss: 0.5059 acc: 0.9886\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.5796 acc: 0.9659  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.4342 acc: 0.9290  val loss: 0.5018 acc: 0.9886\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.2545 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.3083 acc: 0.9801  val loss: 0.0744 acc: 0.9886\n",
      "Training complete in 1m 53s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:22:37,150 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:22:37,182 dlcliche.utils create_model [INFO]:  using model weight: weights_metal_nut\n",
      "2020-04-01 00:22:37,907 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:22:38,674 dlcliche.utils add_good_samples [DEBUG]: Adding 267 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['metal_nut'], 'auc': [0.9521016617790812]}\n",
      "\n",
      "--- Start evaluating [pill] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:22:39,324 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 13.9800 acc: 0.0000  val loss: 13.6630 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.662984\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.8152 acc: 0.0000  val loss: 12.7465 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.746497\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.2253 acc: 0.0000  val loss: 12.4806 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.480551\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 12.9819 acc: 0.0000  val loss: 11.8207 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.820731\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 12.5126 acc: 0.0000  val loss: 10.8537 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.853736\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 12.1787 acc: 0.0000  val loss: 10.5648 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.564764\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 11.9426 acc: 0.0000  val loss: 9.6715 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.671512\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 11.4282 acc: 0.0000  val loss: 8.7955 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/8.795493\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 11.4064 acc: 0.0000  val loss: 8.5577 acc: 0.0093\n",
      "Update: Best val acc/loss: 0.009259/8.557657\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 10.8138 acc: 0.0000  val loss: 8.1875 acc: 0.0463\n",
      "Update: Best val acc/loss: 0.046296/8.187468\n",
      "Training complete in 0m 20s\n",
      "Best val Acc/Loss: 0.046296/8.187468\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 9.9044 acc: 0.0023  val loss: 6.1071 acc: 0.2315\n",
      "Update: Best val acc/loss: 0.231481/6.107086\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 8.0626 acc: 0.0282  val loss: 3.1467 acc: 0.5926\n",
      "Update: Best val acc/loss: 0.592593/3.146675\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 6.1052 acc: 0.1338  val loss: 2.4264 acc: 0.7315\n",
      "Update: Best val acc/loss: 0.731481/2.426362\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 4.5927 acc: 0.3498  val loss: 1.6631 acc: 0.8611\n",
      "Update: Best val acc/loss: 0.861111/1.663139\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 3.0047 acc: 0.5305  val loss: 0.8450 acc: 0.9352\n",
      "Update: Best val acc/loss: 0.935185/0.844977\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 2.1752 acc: 0.6573  val loss: 1.0462 acc: 0.9444\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 1.8933 acc: 0.7254  val loss: 0.6948 acc: 0.9722\n",
      "Update: Best val acc/loss: 0.972222/0.694790\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 1.7759 acc: 0.7559  val loss: 0.5488 acc: 0.9815\n",
      "Update: Best val acc/loss: 0.981481/0.548816\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.3795 acc: 0.8146  val loss: 0.1547 acc: 0.9907\n",
      "Update: Best val acc/loss: 0.990741/0.154715\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.3295 acc: 0.8122  val loss: 0.3437 acc: 0.9907\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 0.7460 acc: 0.8380  val loss: 0.0084 acc: 0.9907\n",
      "Update: Best val acc/loss: 0.990741/0.008356\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.7695 acc: 0.8756  val loss: 0.3936 acc: 0.9907\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.2901 acc: 0.9366  val loss: 0.3908 acc: 0.9907\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.7536 acc: 0.8897  val loss: 0.3560 acc: 0.9907\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.4777 acc: 0.9319  val loss: 0.4183 acc: 0.9815\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.2216 acc: 0.9577  val loss: 0.0726 acc: 0.9907\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.1425 acc: 0.9531  val loss: 0.3850 acc: 0.9907\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.0867 acc: 0.9789  val loss: 0.1775 acc: 0.9907\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.4085 acc: 0.9225  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000002\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.2789 acc: 0.9366  val loss: 0.1939 acc: 0.9907\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.1453 acc: 0.9577  val loss: 0.0022 acc: 1.0000\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.2174 acc: 0.9742  val loss: 0.0030 acc: 1.0000\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.4755 acc: 0.9484  val loss: 0.4129 acc: 0.9907\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.3869 acc: 0.9272  val loss: 0.1856 acc: 0.9907\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.0909 acc: 0.9671  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.2685 acc: 0.9601  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.4015 acc: 0.9718  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.1667 acc: 0.9789  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.0768 acc: 0.9671  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.0984 acc: 0.9648  val loss: 0.0072 acc: 0.9907\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.2346 acc: 0.9390  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.1205 acc: 0.9742  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.0856 acc: 0.9883  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.0823 acc: 0.9789  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.0053 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.0631 acc: 0.9812  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.0125 acc: 0.9930  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.0137 acc: 0.9930  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.0038 acc: 0.9977  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.0854 acc: 0.9836  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0226 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0084 acc: 0.9953  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.1501 acc: 0.9789  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.0852 acc: 0.9836  val loss: 0.4258 acc: 0.9907\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.1578 acc: 0.9742  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.3147 acc: 0.9507  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.0021 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.0045 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.0553 acc: 0.9765  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.0908 acc: 0.9930  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 16s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:25:15,899 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:25:15,929 dlcliche.utils create_model [INFO]:  using model weight: weights_pill\n",
      "2020-04-01 00:25:16,943 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:25:18,259 dlcliche.utils add_good_samples [DEBUG]: Adding 320 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['pill'], 'auc': [0.8240589198036007]}\n",
      "\n",
      "--- Start evaluating [screw] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:25:18,675 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.1419 acc: 0.0000  val loss: 13.9822 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.982153\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.6697 acc: 0.0000  val loss: 12.7788 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.778763\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 12.9624 acc: 0.0000  val loss: 11.6664 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.666385\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 12.4860 acc: 0.0000  val loss: 10.8461 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.846071\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 12.1019 acc: 0.0000  val loss: 10.3365 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.336474\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 11.7534 acc: 0.0000  val loss: 9.0259 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.025913\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 11.0879 acc: 0.0000  val loss: 7.7477 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/7.747678\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 10.5866 acc: 0.0000  val loss: 7.4658 acc: 0.0234\n",
      "Update: Best val acc/loss: 0.023438/7.465753\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 10.0400 acc: 0.0000  val loss: 6.9854 acc: 0.0156\n",
      "Update: Best val acc/loss: 0.015625/6.985424\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 9.4703 acc: 0.0059  val loss: 5.6963 acc: 0.1562\n",
      "Update: Best val acc/loss: 0.156250/5.696292\n",
      "Training complete in 0m 16s\n",
      "Best val Acc/Loss: 0.156250/5.696292\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 8.3655 acc: 0.0176  val loss: 4.7014 acc: 0.4141\n",
      "Update: Best val acc/loss: 0.414062/4.701440\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 6.8028 acc: 0.1504  val loss: 2.6291 acc: 0.7188\n",
      "Update: Best val acc/loss: 0.718750/2.629119\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 4.3915 acc: 0.2910  val loss: 2.0358 acc: 0.8438\n",
      "Update: Best val acc/loss: 0.843750/2.035771\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 3.2920 acc: 0.4570  val loss: 1.7132 acc: 0.8828\n",
      "Update: Best val acc/loss: 0.882812/1.713176\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 2.6274 acc: 0.5898  val loss: 1.3500 acc: 0.9219\n",
      "Update: Best val acc/loss: 0.921875/1.350002\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 2.0308 acc: 0.6973  val loss: 0.9472 acc: 0.9531\n",
      "Update: Best val acc/loss: 0.953125/0.947181\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 1.1346 acc: 0.8125  val loss: 0.9089 acc: 0.9531\n",
      "Update: Best val acc/loss: 0.953125/0.908948\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 1.3265 acc: 0.7910  val loss: 0.7334 acc: 0.9688\n",
      "Update: Best val acc/loss: 0.968750/0.733401\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.2104 acc: 0.8516  val loss: 1.0668 acc: 0.9688\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 0.6675 acc: 0.8789  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 0.3819 acc: 0.9453  val loss: 0.4587 acc: 0.9844\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.6018 acc: 0.8691  val loss: 0.4176 acc: 0.9844\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.8884 acc: 0.8906  val loss: 0.1626 acc: 0.9922\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.3549 acc: 0.9473  val loss: 0.7698 acc: 0.9688\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.3323 acc: 0.9512  val loss: 0.2512 acc: 0.9922\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.2342 acc: 0.9355  val loss: 0.1569 acc: 0.9922\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.3551 acc: 0.9297  val loss: 0.1445 acc: 0.9922\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.1394 acc: 0.9609  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.1926 acc: 0.9648  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.2259 acc: 0.9551  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.1028 acc: 0.9707  val loss: 0.3632 acc: 0.9922\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.3072 acc: 0.9609  val loss: 0.3374 acc: 0.9922\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.1787 acc: 0.9805  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.1749 acc: 0.9492  val loss: 0.3681 acc: 0.9922\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.3237 acc: 0.9688  val loss: 0.3716 acc: 0.9922\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.2576 acc: 0.9551  val loss: 0.0520 acc: 0.9922\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.4622 acc: 0.9238  val loss: 0.3547 acc: 0.9922\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.0680 acc: 0.9805  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.0804 acc: 0.9941  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.0231 acc: 0.9922  val loss: 0.3654 acc: 0.9922\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.1400 acc: 0.9805  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.1815 acc: 0.9668  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.1000 acc: 0.9766  val loss: 0.3316 acc: 0.9922\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.0304 acc: 0.9902  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.1381 acc: 0.9863  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.0213 acc: 0.9961  val loss: 0.0767 acc: 0.9922\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.2966 acc: 0.9570  val loss: 0.0599 acc: 0.9922\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.0944 acc: 0.9902  val loss: 0.3013 acc: 0.9922\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.0100 acc: 0.9961  val loss: 0.3718 acc: 0.9922\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.1046 acc: 0.9922  val loss: 0.3761 acc: 0.9922\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0782 acc: 0.9961  val loss: 0.4828 acc: 0.9844\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0741 acc: 0.9922  val loss: 0.3723 acc: 0.9922\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.1193 acc: 0.9824  val loss: 0.3757 acc: 0.9922\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.0797 acc: 0.9844  val loss: 0.3598 acc: 0.9922\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.0079 acc: 0.9980  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.0500 acc: 0.9922  val loss: 0.3771 acc: 0.9922\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.0521 acc: 0.9863  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.2772 acc: 0.9707  val loss: 0.3736 acc: 0.9922\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.0061 acc: 0.9980  val loss: 0.3768 acc: 0.9922\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.1226 acc: 0.9941  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 17s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:27:52,044 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:27:52,073 dlcliche.utils create_model [INFO]:  using model weight: weights_screw\n",
      "2020-04-01 00:27:52,882 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:27:53,637 dlcliche.utils add_good_samples [DEBUG]: Adding 230 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['screw'], 'auc': [0.5408895265423243]}\n",
      "\n",
      "--- Start evaluating [tile] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:27:54,428 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.2888 acc: 0.0000  val loss: 14.5543 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.554308\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.0949 acc: 0.0000  val loss: 13.8090 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.809044\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.9143 acc: 0.0000  val loss: 13.4263 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.426258\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.8753 acc: 0.0000  val loss: 12.9716 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.971556\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.5409 acc: 0.0000  val loss: 12.8251 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.825104\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.4127 acc: 0.0000  val loss: 12.3570 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.356996\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 13.0983 acc: 0.0000  val loss: 12.3092 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.309225\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.0585 acc: 0.0000  val loss: 11.7352 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.735169\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 12.7577 acc: 0.0000  val loss: 11.7167 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.716674\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 12.5153 acc: 0.0000  val loss: 10.8486 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.848633\n",
      "Training complete in 0m 20s\n",
      "Best val Acc/Loss: 0.000000/10.848633\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 12.2823 acc: 0.0000  val loss: 9.5857 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.585662\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 11.4245 acc: 0.0000  val loss: 8.6548 acc: 0.0435\n",
      "Update: Best val acc/loss: 0.043478/8.654834\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 10.1944 acc: 0.0000  val loss: 6.5917 acc: 0.2283\n",
      "Update: Best val acc/loss: 0.228261/6.591704\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 8.7469 acc: 0.0136  val loss: 4.7688 acc: 0.3370\n",
      "Update: Best val acc/loss: 0.336957/4.768847\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 6.8913 acc: 0.1196  val loss: 3.3499 acc: 0.5326\n",
      "Update: Best val acc/loss: 0.532609/3.349912\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 5.7713 acc: 0.2283  val loss: 1.8985 acc: 0.8587\n",
      "Update: Best val acc/loss: 0.858696/1.898491\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 3.8241 acc: 0.3995  val loss: 2.2094 acc: 0.8804\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 3.0602 acc: 0.5299  val loss: 1.0308 acc: 0.9348\n",
      "Update: Best val acc/loss: 0.934783/1.030752\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 2.3979 acc: 0.6467  val loss: 1.5254 acc: 0.9348\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.7042 acc: 0.7880  val loss: 0.7948 acc: 0.9565\n",
      "Update: Best val acc/loss: 0.956522/0.794770\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 2.2913 acc: 0.6875  val loss: 0.7928 acc: 0.9674\n",
      "Update: Best val acc/loss: 0.967391/0.792815\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 1.4862 acc: 0.8288  val loss: 0.9915 acc: 0.9565\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 1.3490 acc: 0.8179  val loss: 0.5165 acc: 0.9783\n",
      "Update: Best val acc/loss: 0.978261/0.516487\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.9335 acc: 0.8696  val loss: 0.6377 acc: 0.9457\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 1.0456 acc: 0.8859  val loss: 0.1607 acc: 0.9674\n",
      "Update: Best val acc/loss: 0.967391/0.160712\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.9438 acc: 0.9049  val loss: 0.6519 acc: 0.9674\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.6059 acc: 0.9402  val loss: 0.7925 acc: 0.9565\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.7933 acc: 0.8641  val loss: 0.6178 acc: 0.9783\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.6510 acc: 0.9266  val loss: 0.5531 acc: 0.9783\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.7039 acc: 0.8832  val loss: 0.5480 acc: 0.9674\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.2853 acc: 0.9538  val loss: 0.7672 acc: 0.9674\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.4940 acc: 0.9457  val loss: 0.6965 acc: 0.9783\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.7343 acc: 0.9348  val loss: 1.0325 acc: 0.9674\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.5603 acc: 0.9674  val loss: 0.9480 acc: 0.9674\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.5746 acc: 0.9293  val loss: 0.4729 acc: 0.9891\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.6342 acc: 0.9321  val loss: 0.4681 acc: 0.9783\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.5686 acc: 0.9538  val loss: 0.4555 acc: 0.9891\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.7709 acc: 0.9049  val loss: 0.4788 acc: 0.9891\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.2893 acc: 0.9701  val loss: 0.4714 acc: 0.9891\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.5061 acc: 0.9429  val loss: 0.9323 acc: 0.9783\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.6282 acc: 0.9429  val loss: 0.6827 acc: 0.9783\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.3383 acc: 0.9755  val loss: 0.6424 acc: 0.9783\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.6598 acc: 0.9375  val loss: 0.4751 acc: 0.9891\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.3821 acc: 0.9402  val loss: 0.4798 acc: 0.9891\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.3280 acc: 0.9647  val loss: 0.8626 acc: 0.9783\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.3577 acc: 0.9837  val loss: 1.0620 acc: 0.9674\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.3082 acc: 0.9837  val loss: 0.9683 acc: 0.9783\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.3332 acc: 0.9674  val loss: 0.9801 acc: 0.9674\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.2073 acc: 0.9891  val loss: 0.9579 acc: 0.9783\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.3203 acc: 0.9810  val loss: 0.9693 acc: 0.9783\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.3524 acc: 0.9620  val loss: 0.9560 acc: 0.9783\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.4568 acc: 0.9620  val loss: 1.1857 acc: 0.9674\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.2158 acc: 0.9837  val loss: 0.9150 acc: 0.9783\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.4057 acc: 0.9701  val loss: 0.9790 acc: 0.9783\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.2907 acc: 0.9592  val loss: 0.9576 acc: 0.9783\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.3279 acc: 0.9565  val loss: 0.8781 acc: 0.9674\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.3668 acc: 0.9674  val loss: 1.4701 acc: 0.9674\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.4264 acc: 0.9293  val loss: 0.9408 acc: 0.9783\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.2672 acc: 0.9891  val loss: 1.2507 acc: 0.9565\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.4036 acc: 0.9837  val loss: 1.4370 acc: 0.9674\n",
      "Training complete in 2m 12s\n",
      "Best val Acc/Loss: 0.967391/0.160712\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:30:26,960 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:30:26,992 dlcliche.utils create_model [INFO]:  using model weight: weights_tile\n",
      "2020-04-01 00:30:28,003 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:30:29,044 dlcliche.utils add_good_samples [DEBUG]: Adding 60 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['tile'], 'auc': [0.9657287157287158]}\n",
      "\n",
      "--- Start evaluating [toothbrush] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:30:29,476 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.3827 acc: 0.0000  val loss: 14.4637 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.463736\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.9294 acc: 0.0000  val loss: 14.2969 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.296945\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.1066 acc: 0.0000  val loss: 14.2984 acc: 0.0000\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 14.2000 acc: 0.0000  val loss: 14.5170 acc: 0.0000\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 14.3279 acc: 0.0000  val loss: 14.2202 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.220227\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.8272 acc: 0.0000  val loss: 14.0036 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.003607\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 13.9719 acc: 0.0000  val loss: 14.3375 acc: 0.0000\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.9015 acc: 0.0000  val loss: 14.1883 acc: 0.0000\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 13.7690 acc: 0.0000  val loss: 14.3381 acc: 0.0000\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 13.6302 acc: 0.0000  val loss: 14.1981 acc: 0.0000\n",
      "Training complete in 0m 15s\n",
      "Best val Acc/Loss: 0.000000/14.003607\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 13.7153 acc: 0.0000  val loss: 13.6270 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.627040\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 13.5144 acc: 0.0000  val loss: 13.8682 acc: 0.0000\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 13.3083 acc: 0.0000  val loss: 13.6215 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.621485\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 13.2894 acc: 0.0000  val loss: 13.3549 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.354884\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 12.9015 acc: 0.0000  val loss: 13.4925 acc: 0.0000\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 12.1885 acc: 0.0000  val loss: 12.6364 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.636367\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 11.9878 acc: 0.0000  val loss: 12.7058 acc: 0.0000\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 11.6623 acc: 0.0000  val loss: 11.9131 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.913076\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 11.0955 acc: 0.0000  val loss: 11.3006 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.300614\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 10.4558 acc: 0.0000  val loss: 10.3630 acc: 0.0417\n",
      "Update: Best val acc/loss: 0.041667/10.363015\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 10.0323 acc: 0.0000  val loss: 8.2186 acc: 0.0833\n",
      "Update: Best val acc/loss: 0.083333/8.218578\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 8.9943 acc: 0.0208  val loss: 7.3081 acc: 0.1250\n",
      "Update: Best val acc/loss: 0.125000/7.308104\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 8.1184 acc: 0.0312  val loss: 5.9195 acc: 0.2500\n",
      "Update: Best val acc/loss: 0.250000/5.919507\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 7.3912 acc: 0.0521  val loss: 5.4665 acc: 0.2917\n",
      "Update: Best val acc/loss: 0.291667/5.466522\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 6.7546 acc: 0.0938  val loss: 4.7169 acc: 0.5417\n",
      "Update: Best val acc/loss: 0.541667/4.716950\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 6.0650 acc: 0.2083  val loss: 2.6520 acc: 0.6667\n",
      "Update: Best val acc/loss: 0.666667/2.652003\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 6.3770 acc: 0.1771  val loss: 2.7680 acc: 0.6250\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 3.8375 acc: 0.3229  val loss: 2.8127 acc: 0.7500\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 4.3200 acc: 0.4062  val loss: 2.7255 acc: 0.6250\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 3.4782 acc: 0.4792  val loss: 1.4352 acc: 0.7083\n",
      "Update: Best val acc/loss: 0.708333/1.435170\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 3.7549 acc: 0.5625  val loss: 3.2028 acc: 0.7083\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 2.8913 acc: 0.5938  val loss: 2.6670 acc: 0.8333\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 2.2977 acc: 0.6562  val loss: 2.4181 acc: 0.8333\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 3.2881 acc: 0.6146  val loss: 2.3478 acc: 0.7917\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 2.2110 acc: 0.7604  val loss: 1.2615 acc: 0.9167\n",
      "Update: Best val acc/loss: 0.916667/1.261497\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 2.7367 acc: 0.7500  val loss: 1.6314 acc: 0.9583\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 1.6810 acc: 0.8229  val loss: 2.8401 acc: 0.9167\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 3.0166 acc: 0.6458  val loss: 4.0255 acc: 0.8750\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 1.5757 acc: 0.8750  val loss: 3.2717 acc: 0.9167\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 1.7194 acc: 0.7292  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000008\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.8168 acc: 0.8854  val loss: 0.7117 acc: 0.9583\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 2.0831 acc: 0.7188  val loss: 1.7846 acc: 0.9167\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 1.3879 acc: 0.8750  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 1.0706 acc: 0.8958  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 1.0948 acc: 0.9375  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.8885 acc: 0.8854  val loss: 0.0003 acc: 1.0000\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 1.0747 acc: 0.8646  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.7737 acc: 0.8333  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 1.3837 acc: 0.8229  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 1.5245 acc: 0.8854  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 1.3427 acc: 0.8542  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 1.2444 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 1.0939 acc: 0.9062  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 1.4881 acc: 0.9062  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 1.5318 acc: 0.9167  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 1.5718 acc: 0.8333  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.7089 acc: 0.9792  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 1.4561 acc: 0.8021  val loss: 1.0308 acc: 0.9583\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 1.3679 acc: 0.8750  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 1.1159 acc: 0.9271  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 1m 26s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:32:10,496 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:32:10,524 dlcliche.utils create_model [INFO]:  using model weight: weights_toothbrush\n",
      "2020-04-01 00:32:11,275 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:32:12,129 dlcliche.utils add_good_samples [DEBUG]: Adding 213 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['toothbrush'], 'auc': [0.8805555555555556]}\n",
      "\n",
      "--- Start evaluating [transistor] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:32:12,575 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.5570 acc: 0.0000  val loss: 14.3804 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.380398\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.2899 acc: 0.0000  val loss: 14.0428 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.042785\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.0242 acc: 0.0000  val loss: 13.6143 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.614335\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.9989 acc: 0.0000  val loss: 13.2796 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.279576\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.8884 acc: 0.0000  val loss: 13.3076 acc: 0.0000\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.8487 acc: 0.0000  val loss: 13.1079 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.107907\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 13.5883 acc: 0.0000  val loss: 12.7816 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.781605\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.4971 acc: 0.0000  val loss: 12.6407 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.640700\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 13.2386 acc: 0.0000  val loss: 12.3004 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.300364\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 12.8084 acc: 0.0000  val loss: 12.0583 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.058255\n",
      "Training complete in 0m 25s\n",
      "Best val Acc/Loss: 0.000000/12.058255\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 12.6853 acc: 0.0000  val loss: 11.3211 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.321083\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 12.1406 acc: 0.0000  val loss: 10.1621 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.162136\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 11.4318 acc: 0.0000  val loss: 8.2816 acc: 0.0465\n",
      "Update: Best val acc/loss: 0.046512/8.281643\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 10.3769 acc: 0.0029  val loss: 6.8831 acc: 0.1744\n",
      "Update: Best val acc/loss: 0.174419/6.883106\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 9.0824 acc: 0.0324  val loss: 6.1987 acc: 0.4186\n",
      "Update: Best val acc/loss: 0.418605/6.198679\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 7.3603 acc: 0.1147  val loss: 4.5852 acc: 0.5581\n",
      "Update: Best val acc/loss: 0.558140/4.585231\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 6.2870 acc: 0.1971  val loss: 3.9617 acc: 0.7326\n",
      "Update: Best val acc/loss: 0.732558/3.961674\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 4.4615 acc: 0.3794  val loss: 3.4285 acc: 0.8140\n",
      "Update: Best val acc/loss: 0.813953/3.428490\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 3.4308 acc: 0.5265  val loss: 2.3976 acc: 0.8140\n",
      "Update: Best val acc/loss: 0.813953/2.397638\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 3.0985 acc: 0.6059  val loss: 2.7105 acc: 0.8837\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 2.4792 acc: 0.6882  val loss: 2.6672 acc: 0.8721\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 1.9603 acc: 0.7588  val loss: 2.1800 acc: 0.9070\n",
      "Update: Best val acc/loss: 0.906977/2.180008\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 1.4650 acc: 0.8147  val loss: 1.9064 acc: 0.9186\n",
      "Update: Best val acc/loss: 0.918605/1.906411\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 1.9347 acc: 0.7500  val loss: 1.9861 acc: 0.9186\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 1.3228 acc: 0.8147  val loss: 0.8800 acc: 0.9419\n",
      "Update: Best val acc/loss: 0.941860/0.880039\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 1.1782 acc: 0.8471  val loss: 0.7004 acc: 0.9651\n",
      "Update: Best val acc/loss: 0.965116/0.700438\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 1.2072 acc: 0.8676  val loss: 1.9508 acc: 0.9302\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.9427 acc: 0.8618  val loss: 0.6251 acc: 0.9767\n",
      "Update: Best val acc/loss: 0.976744/0.625062\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 1.0534 acc: 0.8324  val loss: 0.2154 acc: 0.9651\n",
      "Update: Best val acc/loss: 0.965116/0.215411\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.7918 acc: 0.8882  val loss: 0.7076 acc: 0.9651\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 1.0590 acc: 0.8882  val loss: 0.5011 acc: 0.9767\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.7485 acc: 0.8941  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000139\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 1.1250 acc: 0.8824  val loss: 0.0001 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000109\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.8093 acc: 0.9235  val loss: 0.4160 acc: 0.9767\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.5887 acc: 0.8971  val loss: 0.5013 acc: 0.9651\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.5418 acc: 0.9529  val loss: 0.8553 acc: 0.9767\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.5875 acc: 0.9324  val loss: 0.3970 acc: 0.9884\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.7703 acc: 0.9059  val loss: 1.3408 acc: 0.9535\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.8720 acc: 0.8912  val loss: 0.6233 acc: 0.9767\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.6928 acc: 0.9147  val loss: 0.4796 acc: 0.9767\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.4781 acc: 0.9529  val loss: 0.1856 acc: 0.9884\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.3961 acc: 0.9559  val loss: 0.1037 acc: 0.9767\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.1981 acc: 0.9588  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.3984 acc: 0.9382  val loss: 0.2800 acc: 0.9884\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.5783 acc: 0.9412  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.3730 acc: 0.9794  val loss: 0.3952 acc: 0.9884\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.3730 acc: 0.9500  val loss: 0.5097 acc: 0.9884\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.1824 acc: 0.9647  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.3037 acc: 0.9735  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.3169 acc: 0.9794  val loss: 0.0207 acc: 0.9884\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0332 acc: 0.9882  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.3210 acc: 0.9765  val loss: 0.4825 acc: 0.9651\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.2804 acc: 0.9588  val loss: 0.1693 acc: 0.9884\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.1912 acc: 0.9588  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.6153 acc: 0.9353  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.1133 acc: 0.9912  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.5090 acc: 0.9324  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.2249 acc: 0.9794  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.2237 acc: 0.9412  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.0888 acc: 0.9824  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 24s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:35:02,134 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:35:02,163 dlcliche.utils create_model [INFO]:  using model weight: weights_transistor\n",
      "2020-04-01 00:35:03,555 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:35:04,545 dlcliche.utils add_good_samples [DEBUG]: Adding 247 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['transistor'], 'auc': [0.9120833333333334]}\n",
      "\n",
      "--- Start evaluating [wood] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:35:05,588 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.4920 acc: 0.0000  val loss: 14.4041 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.404089\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 14.1742 acc: 0.0000  val loss: 14.1977 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/14.197715\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 14.0676 acc: 0.0000  val loss: 13.8796 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.879630\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.9148 acc: 0.0000  val loss: 13.6072 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.607225\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 13.7345 acc: 0.0000  val loss: 13.6122 acc: 0.0000\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 13.6547 acc: 0.0000  val loss: 13.2717 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.271690\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 13.6664 acc: 0.0000  val loss: 12.9929 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.992917\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 13.4048 acc: 0.0000  val loss: 12.4573 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.457295\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 13.3421 acc: 0.0000  val loss: 12.4680 acc: 0.0000\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 13.1618 acc: 0.0000  val loss: 12.3263 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.326310\n",
      "Training complete in 0m 29s\n",
      "Best val Acc/Loss: 0.000000/12.326310\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 12.8385 acc: 0.0000  val loss: 11.3829 acc: 0.0100\n",
      "Update: Best val acc/loss: 0.010000/11.382929\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 12.0924 acc: 0.0000  val loss: 10.1229 acc: 0.0200\n",
      "Update: Best val acc/loss: 0.020000/10.122930\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 11.0585 acc: 0.0025  val loss: 8.0706 acc: 0.1100\n",
      "Update: Best val acc/loss: 0.110000/8.070636\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 9.7605 acc: 0.0203  val loss: 6.7161 acc: 0.2200\n",
      "Update: Best val acc/loss: 0.220000/6.716133\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 7.7424 acc: 0.0787  val loss: 4.9607 acc: 0.3500\n",
      "Update: Best val acc/loss: 0.350000/4.960749\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 6.4864 acc: 0.1751  val loss: 2.7280 acc: 0.5700\n",
      "Update: Best val acc/loss: 0.570000/2.728021\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 4.3683 acc: 0.3071  val loss: 1.2154 acc: 0.8100\n",
      "Update: Best val acc/loss: 0.810000/1.215365\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 2.9749 acc: 0.4695  val loss: 0.5283 acc: 0.9100\n",
      "Update: Best val acc/loss: 0.910000/0.528300\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 2.0880 acc: 0.6244  val loss: 0.4102 acc: 0.9500\n",
      "Update: Best val acc/loss: 0.950000/0.410207\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 1.6067 acc: 0.7284  val loss: 0.4028 acc: 0.9700\n",
      "Update: Best val acc/loss: 0.970000/0.402754\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 1.8296 acc: 0.7360  val loss: 0.5678 acc: 0.9700\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.6372 acc: 0.8477  val loss: 0.4618 acc: 0.9800\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.5090 acc: 0.9061  val loss: 0.3032 acc: 0.9900\n",
      "Update: Best val acc/loss: 0.990000/0.303216\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.7782 acc: 0.8883  val loss: 0.2586 acc: 0.9700\n",
      "Update: Best val acc/loss: 0.970000/0.258601\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.7088 acc: 0.8909  val loss: 0.3826 acc: 0.9900\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.5417 acc: 0.8959  val loss: 0.3211 acc: 0.9800\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.9003 acc: 0.8756  val loss: 0.4133 acc: 0.9900\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.5818 acc: 0.9239  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.3197 acc: 0.9518  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.4773 acc: 0.9086  val loss: 0.4330 acc: 0.9900\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.7228 acc: 0.8985  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.8031 acc: 0.9162  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.1932 acc: 0.9619  val loss: 0.0714 acc: 0.9900\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.4827 acc: 0.9518  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.2633 acc: 0.9594  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.2368 acc: 0.9619  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.4044 acc: 0.9492  val loss: 0.4257 acc: 0.9900\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.1286 acc: 0.9848  val loss: 0.4355 acc: 0.9900\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.5721 acc: 0.9239  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.2412 acc: 0.9492  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.5655 acc: 0.9340  val loss: 0.5548 acc: 0.9800\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.1008 acc: 0.9619  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.4717 acc: 0.9569  val loss: 0.1690 acc: 0.9800\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.1009 acc: 0.9924  val loss: 0.3185 acc: 0.9900\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.2271 acc: 0.9746  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.4256 acc: 0.9543  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.3420 acc: 0.9518  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.0939 acc: 0.9645  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.1036 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.2916 acc: 0.9264  val loss: 0.4419 acc: 0.9900\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.2408 acc: 0.9721  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.2469 acc: 0.9619  val loss: 0.4480 acc: 0.9900\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.2529 acc: 0.9492  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.1156 acc: 0.9949  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.3590 acc: 0.9822  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.3177 acc: 0.9594  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.4706 acc: 0.9442  val loss: 0.4534 acc: 0.9900\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.1991 acc: 0.9873  val loss: 0.4610 acc: 0.9800\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.1826 acc: 0.9721  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.0625 acc: 0.9848  val loss: 0.0000 acc: 1.0000\n",
      "Training complete in 2m 42s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:38:16,747 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:38:16,776 dlcliche.utils create_model [INFO]:  using model weight: weights_wood\n",
      "2020-04-01 00:38:18,310 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n",
      "2020-04-01 00:38:19,638 dlcliche.utils add_good_samples [DEBUG]: Adding 240 good samples to tmp/mvtecad_anotwin/good.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['wood'], 'auc': [0.986842105263158]}\n",
      "\n",
      "--- Start evaluating [zipper] ----\n",
      " preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:38:20,163 dlcliche.utils create_model [INFO]: Created model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...\n",
      "Epoch 0/10 lr:0.00003 m:0.95000  train loss: 14.2084 acc: 0.0000  val loss: 13.9510 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.950964\n",
      "Epoch 1/10 lr:0.00010 m:0.92500  train loss: 13.7005 acc: 0.0000  val loss: 13.0110 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/13.011008\n",
      "Epoch 2/10 lr:0.00016 m:0.90000  train loss: 13.2671 acc: 0.0000  val loss: 12.2765 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/12.276497\n",
      "Epoch 3/10 lr:0.00023 m:0.87500  train loss: 13.1873 acc: 0.0000  val loss: 11.7899 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.789877\n",
      "Epoch 4/10 lr:0.00030 m:0.85000  train loss: 12.8098 acc: 0.0000  val loss: 11.5132 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/11.513165\n",
      "Epoch 5/10 lr:0.00025 m:0.87000  train loss: 12.2206 acc: 0.0000  val loss: 10.8125 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.812530\n",
      "Epoch 6/10 lr:0.00019 m:0.89000  train loss: 11.8312 acc: 0.0000  val loss: 10.0456 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/10.045551\n",
      "Epoch 7/10 lr:0.00014 m:0.91000  train loss: 11.5058 acc: 0.0000  val loss: 9.2068 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/9.206810\n",
      "Epoch 8/10 lr:0.00008 m:0.93000  train loss: 11.1174 acc: 0.0000  val loss: 8.7786 acc: 0.0104\n",
      "Update: Best val acc/loss: 0.010417/8.778587\n",
      "Epoch 9/10 lr:0.00003 m:0.95000  train loss: 10.6847 acc: 0.0000  val loss: 7.8629 acc: 0.0000\n",
      "Update: Best val acc/loss: 0.000000/7.862867\n",
      "Training complete in 0m 14s\n",
      "Best val Acc/Loss: 0.000000/7.862867\n",
      "Epoch 0/50 lr:0.00000 m:0.95000  train loss: 9.8852 acc: 0.0026  val loss: 5.6564 acc: 0.1875\n",
      "Update: Best val acc/loss: 0.187500/5.656363\n",
      "Epoch 1/50 lr:0.00000 m:0.94545  train loss: 8.0861 acc: 0.0234  val loss: 3.7134 acc: 0.4375\n",
      "Update: Best val acc/loss: 0.437500/3.713382\n",
      "Epoch 2/50 lr:0.00001 m:0.94091  train loss: 5.7645 acc: 0.1016  val loss: 2.0088 acc: 0.6354\n",
      "Update: Best val acc/loss: 0.635417/2.008795\n",
      "Epoch 3/50 lr:0.00001 m:0.93636  train loss: 4.2847 acc: 0.2396  val loss: 1.3572 acc: 0.8750\n",
      "Update: Best val acc/loss: 0.875000/1.357249\n",
      "Epoch 4/50 lr:0.00001 m:0.93182  train loss: 3.0571 acc: 0.4271  val loss: 0.4367 acc: 0.9375\n",
      "Update: Best val acc/loss: 0.937500/0.436700\n",
      "Epoch 5/50 lr:0.00001 m:0.92727  train loss: 1.8849 acc: 0.6562  val loss: 0.4349 acc: 0.9688\n",
      "Update: Best val acc/loss: 0.968750/0.434881\n",
      "Epoch 6/50 lr:0.00001 m:0.92273  train loss: 1.5802 acc: 0.7005  val loss: 0.0655 acc: 0.9896\n",
      "Update: Best val acc/loss: 0.989583/0.065481\n",
      "Epoch 7/50 lr:0.00001 m:0.91818  train loss: 1.1606 acc: 0.7812  val loss: 0.1632 acc: 0.9792\n",
      "Epoch 8/50 lr:0.00001 m:0.91364  train loss: 1.3452 acc: 0.7448  val loss: 0.0658 acc: 0.9896\n",
      "Epoch 9/50 lr:0.00001 m:0.90909  train loss: 0.6687 acc: 0.8542  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000016\n",
      "Epoch 10/50 lr:0.00002 m:0.90455  train loss: 1.0536 acc: 0.8177  val loss: 0.0377 acc: 0.9896\n",
      "Epoch 11/50 lr:0.00002 m:0.90000  train loss: 0.6342 acc: 0.8958  val loss: 0.0458 acc: 0.9896\n",
      "Epoch 12/50 lr:0.00002 m:0.89545  train loss: 0.7274 acc: 0.8724  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000001\n",
      "Epoch 13/50 lr:0.00002 m:0.89091  train loss: 0.5732 acc: 0.8828  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 14/50 lr:0.00002 m:0.88636  train loss: 0.4168 acc: 0.9219  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 15/50 lr:0.00002 m:0.88182  train loss: 0.2118 acc: 0.9688  val loss: 0.4564 acc: 0.9896\n",
      "Epoch 16/50 lr:0.00002 m:0.87727  train loss: 0.3730 acc: 0.9245  val loss: 0.4091 acc: 0.9896\n",
      "Epoch 17/50 lr:0.00002 m:0.87273  train loss: 0.3828 acc: 0.9089  val loss: 0.4493 acc: 0.9896\n",
      "Epoch 18/50 lr:0.00003 m:0.86818  train loss: 0.2832 acc: 0.9245  val loss: 0.4495 acc: 0.9896\n",
      "Epoch 19/50 lr:0.00003 m:0.86364  train loss: 0.5683 acc: 0.9062  val loss: 0.4488 acc: 0.9896\n",
      "Epoch 20/50 lr:0.00003 m:0.85909  train loss: 0.0909 acc: 0.9766  val loss: 0.4345 acc: 0.9896\n",
      "Epoch 21/50 lr:0.00003 m:0.85455  train loss: 0.4525 acc: 0.8958  val loss: 0.3666 acc: 0.9896\n",
      "Epoch 22/50 lr:0.00003 m:0.85000  train loss: 0.0611 acc: 0.9792  val loss: 0.0635 acc: 0.9896\n",
      "Epoch 23/50 lr:0.00003 m:0.85435  train loss: 0.1540 acc: 0.9714  val loss: 0.4098 acc: 0.9896\n",
      "Epoch 24/50 lr:0.00003 m:0.85870  train loss: 0.1370 acc: 0.9792  val loss: 0.2248 acc: 0.9896\n",
      "Epoch 25/50 lr:0.00003 m:0.86304  train loss: 0.2362 acc: 0.9583  val loss: 0.3732 acc: 0.9896\n",
      "Epoch 26/50 lr:0.00003 m:0.86739  train loss: 0.1222 acc: 0.9661  val loss: 0.3011 acc: 0.9896\n",
      "Epoch 27/50 lr:0.00002 m:0.87174  train loss: 0.0302 acc: 0.9870  val loss: 0.0492 acc: 0.9896\n",
      "Epoch 28/50 lr:0.00002 m:0.87609  train loss: 0.3031 acc: 0.9505  val loss: 0.0073 acc: 0.9896\n",
      "Epoch 29/50 lr:0.00002 m:0.88043  train loss: 0.0100 acc: 0.9974  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 30/50 lr:0.00002 m:0.88478  train loss: 0.0577 acc: 0.9844  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 31/50 lr:0.00002 m:0.88913  train loss: 0.2023 acc: 0.9505  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 32/50 lr:0.00002 m:0.89348  train loss: 0.0998 acc: 0.9870  val loss: 0.2338 acc: 0.9896\n",
      "Epoch 33/50 lr:0.00002 m:0.89783  train loss: 0.1522 acc: 0.9766  val loss: 0.0000 acc: 1.0000\n",
      "Update: Best val acc/loss: 1.000000/0.000000\n",
      "Epoch 34/50 lr:0.00002 m:0.90217  train loss: 0.0976 acc: 0.9714  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 35/50 lr:0.00001 m:0.90652  train loss: 0.0066 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 36/50 lr:0.00001 m:0.91087  train loss: 0.0325 acc: 0.9922  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 37/50 lr:0.00001 m:0.91522  train loss: 0.0433 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 38/50 lr:0.00001 m:0.91957  train loss: 0.0229 acc: 0.9948  val loss: 0.0001 acc: 1.0000\n",
      "Epoch 39/50 lr:0.00001 m:0.92391  train loss: 0.0020 acc: 1.0000  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 40/50 lr:0.00001 m:0.92826  train loss: 0.0127 acc: 0.9948  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 41/50 lr:0.00001 m:0.93261  train loss: 0.0769 acc: 0.9766  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 42/50 lr:0.00001 m:0.93696  train loss: 0.1341 acc: 0.9661  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 43/50 lr:0.00001 m:0.94130  train loss: 0.1022 acc: 0.9948  val loss: 0.0331 acc: 0.9896\n",
      "Epoch 44/50 lr:0.00000 m:0.94565  train loss: 0.1446 acc: 0.9688  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 45/50 lr:0.00000 m:0.95000  train loss: 0.0928 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 46/50 lr:0.00000 m:0.95000  train loss: 0.1770 acc: 0.9583  val loss: 0.1369 acc: 0.9896\n",
      "Epoch 47/50 lr:0.00000 m:0.95000  train loss: 0.1327 acc: 0.9818  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 48/50 lr:0.00000 m:0.95000  train loss: 0.0210 acc: 0.9896  val loss: 0.0000 acc: 1.0000\n",
      "Epoch 49/50 lr:0.00000 m:0.95000  train loss: 0.1564 acc: 0.9870  val loss: 0.4935 acc: 0.9792\n",
      "Training complete in 1m 53s\n",
      "Best val Acc/Loss: 1.000000/0.000000\n",
      " evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:40:27,157 dlcliche.utils create_model [INFO]: Created model.\n",
      "2020-04-01 00:40:27,188 dlcliche.utils create_model [INFO]:  using model weight: weights_zipper\n",
      "2020-04-01 00:40:27,863 dlcliche.utils setup_runtime [INFO]: Calculated reference embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'target': ['zipper'], 'auc': [0.9159663865546219]}\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_MVTecAD(opt.dataroot, anotwin.AnoTwinDet , params,\n",
    "                           #test_targets=['toothbrush']  # uncomment if you try only what you are interested\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottle</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cable</td>\n",
       "      <td>0.933846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capsule</td>\n",
       "      <td>0.870363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carpet</td>\n",
       "      <td>0.895265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid</td>\n",
       "      <td>0.830409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hazelnut</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leather</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metal_nut</td>\n",
       "      <td>0.952102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pill</td>\n",
       "      <td>0.824059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>screw</td>\n",
       "      <td>0.540890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tile</td>\n",
       "      <td>0.965729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>toothbrush</td>\n",
       "      <td>0.880556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transistor</td>\n",
       "      <td>0.912083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wood</td>\n",
       "      <td>0.986842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zipper</td>\n",
       "      <td>0.915966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target       auc\n",
       "0       bottle  1.000000\n",
       "1        cable  0.933846\n",
       "2      capsule  0.870363\n",
       "3       carpet  0.895265\n",
       "4         grid  0.830409\n",
       "5     hazelnut  1.000000\n",
       "6      leather  1.000000\n",
       "7    metal_nut  0.952102\n",
       "8         pill  0.824059\n",
       "9        screw  0.540890\n",
       "10        tile  0.965729\n",
       "11  toothbrush  0.880556\n",
       "12  transistor  0.912083\n",
       "13        wood  0.986842\n",
       "14      zipper  0.915966"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
